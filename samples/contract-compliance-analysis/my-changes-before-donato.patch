From 21a1b0c6691ee544918a7b4d2584624ead6d8dec Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Fri, 1 Aug 2025 18:00:55 -0300
Subject: [PATCH 01/13] Fix guidelines / sample contract ambiguity

---
 back-end/guidelines/guidelines_example.xlsx   | Bin 35879 -> 35275 bytes
 back-end/samples/service_contract_example.txt |   2 +-
 2 files changed, 1 insertion(+), 1 deletion(-)

diff --git a/back-end/guidelines/guidelines_example.xlsx b/back-end/guidelines/guidelines_example.xlsx
index d64a20124607aa1970c540c00a9444c45ba2a443..bcbd9883419573f5ba198c4b8efacbb0f035877c 100644
GIT binary patch
delta 31566
zcmX_nV{|4>6KHJPw(X5=+fFvNpV->iww;Z&v2EM7Zr<;ndw<NF)7_`4i&NFrHKl1F
z<B1@ciZY;JXh0A^P(VOH#6V?f<r{XuKtRd$m}DS;al3vdB(dk@H^e`!YQ~02YUlxC
zgyR_H51_i<L>PXfCR883ln@ma(n3&0cE;p6ZO<Ni>AN1ba`l1XYaJPnl?1fCQngK)
z%NM?Hx?A-ii4M|O*Lmi+f*b^T2JoesK$?mz0~zepA>LC;9ERZP{Qia6>2d00UNO!D
z!Mfo9?i-<6_wizPXk8kW%0BS{iL{7fsloXSetRhrEYraOj=IN+bf`W{YLq{B$tpd%
zW7#5N>D&;w_&1?USl2F=?q3`$hh5561?q~jqOy$rC=dp?U#I(f1Mgz4nngi#)8^WN
zcTQI2An2h`!bYI+RpocuTKStf@BRP;@tjo4uMnZNd$V0sZiw%He@?c5r>E~_{+Pw$
z;mr>L>AyW&%$iKagy(H37a??U^(tJ7;JE-OXCaH^V;#KEpQ_i)Qv-sDDB!mz*IZ9~
z@U397^xQ0uqd{CNT6K-@o^0N$Wy83qMO+`i6K|Q(pi%X^%|L!czunjbiVp&i0cA!C
zy$<{)p6KFTry-fMVH7)&GyMc+PX9FIOph;W|9ln~a>;KY@XD%n&+$xuG;b*MC`9sh
zLrD>X4$Ly2?@;fT`TYAA5;@UHJmx~OKY+xh;=J;aHHPLef8~)svTCm&n1TG;AInuj
zeK7D>o30g?X0j8O_JcHH1-ULD`4B&J8%J@HZE#8wiq{#mfd8fQwUdKWuGVVY%YL+&
zls3LZbShr!C4N=-?4G?qJ-?W&ug-7mG<@ux!~~RpQu{Oa<ofrlva&dNNCs&3(dz{l
zcvEMQm@_J1BVF9*n5mNmu~gHJakSu>x&D{Ql*TkC%G6fF+m9W7e}g7IF(X1NlsuOo
zf&u|KB(6eG0+0eTs)T`Ti`~?USKY3uoqD0wft`oQ$}2vvc`1mcI7`)Pyp@cNy<a{i
zCph;r71l|XmsA&`Q$_F%GTX(+gG;M);U8-oS8iOYQ;KAzret^)46LdFIG?Y>lc7<m
z;Kz(OKuM2^(?wN2!DnQJ;N`WRVlpdQPD)77D)qvy0CFm+^JrzQgAo=vO!VO7H-tXS
zRKuIY1ah_mDU})JD?zZy2(UNTp^A19+60*$7!v)AF-Z?4;D3RKvfV9t?doJ-mlX$r
zbWRT5QTVpBJLmm~nM|6SQgyCws(mPZzq^x`fnwZ>ray)$`d{>*T8^3j!i|at)})W^
z1|&NO07k}s8Ma9<*?e)}Kv*?v-x7NeiaH}~(D}MFnsWQDNokO(J%*sssI=7_7NsbS
zk;#R55tjIfY}1FAz~H0|FmSy8EiIfCnnDzoIZa?|%L<6+^<Z+@3^=5cK^o#pRZS9|
zgJvW@akyT-wyqh>F~vixkvkQDM@55yeE{$72S}pi(w#w)uvR0#DoPmqb|9$EV_R+#
zr`97CrZ$$DQfV5&)rM9ddtDQTP3XjGlAWzEqMp=(KBBxMKW@Gw1d~NUM+Y-nRoedi
z<`&%vxZ(Z7FPY!>y?%p$@+i3!&w(V-UVEmKoVwL18yt6RuYa=Jdul>@@(enFU^|T^
z0SK`8XEKi~Y92fg@s6K`T$AfCH)2x@1^#QnR`Ppw>DQ_o@5%!)nFNmg(U(ctv4TkJ
zvmSSq*EVWl=35y)`(n#<mF%l|*|V1~W~bNXk%wWQ%ls98qpEpt-<5Y*^K?=*OP<Xm
zgf()cs1oj(y`yD_(1ko4ZEQU=^yLcHGXP@c#$nruZXSAL#D+Q_Ro*re-0o6^c6~1G
z4?UyjEeyUM`!2^+JB5#H<X^dZr}G8=wS<DP{9VG!{B!(^YL4qoAw~AQN>y}XJa3kD
zLjLU|Gsj<X=@r@Wk_|-cYR&2KAN7Txein3c<?WFVO2f~!l_xOo8o9ML=MbiTTmZ<V
zr!Q51={*0%LRUL~x!-x3bJd-dX79mkMo6kQnfu+`b?~fb+@Y87bOVjvDa`dEv`%kI
zSm3b<$?Y2---Uy%<QML(CC2H<#1<gZs8?&$dJss6hb=S|JKoY94xPOhz+${Z^+x*v
zR$u|Yapkd|^Vs^O4*p3rjC~$L;;L4Kt+i7BfoCIJbYE+$9rEb$($u}ec!Ks@X8Eux
z!&~k7q#cmB;V;F+8CJl=k?-D^zG7_ZiZZ`Hei7ckb>aE)#_&DY7y8D@(*s#t8AEWj
zBK%CeVMcGffZ+jwN$xj{V}k|)@}^5<f+qwd>DaF^p$%_SUh-=CQF01{gewB0TNnRQ
zJ!hDXbp}!2=W3J-kbA%4b%VK7h0d1-%T2rg&W?&p-^4Q&$q~ZMUke-(5`}KkRV&y;
zdw6esG?a~~ud3E8)TTN?hU-cPe6g+5ewwxbr4Z$_gKuiD%MHxj&`X+wEDA;SEJy=n
z%x~4~h3BmdlQBmrWDBTZ$x-Pqp;dh0MHZWP94cSrg@1d8hlXlRY}<%g$g_>s_DPlG
zx^4Q?t`ZlZ#nee47K`4UewL_ZB*QQHhN}#X3hh(&S$M$gKW~dA1pYQtwFM;$^PRdL
z&katDzhyo3{nRkpV_UeP+W_t^NQeUzqs2{C9iVf35Yh1t=yp7~P*wzfX;FG|MBj}P
z#qA#&vPd`fIc3K|7OpRnj214E=rDZEy;h-k^w-c7<TIR*<ZKl~!ymH>2nv8*OyXv0
zs`CqjZh$~UP&?jh(L5gDT|3eWn+|Ie4G$wItiEe5`Ub4k<XP$ZXQ2#LdxQcYA80Mh
ztJLPWUuX>-E0@kVoA{v#$IX^yyoOLfGY$9+*z{^FI5FP=M>@Mao@zX}#k*}&txx4g
z%{>~38A%hp((D3aX04iNTiY<!Ex#``ntMR&SKF0YFM4oytXw<62X2oHML@RYYH&>V
zIREs2g6`}zifs20q(eHUh-(2@3WBfU+z!yj$UT>K|9arpyz8fy^m(L-4y;hiFu8rs
zJ;I`8p(^w}hM<&M8YmL2(>nMnk$J}J{b6eP2kZDNWK1Ge8s4|`>nEaqfB!G0RArpo
z?Q<Z77?9t9vXQtpV#EeWSGpLGI>gukTv|0tt=^xq^FbV^h$BFl0pFKrrm?PUojwJ=
z?Y>?51_C{u-B}6(-QS-#`=>hyh^+z!-J1snxv^nk0NrP&*N5|-+}hUh$My61{MS*!
zsnV#g)9Jfbr$dTw0550haO?f)?On~JI&K^lgSv}E*qOE3wwG#deT&E=rfT^UY{jMi
zJJs$p<<2d%PjYw-;1m%twa2b@`}@V|^Rw0A6p$0cU);(nmO1DRFfO83KR<D-QGcK>
zpY|Hhcb)y<I+$-(n`<V<|Fxyn`HV|sTdzHgA0{lIH2j#ty_u%4tR}S_;^OELJj);T
zoD<tLXpJvsP@VQ9Z=XIt_zFU*0+FAcNr;#3D=C3$fpPr{fNuqBiRRmEoH12#g~bco
z7E03=8eduJD%tt0TSWiX_Hxp79AR<p%feQDR-y@eJ4ACkgv2;?W~&(aOc3`U{zsQ)
z<28=Tc4~Qz5%P7BkX;YBwmqLMr-<jAsQ<st_}{wf2)o)Sdx&n+{p22gs^qkezZ!to
z`WU8o6vI%B6TO9FSv7)!qrGjG=U3%B0mJHD^@@^=29;bG>4;sV3HIAjxE}vs{z$o%
zcGQCU2f<a$&x^l)$}i{(vV1!U)CgA58j!LZyy;9CBd!A!Xnw%Wg%7l4r&S{7<$@G7
z2pQpWmV^TlYZ82W>5$gbnLuUfUjcweRYOz_Ncn#h2PS+<?`d(junYXec7jQ!ssDjd
z)*$4B%Z&{C7d$Z&f?}2ZLd7aezb$v4B2vr<aWx#YZQ8@qIB1s|C4#V?CWEjxPa>&8
z)11)K{u3F;P=H&*b%fp=r)Nq8+H7G8%$|rCUqaoR*0|s#(G9PI=Nz>*4DgXP&3lSw
z$TJtG&XZH|XR$avjP=3o<~qV`j(bg;5WK`T6r6lO1S+NOO>c#|zx6RjRmV2RYUX5|
zb+H4so<;(-J|f@LelKx(GbBFx0sVJ#K5>D}&P9mV<r2-Tm<3(dDnDLE{EN@Dp2=Ba
z0^S^}$O7@09F8^b36510keSn*=Ncf^6_U<-*G1UGG*Ra36DKL3P{l(gA*Gmk1lmSz
z6SUPof&a>pb_>U9ZNHW1k*4ixnAW$(MySaNj`fIPel^nC7j2RDpZJU*76ObytrHss
z>+E2d&gh3W{@4#-O=A`Q$j=0>4AcZ}spJ#%yacGQ8(}E?$01R3n8hzm_=m6*A&0Q4
z<nB+iS))_Lt?<)saVI=NvD@sFStk5>m?jKuGf<5F2R0EdcS14{y*AA7|5onCf*WXi
zEp;Hx|5M}t=uj{f#K$tPYbh3c;@;qno9ow}UlPKppH1RRGH;Hfel`4|GXmoGJRk|X
zz!Ch$?i?v*B{<24ukguR+7AM@3=|c<jJh@d0%m7(i5RCI`ZeJ?md?$A6yx*e*XM{R
zXoW&Yc%3THbqm7mfA%3-_*4%VZ8cHHPploj!7Van2)uw1UHiYFX_gE8M<xZpuBHXR
z?DGOdIL@XZ_Gq^F1<0B4fVhbN*r&izl=yjAUmvD&5njkG1AedZ=#p{}lRL+(4JS>o
z=f(a!=E@)}=|RL7#`pzRoCQ|tmIv*l!=j*PKjc`Oqk|VPLyDx;BFr}7&Nj)iIc*;N
zzbz9H4M*|dgt}|~qZKPxmhDH0u%6i9o~A{8QhTPEf~)B9O_iXm#)ZJI?gWi%!_Xrm
z5EU|MxCaxA@GNZe7;XbK2$SJ*;iGInYNTMrEz3cKR8M$4CfQxWmh)8ciSF@vLu`CU
z3j>Df+CX-rL<9m7F#d_|*Z>v=4_lk8#P!H^rk_I&tS@A~w+=t~KZ>aaN0fH=Vw?5f
zVksubqfX?9qNg412R01>Nhla}adgbv6ZW4O{P@YD-gZ?pdJ+3f{o(Gi%LVI6FYo6x
zX@;iwm)10{!!ka57y^_0fDD4B)wLAoF#nlVl-8+7aN?9^-JjGh2jE^eZ&_Ftq|iv*
z!kM)sl8`_aQNXOE>hdB>H9-ou$rgAUV$M6r>mG{5P#*MUOY7yGPyGZXuhh8t2s~c_
z`A=JNR~{6NbTBeit`uHRX2v&~b!=v~H?dce(Jb__Lt2`tu-Z-+%GBxVRo_qENq9Bc
zrS_XxHVb*+xu0-{7eMo>DRX-=CcR~J3Td=YJMqn+av`d>w{4Zeh`H)Spz7HSRp7~i
zcz4T(xF^;;mZEfrS4{!9vC)R*GOC5a-b#AmW~lJUGG@s{KzJj5>D!w4!+D^6UcK!R
zAdJjJmzw4In+V2enwFthB7p1t96r;7tc}I~81u`T=~g3X39xV{J)T?OM!$jamyX^3
zM84hr?It8j?%dE7&bUh_@~vqnB|t7e-GOSL35=ri56V}2!1#${co?e_T38}m#2gp4
z(Lc8(D_82H^-l9Ze`3@<9rJ|XZ-oF>EM+2nW%0sH>)&>p(jLIy6|$jA-yr`#1}9~0
z#%_!N;6n@s(;&k$-<FMSi00o(LQM>7Ir?IE<+k|6FiO=1MWiQr3&mn%wH7pNDpqQ*
z0Us~7_s{kMJ-)u5=i30l+xa+bmyg%?bgRJjc#j{h0sm)eiTyU<efit(`}XT|IQJ)B
zZ+tO#`uKiMm3*77Gcpd0m)^a4zdkH4yLtmYKhDq3kFTxo)MW`U?LV7&+vhn1Z1^#S
z5Y-L|6e^9^_0h4FJ_KGK7k#`WdR(6ulm7BmhuTgrM%UmxtjE5%)~BObuRQ5a9#jbR
zTtXR?n#-3_x5ORP{buXn(T<}IA5Kv0ZSm!UNTiKAVanZ_wda*>_o#wqxACqqcU=VJ
zZF9V(caSgCUAARRss;J2A5^ZQT1Q@zYFyx4*2FHEz%(S=VQ<ts68<5b5dPPC_l!k<
zwBNB&@*FKGK@CJIEQI_TIpeJJp;iFrGx$Oxj^2YrdT`wW5y=8nV*D|J7cL*dXldnJ
zvNKu&=P~#<Zv0l!@=Em~Bknr(*zE$)fd88c)PT8LQI!}j@`ZyUGblTOg$ZLHRt$YO
z56ZI>vIEr2e_|+ZBjB-u34%Ubq1R~4Uo-msFP>S#k-S*_>&unL6*4p{69vZ)j(oTu
zS`c$;i3iM?`88B!(<asb?6*Nya$s?MD><1^(|T%?HO`ZUU9=}h)s#pdF9Dpf0)q*Z
zo0)~5^8DnA@18XiUSAkmPeD5&*Wcp%8h;L3m}qK}K_qm4o=?t2AQnL}I`Ya2aM1FP
z32Z8U#x@_4#52mo@Y?Ol+}h=EIgr5@^#Z@IRQWRhW01h+QUqe!c;gs>sv;gjOq1oh
zuY|``k$wm>lBPlkIb{;yU005Pt=f2d`?%qUToVsLuXl>ar(yyzZR3-49rW3t!NBS)
zd%wfbdQvFW3KV2gVrRb3%AGt$G;F205qRk`p_m>seV|GbgjYK22>Ue0yx3q_xebh2
zxrcS&!tU(f#SCi9%;8!hwPV~L;mk+XpWm@B)oQ3h$V&DjWGO)MFcEZ=c{{i!0juVJ
z6X@ea&;jzTCsxxAo;EUu>&SGNo8;$XM~3cLtaKPAD)lQ5<#ZJ5=`Omb7{xB3Lxn0|
z+H%RGWzc%382_xs>a?P#_f=(!Osw}0{?5^_NR-0mt-c6}Cbrri7SxuwW{_ZGGbs=l
zPkN!_Dw(X00&48*3Kg*VqUtx%tEp^hf~ZRIH%+y-HRRb-vZoqGQ(C3G$BD*niwzC3
zS(?oE3;W=lng-#V+Q+!H>){G0A)8vjXgCtYTjnp`AUZyh0-CTg*+7(%7r_eZd?;X^
zmZ=A9n7dJmXCRa`g;2qHFOmW{a0#uzn3eT|vX*`$04kQaL9IFXT~;VO+GwCnz0;jw
zapw$Eb6KO!_fffFtm604X3=b_okJIGd`Kjy;hpgMRq86Iu%#PsBk&GcN36PzPSABA
zCY+gnaD2J9(MXwOrd^mBpfSwS6zjjbN<wf)n*Jb}mT8j4W|<y*A>$eQ8Q=IopT%$w
zm;yNX{}i%8a91zmUBEj-4A}Ub)WuvosU-}#DIa2_uqkP>0Ojxk1>u1+jX1)X!?fI!
z4;XR87OK>=&;HR#I}!c0`QOA361<k#)6OHqYkd|V43m4prq3&5(!Tml>FHK0J{Q;1
zguXf~g9v4;9|3C;1P=cmWzveS6{QBG3nhsh5o>qDrKiSD)Hz6-$Ip9B3N<$u#hQ9J
zG>5UEO|&>tb2dzClF@)34N`m9l6J31+67S!yF<Y+`DH#l%#tv3eCr?;S3xMr*Yknl
zek2&N;}WugaF1EX&!dkEIV`~y4X%I<cjHlUG#IxepT0~9*(|}8557nz-r)e)xLxm&
zk_3N4tQ-4~OV`5}WSx0JxqYw)*>dnVKrP7yz&o{{{io}4jj)!Md@UQYC>!s^d;GvR
zlgW7P=*h?cszdg0Cz?~{7pHdfI{G1v0<?9aF`+LkpI0r`74v=47$R{PoA~*~`B~N!
z;>WX@B{%jc_);YmlqGlU9KbaeKF377m+P4cQnAFj&HnN|eh`i6xS>w89FCUK;80A`
zF)u{NcgpVn%*KhP-e{MnmOF1RMW`9;xv$>cmzDzsZ++3l#|n;PjXucw$Jo>YYz@e_
z@C|T4?d-AbqHdGR#%$3JnE-H9b!LAjhvL}!Ln{A?bL)lRUl0OxAQp{n0!=zH2F2$_
z+}MAh3OA<myas5nxA-t|4U$xh;*^S%CGxUaXOO55IYh^d{9H_Z#~m_b;(lZ-{ll0S
zeP3*k#m_f|B4)?5rC{xe8{Z&u%JLdp^=E4;aE@>%>5G$_>zv(|{|w+qb*2Au0<+zw
z|Azt)7@}hQpC>?DH*Mx+OiSG<t<5_p?3o6dz7GtF0~zw>ovpXDr{;;SvHtrJrg)xs
z1iZC&t)fKe3NOY;kZlkKZbXdj19vwYxY}$EaSK)^IH;1e4bmZ!H%!H!Un2kWzJCx(
z1oc7Irqf6|{~2AYkm~T|P9J0Go-)9hj%#F&t%#pO3vIJyU*p<L`hmJE?j$9kRg-W!
z^HS)}Ov*9o;16$^^ht`4do#!Huzs{Hs)<5(#q=ap>vFM+mzV^!9jbCt51>FNHu_?4
znWK{Qmp_Uy_UrGJ&n(dBT}+IS3(Ea<o4Zgdv4u>fS}0vf^v46r{dfiI=G1_1sZn>d
zBR1IrOu%8hrnKhzhl6pkpoCQQHcDP69)gUO<Cy(A?12EaP{U-e7h|S6u^=m7DQ=5=
zhW>>_H|?xa+Pp`Eezu~W@GLf)s1Z-m3Y+!s((<iwaXRg>gFNGPVMj9RRbq9Y)Ztj9
zY{9&Za1tHDj_6C6JHo`^23tU%7p6|WIM8AJz%k@$2eDWOll`HM8X2^K5`vOODPE|w
zly#+*M8X_i;lTyCl0ujhYLty{i^G^>(gON{Qh7qAn(4Vn)FrfX+l16Y(~>|AGvcPu
zAE`E@K|Aew&-pw)np99Jd1it~T58U=ktGYIiVL@bgQPvB`9M>g+f%@HmEk$7RPtJE
zQ4LaD<oLo2N&TZpRM#P{K?-_fm+o!jaN`kG?d8JWtAdxyeq<~eKBa_|JT$*VvYoa0
zpOrT{X&!~xgseSpX!2r@NtGyz1eYp2a@RrkGIDTh3;lXe&k{rcbAoDvt&mfvRg8J5
zib@pO(x=}kROO7_mL-6i3g2EkC=_)xcy}Jk;RqSuNZKJfP2`6CghR<XN2w~Vsi9i0
z8;{Od$7i@Qm8LseNxVZcL=nbeo#FuYW?gW1uh`l?-H%PntRq!5noPNDyu54qL`KN^
z-=8ciF}O5&9*%2i_RTJ>VRjk@m4Vm=IbNOwv{R(YDMp_M<wQU%*^>FAjX`pZ>7$Lw
z;yprc=fVhS#A7kTAkUeTJWS0jX6XVP8Fyhchv(J`6;#?igL6#9<N}$gr{{)Uz~9g@
z*J!nK%v$}5%)JRg4#qE6SUPbOvUMYR`>gDNE95GVmfP2BS7Y0`v8NF!N|MZLTS8d}
zn0t1bd*#MIhuHx7kKF8V>P=>2dC#qn2c7RiHkSLBhpmaFVT|y4<+{S6B}OtYYo>&(
z+aJE|ZOE*^W7LOv!Mv=w8ak;52ZJE$<fS+ay4Wl6>?8e7V@)G(PY0dN39|iva2m>Y
z5qzHD7mHI2zKzgCCkNt_H$QrHdX;;1MGN&$hYOu+04&Heohb<`kCA?P4NI0=jau6p
zhV&<$&j6)(ryuR2sHw9ozW8Vp=h<qf9xL9)_Vaa0B&%5mC#<|l(ncpQol})pE*A<D
zvvW&LofJ*xppcRCJZRxx6Z1TXmY@D$n}cb8IaGiV`|%U&I0QT;>#PQC1L*nsv7?kX
zA|7WzvWUw`xN=bP;+t|>$|X|09Rn-flX7D+*;2{lW^})0h+35?az60+-!NBM>#>A?
zZ`x^h_#xb%_b2ffqlyRfGfv`Ekd&s{ZG|kQF$7<chgn|KG)v3ODl>%*HU4p9N;y?N
z-SQZ}6K`*fORyZh*w628sl0;Y$}(_9$m+WRXeB*hPy!AY9*DcsQY92@qu4D?(OxEn
zM8;E@izlksw=ZVK)W|Ebb&=i{)axuc{m&!io^np&jJV3Qoi28bo<nRMct7k4ij|K}
zTH7|j>XRo6P)9*cnzp5S#ukdGCgB`bEv5F;TxEwF5evvFEfcd(Nlo#UHYTAz$JPP9
zCJL+N1qcPgz5xF#4gT-N7bk=e_;cS`JNE#D#w0E5FRIyb2i7cWMS2;3O6KGP9Ms_n
zxZh%fj>xUT1`Dt~?5YaebNgcq?=1VsGq2e)$IRHQJjw;dW7db;ADqG(B$VI0<u45z
zK#&N!!&J$_NF%oOSE-S~Y+2+Y2YCNv)#Rh?t>DT%^$h26`Xob4;bw;IHSHf<icY#k
zGTH&9`&RULy?(I=F>7ezMhZ~V{8OOV0jk?D<f-q2tHFPjbC`ND_zPV~ARrLpL<UM+
zfJ_`NCrUTu2!QB~;e4@rxVIs{l=3Os*29$1=|D0mgTPINs2m$MAfT7~5QRw4tv(g}
zsU?g^(jQEdH1z`ul%rvluwKkfMlQC@!zK<>o{6<LI^(TEvx>&Aib22UmCWcQ2};Uy
z4Z32P2AJeDSiy?t8Vqr`P?=UxdDkTpfUO`!sfmoe(Rq6-v3#2oDJ6_FQtE{09;jJ9
zsNY6M$rOFa-c3a9!?{n=2SYH}$%p;|_drplTd9h32sY0qNG&gT*|i!i4^^R7;i?)4
zXvV?${n!`tC@KOGSDxTy*#GZOPUuAvhtqswh4^^#1#5sj^EnvPcT#T5C@MM;AhbA;
zkw<9o1MCoYdEA2$)7Uz!iky>0piP&7=~sC=_uz*Is}+{GQDMidJ&>&Je(0o;$;!$J
zD-d6LZw0H4ZuX?Mz(hR;)%(fpFH3|oHAwr@TKm<Fn1|XR&OBMb-w?u>w;eG^dqHge
zwSI{%H~XD4&OEs7m3~gzO`#PRzyq%0gr!$QNR4QW7ockm-gIcS8*?kRU#T&LmQgVt
zK2vsHWx}I^A;BHmZ(<OtS3BHDOr=O2mSq5S<bmJ(K~vF1@R*rw7o=3T-=SC?TkY&d
z<2&>yF@j->bR}VlBT&uhx8!>0f#^)g8Ca{(Z$lw{e!$n>ssdxq=ldWgz@XFP$(O%X
z>2Tz7-^FhH^QpG>`#o-Y7U1`BY`^`%p83Y7zxJZB?fZImY~ZKxtLm@A;CRpH%~>g-
z{?})vLC@z<VHfR9Jv`xju%t_BRz4(O0Jzr$<?!Al*${I{ELf~itHh(?Ai~WR3@c%c
zgf1pON-r1xPW7S5@KT{BfDZj}!iQ2GZ-@A}YB*#W*!@8_C2V-y<tkT~&UOPdTEW-(
z+3^g_<F78zrE>0=pDZ5hHER|PA0@StBw$zp>bB}iMH;_{U@l@OVH)i%seqtFKQ;Qa
zK2b7chF^||fi^b)$$FSGEKV_wb-M!cU_q?ErFX*QBaLY|ru9Y{u=}snDH_$B_XDVM
z#o}OATGnPmktX~hizzl#g``;FD98U%Tc`&VZXfZTScjZJnaXQ#-qWAE^$)1uT%2RW
z&6@1|%8(z40+ASV`*bp*-^eC@K`t=@*CzIrL=xAo-!Ei7FsEiY8Wd4LBU+B;7RknD
z94*JdzhM@=KU^1U0Q7}S{I0_dsY_5{EdBu%;h6yiK8%N#{##F@hf6F?v)mVya}GCW
zHGxu56jSRg+ep5=IjL1rmSf%vZryCs9CUe9Iyb9sSS5F5OnGj`<Smm#R9uf#;RvYL
zJ=d{c&^%QK1Xpuj0z*@)#ks`-1{(bl+hR{x7vsbB?TkX9fX;e2r1ubC)}e{?JjpcX
zP>=zMR-(P&9;Dgh3S=FxL-VT=`hFm>1eI$tHecIY=bDR%F9EZ-9{;xBz~R~#J?U({
zqy|7u?`p_9XbL-Mr|dN<msAV)c|}EAg>|5SuUg}8MuSBbjphk8`hD+rFUDqBrEWnp
z6&D}bZ^|}Bz`KPwHm@?RI6~1Wkd#M9daU70Q@QN6(>#vuzZ+(IKJLG5z2XqiHDAJN
zK4|;kO%W9(_1vj#XKkXe4Ef%sp>pTRS@X7DisJ|I3XKSs%@rNl>Ad9XgC68-(IUgr
zW+&o}Cug<`nf#|4F2>6cmaCl1{TUPN1y{@kZ3MyLfR7wxbF)-qv2_zMnM#8&Yy80&
z+TJEP)tyJ&J{fPy@cybsxEOA##Zn%5twc|JJ^U=0m<I+67GBW24Sfqi<kOZG*W<f~
zvj)`;!6JOpDi`ONx;duM)IC1lOZ5-4p?1CC1!jc~<1Snn){N?B<lk~s$A1HgIaKP<
zvRwnk0lxxu(xCNS0<m4<c1;@mH~zfA!!>g2&dVl^aD1#YjSEY%_p(gk*-28G1O?NO
zAQehc&WvxHg37>$VXarN69pqK{pFY$3p2+9+k|IHpBxcgHEI=aDs7Z7e2J#*+{U?W
zh5Rkm9qd3jIM3=bk+KIIiWZfjcG*jv>=2<i3Fzc5b`WVHZXo%d!k6W~T+>jc2y1Yh
zz+j$IK+Bw9{YyL>!+m764|+~*z{=&a9y09g+uMC#{{B{|?L9>@xi{gWDVCez$KneJ
z>oiky4ChfdTd>`#HS2S|WM394@KT6a&T7ZxLZX|G9L1Y&8eC_q;^rlEmFxHy*n1~x
z0tnmYun1m8wfDXY+IX#6g#6b&#1>&+vvQef@ArW<VglqIAyZNWO}=3U3nyma#+p70
zVe^NQrWSb@RU2jvn!i$Xv(6yutyr2CC#By@le)RUu4^Htz{?d&jW$UCk{XYWM!rJH
ztxF*A9Ij=I@pbZLNes}?UEjvBE0vxZW&F{=yrKJ`@f)+_L;?-!q*2^<p{CV4M!91P
zKe=D1R?Yeuw`(qM)*eAT$Zx?qE(hXd!GFN6i;yF<TDfrTI<;S1jInr;fqg)`8keJ^
z+Gxc$Bb99@BwE_3$G<WrhVu*ZzfK*1^Vyd>`%ha6$j@~({7>rOVZ-R`;%Q^%{9jdj
zLS4r`iwn)Kw&}a?j+Z&!h=&!VLY6`@dCj`mw746G>0broh=;Pd#^?1fjtMxcx$%<s
zIzE428^AHIMq)R1ks#v4gKj091SYY#tXlg~#pI2FyI5U+S*z-zs^uVyk0IcfU*h*I
z&E=&~-MaS>9SGE-#mm;3ort8tCacst>?SifZ45_(c3MWtL$*=V)h02uBwnZt3AKiY
z=*q~Mh9DVx?vtLP)vD6C48z}F9(2*B&7SKtwwBcXXGrvxA)%I5#%yVYD2%=Z5_e-K
z`kYT74iR=Z`t_wQ%cgRcuHpcYgH&QMXy|>37Q~|vNm%0*Q1{&d&oxUkZ`IST2JF~?
zGUvXd#JOCx-4vq!`5L~<Z*fFbf3hJm1zP$hAq-*2oTw~OrO_e$W!0NG2TGf=gFU9m
zPj13XtK5Sf@75?T0@BQMf;gTtX4~}L0;tdXZK``7Z^f~Yv^GPu18TrQq?tH+U1Z7a
zW<ID6deP$uc8Xtn2m1rk;OGU=EzEt>LP;nK56||iC)#1TVGMXJ*49=>?IM1sj4geU
zcFs~(i?-74hZ`R=d~a4HwBxz-rO7>%w`Kg=xbRx5YiPb@_HdjClPOND$Ns<F=~?j$
zY#WfI?_YE{8K__OS>k}E^MAY2H|kPH4a?j}cXn9?)1hweHaAWdBQrh&uJvE&gjpl8
zXZ#mtqq4ia3rUaLti&KM$DeQTC6%mUk3CE$;AB3rg6b2>*GhZY%1~_(e|8b4yg{@l
zlOW1AoQ>MNC{BSI2?$D=Cji>cT^OBiwv}B^a@N)aoEpD9bjcHmn6UtZs*RynAzi%m
z<}ZAH)7IUoGrFaEfICRrU!tMY`|dR>g~f%CR_`@oZcqkIoO}b{8#V^D?wn$HRsEMV
znz{{Snw0B$@pLt<9eVW$`!{dn7yWNB=VRNoinO!F^RRyxCQL6xzn<vEZ){lRo^25<
zr`u}x%{-DtjTCi5mFl=P=hW)7^(ln@h~C<@t!$BrvFzt`-e|*0p~YYpk>=XarOG<E
zMlUi8J5z%}mk2Ng;*knX2{68D{4Z}+!kbK@mIDIv5>G^A!2?`6uaErsdai8$20m=B
zY_2rDmT7p^W5_Hr)!Mo-9_N?Z(mkUgBtj{wqkx70BBup>UVFBCLx36z3Nvm!9(|B&
zsgN<v&(GH?xC5St5i8A{l9Sc+s{r38=N1OPq#GWa(hkoDuL-+&0k01N1mtSjH5R80
znif3(mqfL=FThI};4}5QqC);=-SzQZBGt9)b(*oKsw8!lraA{b(<Y{8BFZUw>BXY$
zrC}{ei>H#Iu}Yu5=i{id*6;q1W^y?$!Kz+wxd-rYzP-o3?)vp?>sFNObAP_g|2E*R
z_7!%0CLn9R?W^^@+rjwC_<3NfKDNI+Psg3OnA}+L4k*T4Wf`8Di!xh!U*C1fu)Pua
z_$r$?ubP;@nx1aBqZ!_w9(U0@WIsvthZ{9*)-tcO(JTEZdoR4N(j8rXA$;X|%bvH%
z)+?2HUAqnA8JK@Z^h$rk^!)%%s(#DOEhT&-Y(FGSUZtz0^~`*~P;*PBPn^FXseTvm
z$&ue?1W0FrJhj&}9<pRE>CipfMg-BHXI`bmMLzQ71`v6+PrL*8sh1QC4i;UsRM%O~
zzh2ltEmUJO+Q)i|$R+iUKa1s-8f}`Vj$hfNS2SK}mQAE0J@04~81Ggh^)bj}A6?%}
zFtlbIeIrU4Q7^1pvX_KgMCguAm6TG}<t`>}0jY9Ifk~rU%;3m^E7mGIs{6Iy&TfhR
zfJ)=8A>#Prn@{6$c6^3ZF`wUg^DNmg+m7~M&w5@EVeT&Ja@!rwxpsYroTIZWGD7QC
z2g0gq-I|HD-p_{K%=AmH>GHp!Laq$r1Y}d!X?k$DUJE<3>@+kEV)^3;?fTM3t-AkK
z0lYCE$aK(l%2uZJgYpXjTy%_1RVp>sN`b&<KFFVY&;<DTeb_bN|HP84z7mvET-@y^
zx`351ow$ApHFs$qsU+k;e)7<7TNLf}mKb0nRWQz1g1B>Vuc^D%kBu=Z6nJydc;LG>
z`aBUM#0Pq<b(jnj`9U9PC#AE*``}Cb0_;0JQ+@je#MHEnXq-0Fz4!F;Ez%9YK2Og?
zph<?&N(Qi$Gt3{d^vzM_CBC7w3WHlEAH?U4me3txFKJiJ9||cSSK4?w6V<jcj6GMn
zbWLnqKz{+UlObmi|4N{nnr7=BKavwLgKCZ8&P&C=-OWeA1+POz?dd)``mDQX1Cm((
z+}-`IDOodBVHA2;HhX%ery^UBtf-Q&bMZ`NAS4+y=<G3!nGR(WONEd|@suo!+CXs_
z(kxUgdxs%bGrgsrc6f4uy)7sjUrxU=N){PkRGd|__mmj4POK4P;Z7faph-+k>2#OU
zBQtYLw(y!$gnWTgwXVk84%iB)103Yqc~E$@g!rI~x>dMXSGd3-CywGtxTAJcr<cAq
z>?No(p@kCo0j*ZyY8P{Ae#FfvNHu5chsG&mU>Q%LAeN<m+|p!jjzpPbH%TMRLt0Zx
zotx^Box<%&y`bq(=)pW6)#EWW^JY-rx4YhdIi4%BA6`%gL;e#nTY{(w18k5I2PyrM
zt58$&CneqxRw1)bCs}~qb>#&@72=pr;FV-(*-*}=D<|pmaCPj>4A;0VsAb*Apc!oL
z$93BJ3^G+0bl@GVI`HXXs7YP50p{NkKGIqx{r76751tT8>GCIFs?Os^9qKR|VjAw-
z*D<lG#aL4}==Y5g$;6~aJ0QCg+{^(Fl4}!|+bqjpch@C^yth|*2~yxpNX;j}0VEt;
z3GGu_Tj=jd#RChuQ+gc^|LWG?V;I|;cY@!y$Ie)`&wn>PYHV^tA8a~;tL_@Y-$(Br
zHHSd^9HtEYD+41L3^$2K3k=9v4}L>wrt$B5jCq)b6?q-m7ef2ZgaTlIj!g7zTMpQJ
zV8#q3JHJ13d&nCfAWGRGEo2*gRGyz6?cg0l?H#t4Jr4(;Vw3S6rbSc9;4Cq)!(mp*
zX(uK!j@VaI7XE5xp3=_|cgjptRXYGxM%ik4n$7S52N!f9a^%1>4A{A`j9Z6uch<NL
zh{j;E)AWcxOTRJw<pEfKotxRnxb|=yejD2VBA2x2{n}ccE6J-ynI#&gE~35uIldt$
z1bRxbk2SkA_63<vvg;*+wqZebW_vN0rdqWD=?MFyCy#-A*%7CNLE&Q!t-m!O6`~IZ
z(js7!hh}RWxTzLwiamrRNFY?XOWeZGKPLHmRB&<XVzL2WMd3l2)o=y)b&cdP9-AtY
zKJJXFW5Wynl{QZ4MMO#j<)#8i5h{|IOG>&vTB)aJH{JI)dm_mS@%B*I^Gexj+gi(0
z9X9%sT|;gTLgEvjdhu!A5mYDc;e;ByrrUccld*qDrFpPVxJuSuSUmwh6^=FcrVpB-
zS#TiJLgBS5XzY0y(asZXZv5RAgzYB`k+a7r{lL}fvqOHCMChBF@%8|?Tnw_#5k}pJ
z6A2T?({Bv=Be8%Ym>%Vb1$j+vZ0YMinc4{&Sxb)C^IXm}jRkwTs=>%2LlNCBJ6v(@
z?HQ)x+!$pQO{6%;Qi;HFC%}4y*U1V|%w*fKyS96R(_m!Ls*uMKh5&;H6MdKv{>pE#
z3WVR?j^<!<d?0IF3OoahH+@YXIDU}@KmnoZo2vX(k6&wW+gN{qVbLOAA~z<ClELx6
zcj<T-3LiP5wUd^-;pLMfq}*WIW*E!~=IEF!+*P~$phzFM35F$eGbnH)9Ml5dzW@Pd
zfzrz24?&W<ASy{fyCGRjPJTX%+J!Znfr9JW*@PEJr=Rz2^PUH&r$?VRl0Id=72uHF
zTuZhLzb+;o;9#h>oAO;#<cmQmh+-GL_sgZLn4({?yAavfZeohi2~*GBgnZLvT}BJ@
zp)u%gmvhI(Yb<mTuyUTt4Qh$EMl@xYxERAU7|FE;7+{-H(?Rn9E1<lOeg>0-W+KFu
z4gTiqFAB`=k{t(tAq(2*T-vuWu8`B~*4y<achXV|3-x>HX5XS?uU;BC1Q?I{>u~6R
z<#|+CKi-vZ6t?X&7)}eI)3dG((TjY#8~gbe_G$UJIzPK3LowdkMK|07)4_TLUF})i
zC`RIH4sz{;z$n%Q!&0J~CF>esMEotHHZ7(>U`ehD3v&e!2T0aU-XtRd-~;IYT5_@Q
zQbqzkU{j-p3R??@GiHmUWGbQ@tBIxfr(qLt&W|9qcKFq<?+;NjKY2k)<l=>r`E40q
zSZNeZZjpK46o&`wgX!TT?6);+XAuhE{>f+M?d)rBb@Dar4{Qri?QubYkbH@wPu`>S
zQ>f%to`V2}AB$+#>thkkNJ#%dQTG*wIjF7~V2oqOR_cy+-D|7t?cH;O_`wCAYt+AG
zJ>_wd!1w^aApmlSCE2R`nho#$>rW?Poilw>0V2E!gjVqP+gyXEERz~OFtVYKvYpzU
zgp6t$GA{dQ8bDzEr8AvKd@q0~<0wKt84Zs_O=3Xu2U^@y$(M<Je=rMqb^VU3n~E>7
z_)8+07+oAlt~6wU^iOtMt>)ph7{hNZ10#J?lWY||o?G1r&X)XgQ_RGOM(R%0@=cTa
z*Wd#Aql1e=DFE1=BMBRW{hS*}u57jmeJ~vl_`*jm*D2r~FR~R<X$;b2ZvUH`$Im;b
z(+A+3f!D>8)yXe|pg?Jnn0TGYc|DcL$(T5BaJhT>YS6<aLqW+HYmh6eFCU9AO=&Nm
zz&ULo*PZ&!$1B+_;Op#`l7$C|n~qh8jYUM^yJbw&sMYWGPVUUf!tdhtyuCX408)^W
z-y$0pz{|~|v;gq<JkoIIWPP8$s2U{l2>|5v<q&dvc;u(H$zJ$8Q9u4v^6|aWYOrws
zS}Mht)8A1FtKE6){KcPfBe2!Yo1UfMH^aU&Xfgc#iLl+boq!oui`XMD<V8s-QM=XE
z%a53FymB&{>D>AJc<}K8uJ04y>E-N})A`Hy-pMJJalA*q?a2LY=J;B$z{JMG$qC@+
z<Mnn$5A8(MAx)9D8bwH9;ej$TOy3D^MKMiTOK}W1l(4vt{W`#yL&c%QuA-;viKQLq
zJpuvU*~P9}#$_SPri}2~l24~-tj5BgSG5U?x_|(tahAi;n@*ArfO;Vq26dMJA>YPC
zGkc1ozN43^K@x{x(GOquw8!q|C<35~{`1j7OJb3HSxB9cxPB$3V;O@lWBp+4HzDV<
ziKMO{X@tM1RpTGby*Wu?jip>FrU0_cZ)LF@Wv0i$IYx~!uM8nIS3HRFU}RI~$rVWw
z&JK|PUaWT1I)Mpycs1T}^?1GLcQJopwg2h%_%pgH%tcq{Oh7<d5>EabM-p(^C%Z+9
zcF00<Uf4NQK7m^u`^=&xT)<Q?QpG^H1jG3-XS^8>{SgCS<r1N<hzrJya>SF{Ki2$U
z+#p-)2<H6~SP6K(xWI0WCw7KpRVVOgqeq7c@(WApPOAOl_S8SZ#MT5Sq$OwP5%0>X
z#+;!=!2$c0aUdLa&llj5+yWfWKVy!-(3)sM4eK8#GJLoS$le=@k|@!Mx2z}|F!NCR
zmEgqW<&qoG%JnM;aZ0UpJxnZVcxp+4u!+4%e}Z;`;c#{Jj=Cqvr0P&P!V*L`%PC9M
z^Q<F{mzWW$6W=4eaH8Sp0-J|`-v45Q9B{tJ#wMe!ptnWiD=yh3X#<!d!7j0K#Xy^p
z|52!Dy3^AQHr*vlb_u({?3ZUiIPk>|SBO}NI{t^><kIW`l%U7yj`_XZOuZAyaiBPM
z%3z#wUz1ij{vi3KyKgfYbjXuYPr!}j0nBiY;ANc?m9h7fo_Eva@ky_aejDdOfbUJ&
z;%i^?Z-e`>3`xaQTLK`0N&;YU0<mw{<&C#+KnmCk1jf$?uI5Tb6lRk71F8~-m#1@B
zSXKwIxx1eLCQR>U@O)wdk$n-XxS$<bPHIIRVl~%hnCt&jk%H6J_41U)#C$*^Nb(4V
zr4v*~cHeW7qyOa$4>w|lq#Ov^q6axKS*maDKwXDbkI}H|M-1q_OwYT_vUgb5Gn~Y)
z9iRL2yz7Nf%!Sl#&NVg8*J$p=X<vhxH*R3cErrk;0%JAP(kVhe6gHgbFd=e<_JM>=
zvgBoDkLjW=q0@6P1B%g}&sxQ;9G@Fc7m5cK7-%R2Q`eivlvm;`g@u{xs3fU>Do+P$
zj+d>b1@>H?H3yKk=ecU26--Cpudi{uF}@C>1|w@1Ax;~}0PbM5bp!n^Z;W6##Es$V
zU%AF<RZ8GO+6t~k4J9Py!3H4u1kD+q(~Dm!X#Gn7RUy-~@TxBwAVnlv&j7U*9x+JQ
z5)3ddFVx!!0*wI$LuSJ9>lJc*7yo1_Y?t`ABs>CLPz*5c-0KA6M^nPXU`-mHn5VWi
zHGg#cC)hGmhsH4_qB~;ecDdH<g2L88jY3qLvG6GW-0sY{fYy@LxGAW4%{G$BS}1IQ
zV>-~))Pm(|c+!9C=27lfw{Vr|jcPxqE)ttJT7wy^kUWnt*IK`*vz0z^xU4OivIFu5
zdy4{y0S(Z}o)pgT=LO^a1Mq9AlJfCuDY2zR<av&IN96BiMhV#~6+e5;H73w9RVNSH
zG*prL&E|&oJdgs1KZUhAZs2q~-z%q=>Yi#m%M}*dSMLGnz&s>~OdWc>3B6$-CMtza
zWCh8waFmGsCzgMM*8xy`yrXVAu)`aWec(5R5h-BS^P|>|=}h~^_67DjhxJy2*3bz(
z9_#12jhdP+F+)wIS3cYSi`96FjF3ucD+*2!(GWNOLM+%V#zQ4Cx}RJ?wW&t@8@WG+
zJWi|=><z~qG~AdX4d<X26)czG0y)EfhB7>nJ2Rk-Hu!6IDxx8*Es(2`4^$lsSa9CB
zehTm%uuXLq6HkT0E0MHQU%ZbG+=y+!;VaxsiYG5H^D70$!%8Ma(X~#M*^KTb1TLw1
z5NsoZ$?Bhn&fTOIxu#HezMlPY0i!;s===weBFwj}5)9WXbKC;f>V&;Sqq0v1|DgRJ
zUecNXArJAoWA4#Gtkb|5J`&0obQYWh{3d`f*!*lfyg1yA$^#Q;UD<r6JsmcNY!hpK
z0J0t|G(80-8O93CtBdH$X_<^ABI9si%X#!_ztxaKY$W9?#!jlkJ`yk)&Pw3zRTRjR
z&4?UpB;SQbpy*#sahz@p+}*Vu5r*Kt8FC;is1C(3e*#QSUzt|HnGh&t<$7}W32*>T
zbgLI!)MnAbuMt0}gnsv=@EZSIy5J3%oj^J0bf*$l%+(7dQ~E~ZFFNkq-w)Rd4$#ij
zDTeyQ`*Ne3?dMPeC&fX`<^fb&RJkI3z5}Rr`VDBKJE*b0czkW<Ekn4{@JQIfl{&<^
z$Y7ClB+533@B+cb@-CEvq~)Ok0tEqHu$7E+%4J*3MY=@1DJKY>zxYPBJqWe2&}&_^
z`dV&VhF)2$>VRq#vMEI<{^rG+w<mvF?1+#R)VaR0Aj3sULx5{S18a`xeUzjr69kc*
z2B^PvLq*W-@I<IX-62|GBmatFtU*RRQm04fqD;^h?%+qo`jGCFY=cn|(M|+7Rp9-5
zxq5@@077j)K-fx*az&6ZJeV6+D{_O=W=6PVqbOh3xo$g{p!X2}HzB5Oph6s`4t-GN
zk>OH@>o1hnSX@LDAE($?<9<aBx%s;n3R|%Z1;`i;QP^INmG4l+9asAcLKS>(G4zC6
z(vL14EqJkeiH-*xD?vtu=4unLescL~Icn+S<kxt*yASy?4TLV7wLjk~r8e;!Y>HUM
zKJQUo<mud}BPE!?mppW-;gsCA%nZ{b_G4Wcgdt^87+VF`96^jd$kL4o2eezj6^cG9
zd?c5M=`@HP&HzKOHJuw1Vw*v*Tc(dL242UU5D7G}cs?9@)RIFOtPBQF(E|?BU|h9#
zNw9kz@Uf1Q@kF>Gi(APkx<?L-8)zgL6!L0a`2Z@2_RUn+o@YX4NMoHkR0t%hR{nzS
zZ`u1S3`As4%7xPK<n6yCf-{32peFOuw=d9>t*RjIzd58l9zr>J4K~89r(+u)#`p6x
z+cS}a5HC0IByib1ZM_|UUFYo(@x~Zxa#;`@M3jUYH#hY|I&&z{`%G3)kfcVh*traj
z`5FHWMmN&C($G3^r;TbTv`+$#pu<uUvmaAc;o|VD-i6Iw@EJ7A+;OtC)gKPbTTqj0
zpukn)@(v~oXG84a?;8#y-rJJFvDVNSW!%u9{;A?mFAWAmdMGL2!~@z|qc#W)eJ}F{
zVk-cT&rDQ;O=MR06)N<L8SctiT}zcJWkpkufR0=>>*4cBXp}4@rZsQ!tD|zksHtRP
zCpN!;w)57F6@9`#jcX-LRM<9u%}vqDpN}H0(IUzsNypmIQfyL4SXTqMong!+XvF$a
z6#6)>e{*YzoIL|T6_#LK`tO1n*<zG%X!xj%2q^3w5{+smXd>R;hfjXpwKZmZ2eEJ7
z-^us7B2!)RMZf<rX+5o){N><T(pX;6TbPdU(%dP?tOMyY;38ON!HA+^%T#VrvQVuN
zqF1jKOg=8uo;)K>;SYXtU0QF&hA-t#5y}9kHTORk!)b27AG`=@eazRyw@3=i{60=7
z)W^HLr2K_U6cTl!2qT=K9sDAdes_%con}NA+qC&WWaI_NcS^6v69M8ykNQ4F?MF!0
zYC|LFUu;Hth$QNpwHBcNenZP7HlrB!Q%yc?ceF_2%1tZcg^3xdT2!S9oe=EZ@^lCu
zHYA-h2}x1{xU$LX@~RvZ&(5n}c=NB=gZl71jhFk3)aZ>LZcj6zd-X)Gg1Db?pOgYG
zRHOJ}-SV^kZpooZy^;;-bM?VYr*r@vBm?zU8+Ht`8Lufzy!8T5Q>;xcjEjTlPuk;N
z11*`mCN|md7RK86(^8@_(}>dqxFKmv%X%J)y<2GkBvHCgL?I07ATq&e1oe^3imEeu
zd7*E7A10!}70&|#WB5UA3c$1e);H)+Tiv1bC;SvS1_duB#qIvWU_Dogn3Gyf_GZZ}
zJF?cU)>k(X{Vv0*n=y5<A|QJOQIkjP8Yb_d52OQyaFJ9P*G0?VaNg{hyP(KbMy(hV
zz45^S;_JTs=mM51>XGBv3XE9`H{Oc+GZ#7|EjAHRu%KLgYV3}U{*XN;BCCGsN_0LX
zO#wvptG_Y@aCKE9|7gJku~3)KH0}y9?{*A=7l`JQCy*&P?h|^XGXrb#_!2pkMS)rx
z!Whg23n8Q!qi6_uzbQP0P@;@6nJu~X({6A8$>-!yJzo^aq@bA%D-CBez_fG3AZ#hs
zi&P{huVWroR;o0brZXai{#H`s<e(>@+^ElT|EH~YjM5}%_I=xYx~HeDY1_7~Y1_uM
z?S9&}ZQHhO+vc==W}kEK-tRr@W__qtE2FZia%I$qjELV~6GSj`34RDP(xs$PxvXT?
z{+v<*x|N<z;hp+-QglIJ#2o4c<UYcv!fVI!qtk#>-B^Ozm_2(GOCWLrN<aW)!EYq~
z^skRAHAMvAt0=i^<rxm_?A$yWLmrg2yeTOwgnz9gAveYi8e~aje<H#x4xo=gE%Rf%
zYgCl^5$#|VRjL&h%2jD$hwBe@r*%X(WUP?VChe6||4jy@M9+Rk$)pjETkmQK8cGYe
zAE;4LUoysUw1)j59{dj#BX7O$5Su9p^G6C_)uU=4PGB%>?#qf?(JBg2Xvv~-4b!J<
zhvWNO#uhXNDs4x<F8mra1D0;m@lfYafa6p2;V<~FtNynK81TFC$9HYLV<Eh5IxQr~
zd_8}u*WRk+H@2#i;s6=9o_5}AbZ@Yrt&WSOpqUIh5bN%vxX5b#=h!5UaPj_mn(p~w
zD1kVjjA)AlNSyQaUuMCFEz)iT3qWv+mbtT}ZY(4LhHKTKp%WuD=y(h$%DLEjvf@+^
zJdx3<S^8$QR?pH!&1f=acyAse$-*MkefZp!KC%2Bl8v{aeSufr4QubOJ<&5y1Wlto
zfLw!4SOeD{%z$Qmx^ZUt=r<XvSj_lkQga4y%qi9w2`PHI+V`MHZ>rUh|6}vK@253E
zELhto=(`_CZr_vbj?d##pPHUG>B#U_AYqkOxp}ADJc0aZ&oCoFV5jz<78LtwKb7e`
z#r|dZ-`sJ~kx@b+Fg^x4up~)eSp2spgyGwN#{aFdryU);8oF9jeD!_C{t@Qb#K2&n
zxZ67VDEg{;P3yZ2`LRFO_2k!1OBJ!@QG+W^xnDDgi)gHB1Abh}yb)M!6sPN{Z?N<j
z3I#&tY!NsbLM$fMzF@<p@ZXnHT3qLu3<I~`EwnIS@rOy@vetqukx0J>0d3)Qg``8j
z1}j+Cu|=*Si!9<vf7o68j~SLY8h#@n+NBHQa$H>v`-@6_0k^y$@>>N4LzyvQUQ^l~
zqOn;*PzrgYmp+C);(^DK%K(AijQCTH6XRm=k`|s8((bv-Zs^bJl^qvuo6P{bVT5Sq
zIx=F_<9Avr1{jJyLP|LXsPmRqW^@P>h`UYVzbd*`al3nt!<X;urWkB)d7hU*tvO>&
z<=UDU7<#ipKH5LOSdZnE`c`gMP<r>)qF}hfbSl^qf5^+xv4?fz%oE8E9NS5(oz__3
z&Re1&J@vxs|7!UY!Yq(d+o3Qz)$D;$fXai{i^RTIPeQjy?pM+dE-{N{XJv&B)ns)F
zvCl-HV>5Rns%5u(;uT$!3K$m$9(L|FSl$pXp(=j%X<-!J0tT6g)|piS2=YJlMI}Ot
z&*0<kXsihRdo28f2pR{ZuNLUBk(d9VbAxLNQWzUZf<q!tiV%00Rn6M8M58<PTG{WX
z*vR{#BPBuZhKu_{60ghiIyYo;>C$NvUV`?dEW=C}ZEO98%qOJp52n@uj=q;H1(N{;
zM5|e@x!2`;8Is62(L)!3u{Q!K)=#L@XnrOiZZUDl21Oj4nzqOSaovj>0OYax{=<?#
zp62X0E43qrD&C|)<SecO+*sT1VW>a&JBC;hT~Oky>zq9*64MRMElcM({2%dF7OR3K
z|JF{$QJh1c*|B_i+$`e)&k&@3e^PB|k1Xwb<yOvaNw!rk%wN!1k=n^LbH&<7{c67R
z+Dr0^q$k3oC~~4fSi5mpEMsqYqJw*~YVlljiET9);J`geX0IL1or=2$=tK~Q$_^7o
z6x!=%79BP@VFG>z#N$<{OXx+6FbfC#+^3Tm`WKitj{oz8!+@<1BpRGTK=?psAy$Mz
zQe_$x{+XS8jP|74hic?%Ku2xvC-`)gA+;t(3<%u{*AGs&iB>o#vP3(>5M2-t`*>8_
z7R6<lC$2O>r|1u%`<zbzb3H90bu-%$bAsrc&=4r@x6^=WiW_PY1cTclpUP<DW#k!*
zA>=;vbh*kiNm053@~rs4zp!LuM8OwE0go)sKeeDSU}OlH=mhqrnU@Nw5~`Lj(YNEE
zFQBp10<A0(sJ7e0U7sfX>76gCb>g5>wkgC8LnxV_=36P^Tn_5XN<gk?O(7W?-ohRh
z`%g@T;5{l)lA3+Qh=SKGu+0u6u(B`FkHgSj+Rs_&O@=~&5YLiV?=O4?jIwNbXb*_@
zzj>X}f;9jE;<_JiIPCd3t6R81Ipr2wmoEd?Rt76<RGogZ*5OK`!TxJTKOGpYoGKPn
z`3?8q;2XLF|JqU9;3foDuL}^FVCM}cc@<9lyyVRZ_3yY;h{YOg=^*D=t_)+HBWCb;
z_@zujhoEc?d=w)aK}#q`jTc{HW80b-zWm`^=kmUKK2E(mC)jYuF0Mbw5#6kH!Q$iS
z&ZQCmz7w;}2=Ry@Tw^kUxMSmJMcmzoXW$njt;Mk%7Bj|4UGJTo2``pueTnG~*X~GB
zYi%pX<T#-Xv#psRDVU?dgdAX|l+eXH78(xDetEM99A2lST}<Lik?m>ec(m_OnPD48
z1^cT`>a?<LabQXJwsl{5p;^L&Phd#JMU6-EQ*MJEeHORZ*?qYZMMu33)QIa?HO+yi
zESX6B_qwOKG%-O)t6L1t)dhQ~k-@K`3Nu(iR-Sy$Sw;bkekVY?3L;l7BD;0RjgxVs
z;#=(%&?I2V{0=nQcLgc~<K8XTK#yPFtpqzJd$<brBaSGt)|o7B3w(<E*SE)u*Xj$i
zW)^aB@-uD{yZ)RZELpwra^(Pot%rIek`f8`VZyAs%(<Y(i(NgXe0NpBFqSwrY$RRr
zTPlX9oVak}p5fiVF9h#rp{NNqYtvdiHOhr?pwxD=&A)mbBt?V9N!{wwAd1JhQu7Ve
z6>IxxmptUShg)nH6ys-FzPb%T`$c&;%UBrFI?tfLc2#VjZd1rNqX1A87ViimKpq-c
zvh7k&#Q~;%=x`zm;pD3H;-9V-7G<YcG1eGX#T|N+P3!6oVsT=YMSrG|OT-r+vsqkM
z;EXWC6V@d(Tl*7vW0$aP{_n88zw_JU*Q4ma=V8h4)~hs-^R^&VJT%ut5}_%g>(60!
z;APhQsZcCy=`;r?N*8`dqS=qr7(HKQS0ZOxYgB=%&4!YPst=B@2TFU~|4A1Pp-D1&
zVuLs@zB2^j0__pd5A>a(tWzpQ*eGB^16KDuWC>`f`Li3P=&{(r<y7?hWbAXV@Fb3E
zc~al8&BFwI^0!Hbq;4+Mn}J~6w(U^y#?-bxH-D<;x!ug#qJ>`*u2-?S4n=-!99K4l
zK_srrXDq3=;z8L<Q#Qmx8GD5`_g=|=Qe0m;ux+89zRp<tWsrTHzuy=s6?9RW16}y8
z8@H@+c_qqLF@4F5SHfYUDtNl7e>AD9zwb+w05W_X3FnbNRjqUrE}YP)^u`s~#_GFA
z5GNoH;#w~}^`ShrHz}fz9W*~L`IuScSW=}Jqw^%i<?QegEnhsX8ZKTOy-JX5YX(hj
zTfaV6@xkRC#OE+Upyay6A}BE7fqYlFTLS@%JcL3cn0n)Y&Xb*;kKKHuIl{a)c+z;7
zj>~Rc^K-}h%bXT>7l()AM=cfzamT;+?5Ch~RRc{kZ0#XAzjD49IECJ?7TEc7C11)|
zIL+Q~2NEz~abiYrvI|CD&hDrmSjB%hoeA;@%01l3#l+~b(@w0>Wroby0QbyqtLTC5
zUS7d;#|ao?_dV@Ncd%W~ox;SAN*}e4yBIgJM^SFL<%POEoSfe%*}-%tBbSPFHFL#h
zJ90j|(5Lg)o`n-)e2ypN%j;dPxAttTcweiVVJo=^-&i=$@CA7I+1b9{edR63Gdo_U
za##en6WKhmxcG*MemK`iz_=XY1q?i8FQ0@=IbC6!;Xw+LyN!XKafVPi;d~#w>05V>
zfZ^3C0}rfeixo-~{|_;TObh!JRFWhvtn`!a)a~a6GxwIq-W850))6%jq|3uLKvkkX
zJ_C`W+mYj*4#>V4)aPWbtAV_pG(Ar^1E`UXmEi~rtkF@n-^S?_kekth-mo`V*L-O%
zeSm_wq%kKL^{k)>#7mH^Y@zK!&_gLa`i7;2Bz(*t#qFew^pqRZ!iBD=;gmM0-+?go
zDYPz?iY(i=x9*jc0~M5)IFnd7#hT_2+o;z>oBDt=E3SdtGw{dYNQWc-aA19EbFGq+
zGHM6e`YVMSLV-OeP)+&=JRq>0{R~p#1{my8d+I+FT#@-hx$fu(R*fV$=?tfI=a$Py
z^2p{G@Fo+Vm=IjtI?zL5q4#n`mqc*pD4b@aM2(ISx*w$s%aB_BgIjL<wd6n_Co30C
z7!YbvVCpg-4&nukwg*ykvzr%^v5mr=@IHBsRn8YjHBL|i3^>M^PmHQ^lOMgtQEJ|q
z;+w^FDM<(|Sn{bXXPmPv!l1A-`b29*hc#a|L@=`|U{^chw!)mGefS*|up+S_o)x}G
znd$&GSbn(*P9DpAM~d*1CeaBs&xm9zvH{eXB4ic>3|=Lt^c#gQ2?8`IWQ6*i3?}nX
z0`wHyo24NGc=%qLFmdkl<2nzO4Eav;z1rQ;Iyo!}0z6Nkg@P5A&4$I)S*|)IYYlxq
zF(w23g{Pz`Z-<7C8g~D_lSRWip8k!9PxLQ%;Q*74sVGTfO)BnSYu>*i7{be5BD<HQ
zp6+o9z@h(2Y7kq3m=?^RD<R9s19jZ`sZRrD(z7Wlp!csr>k<_`hw~rdD2)|Z*DJTP
z#n)8}b6N9;N?!>xae581c@ASQWGL&9psn-kn1MdA)z7KZkk}1677U3I)XhGn^R5q|
zT1+CRh~RL{u3?MD2kUfO1MVgRYCIx@y&xMJS;qqDTzUNryikOF$jPV8kw8g!7P`@J
zsz&lVU{&p70pi2~%P>F@p1LL-uaM~#0F}yW0k5U-=YG&rJ3KlY4@lh~PGl(`aXmm#
z>1)QA0Etj;Nz#Rey5JO#hb`H%ppRKVY{S`5eT3a4U8QNrEx}wD(|FG3#D(5$kW_&1
zZQkB7_@@Uqa<>H2oL#-d$bT0F+vZ<>f<H3^u#pP8E%%1(#E*sb473OSMSBXx(mUw;
zqI|DU64=tdnM0Q3L-n<$^UkmTBA;gahY|LBESUJ(s==??tu*k|MI<3TP|n6MKU#QJ
zQ<IvUxlCZrC1^}_9zXcAJ!^t~AY@fMorrgRRmmfpa7XSw&QCdgmx2(!eSUA7jhLVa
zn0R7pv_}|HgJwxndg3g`W!hfVWJ$%y*ryLdhfaT|f{&TWQhS<PC=@Q&7;%IeRBYrO
zGn|@WlmxDadRk0)MJAskMsS?XnaXXZAHB5ugYU_a+~Fx@YPFg5kF^5Xtr=q!Jl@aZ
zur|uVtAE>12)|GW&6A_ebAc6vnF@@Gz!EfQ!gnEmV18XDFE67EtwbmiZ=g@%!-jC=
zGb#cpN5Z1#jX#vbKp1zGtC+Lg7r*S^UV7)oC^qe{lcO1PXnk`!^!iuA+VfsODo;M5
zxn03Jc*2*2BDLi0K(<TU`-k6@SYmSe`%!PDFGqoYk~%^$<Vg|>>5uY$=!qpepuzg+
z=`evQy^60TqZ^3SHu#6}zW_9cNV7dj1IRBkH<D<HgK<7<8OMfmtn=lctNN|5_xQ$N
z(*aYfR~Cmk{u(ZS4m$3`&5$c_xAX|8Kh+H(6ZizMJWOx}G<5AbN|g(nIXu*cJUW#{
zcrI+j%`bYU;1cAVmF+Qly>qs`fW_adv+C=m_CkzVdN?#IJqfNEjxSRs{2=YpOP~3M
za&GeP;PqLE!_l`L$pS3MA<nk9hR%5X;EZ=GLf3l8KW?JIFA)dWGB4WF#!{9+UhoVy
z9@(rP-%w(nuTv8{j6jg43rziPE_iw;B{_zoT7XoNo$BKW-h~HC*DZ>tz#O`{5iBTv
z_#>?@ILknKhMuK*Krn>80OK#2rHg+tk^N6^m$8|_H$zAD?;1Og_@lm`O$KA?dEg^W
zV-5EhN7Qr}KO<HbN`a}bPs_|NMlmfX{y*m0arO<f0tXI$RLxN<b_wHrz7B6XE}?MX
zn-^N@xW~{bMLxt)v5%5k0V(GFaNGkzxbZJcK9w@%JWEhmre`dpg_fFiYegJdnQa*b
zL-$m1*j>`w!o2aH9~dTh^vnZzv(Cf(lKgoTp2LemOTWjd3m4j&V?50&8Q;m>&8|)V
z#58{TXxtCp{CwT9kliB1mG#p<fazt!J*$et;rC7E9q=IT*3ql`2@D?QEh!RVO7bKx
zjl3+fi!oZY-i0p1xY<hpV5AWV%+Y3c6%x{`ZkS|&KMx-3U!?OgHVL_aDiG?TYgK}q
z^Rrzzv@CSq{Jg?l!HYI)o$AA-oBb5uIA4J@)gkhqGj8!zYDY_k*sKy$sQ;0INjiS*
zQfqRK9ra=C8v<Bo`4@j~{&RYP80D96XDaW6-f<|nil=%j5afcm4%Z#Hb*rI0{Stn-
z97npwbdzMj69cdrKH4YRw6QCX$49oK*)X_pc5HBY*rX2yxCpnHI~q*yAZOhYIqr*B
z{yyi>EVXFFh@8rk;#^Jvm-SUQRe%D89MZ&LEB4{V)mAcG2g0&!SVi!^xzkZh$$^H6
z!RG*XL%PGFBFU1c1L|oT5IyUupr~%dcHImGMR^I}0~9v?fv9G)YsRRc_C6G%wu8Bu
zw<|6P+JEO8e2W?G(H`Qhf~&v*+8**jVi6!UgBY_S5G-!wTo4vJ1l+;%h(r$!n9{xd
z2C`#(JaA6jfR-uZ`OA0oxTFqUsT9Bc;Dd27VK|TuVjj0Q@C83hX`z1biJkP+joktW
z!}rC~SvydUrfi^H{E4lZ9x{n|Mo;q9eBvFilNtwQ-98Yu9OwHUT+Ya_uCT_Ab5A+T
zw^}&iR6Hf5+x&*SAU*Hw5x+8FX$+q`cs27>e9c7VfF;t})qWcv6I`D6xcrnM7>Ykx
ziZg+6YB+BJQ8VHeuuzuo9bBYH*wTrNIEi2-U9=U}!Nt1I_xp%NG34!64bx$#Fftcp
zr6{VIaJE+$ew?LPx19htos!skKz4)&#sw7K!Jm%iw(~niEVe}Wv1NU!*jhz15%xt*
zW(BQ9APaTFvUzJfzhCSa!w8?21Ef68>;|qvCJ(w+f7-8nW+_CZC4o$pG9JO5q)lGo
zHa+~lj2J9Rh6E}nYlyQpM?ReKF@IEl`waAmCQKNsj^^YK`ix{d`70weSR>R)(>J!x
zX|gO33DKy+A5fI{MOEz`nrWGaC|9$J3#vvIz-iWCR$_w-lM&KwdZ_Ti!Ul`(y<9PF
z?5p;UVWfd$Xx!qX>@s1U5ne@4+#@v~ez5J>HSIS{I)SIrsyb=BQ}IN<HN#3Y%|i;|
z-MTw!V>X#Cy?1OPIZgp1hU{>Gf5gH%mXU@^nE`-?!e19%pZjj?DQa(v-~}f1Aw)kZ
zprY_(bmkM-zjCAmM@kG12a|}!bTwv<`HZ9JlkC3Y=pj*`Id-@Vl}jx*4cv`?@j(c_
z2XONAj=BhkSC_gvo{6o_r(dC8%l~ST9ZxwzGhScR<TN8E@hl(o7df40etDWq^`QCY
zK1gH8Ig^)+y#NY&(;Y`MI$T|!z?ImXfJ-GlremqG(0MMS#^hnYCcmGk`WR=yC20?I
zYwUg6>c3soM4U4gN`4UJ*k4zf@x5I6hDj901-miOQ{tvCVV(Bo2Sw@`ldG4L)|nZ5
zP?VBv!R4)mwriMKV!ACvmTBj6<+{Al-`*2a8H1E!6`44_XR(DU(6}t`j^=`i0lA01
z{zf<l@H;thN6{>@8&YLA_U1+v4y@!5zUEiNWe!+}kTXxtLv{zi%`Qx!lCH6U`BKTH
zD6a<`h9U`#bYEbqMy`#a1F*-+aj3+6#Mp<lpqVPMnsP-|j)a^t_>1<KcCs~!L#4Bc
zM=2f?aJo3vxE4t;Q&!EQCal~ofyL&nSJjhtp6I#nE7jXAWw@2!L7#HE_D$nc6j#bK
zkj1sK6IXb04JeOzeYr`|W5H|C9VrUf+!<uJTy`|qd@p8C0XC495-Coq_FKEivw^}A
z^cW!`BhkCa1cPd_jC;sQV>|+&9P_=M)4L{nA))rVeYz$WtLh3N*<q^QKuKfRJ`sB$
z>Vi`4I>J-KE1MVSPGBxa&Loy;?UFU511HHmTm?FK7DzCvTLDc98%Vq@0QJ2_t83vl
z+}R_FcBH#Y+NBCfP2QapRDl$>pM$}DYBwm48x_)-SK^gxXOsynEpc3z7cKG<;Rm=O
z*qvG{2$xruqRtK5I8@vKaCpd?81THw&dJNOurPsNb4=*_<}X1{1Mg?Ej<f|x1BYab
z$Yu>}bjy!Kn0s%Msp7YjS1)WOXXL?r^Q}jc(CM6!!p|6y2m(mOD_r#qv#2_Ylg^?>
zR`&%3#E(`;pF}l-Z<DVE)Nh6|+lcMHo*5?3E5JE<-*n`3U8|@Av)iYVG2MFt_o^7n
zaOMPLLHwbx1B42h&&9v0#)x$qU%q*D;r%_3(d-9IpTPaMxRvU)bqSOh<Zu}rq8U?$
zSUEH2=$9VQC3d$q4>iBW&}Tq<UP$N)i%1ZV=md?)MIBvuq&OhZj3B>M6Jvj}YRgQV
z6XfQ-63TQ1B$C_!{|u9e!f5|PJ7C}WgL`(x1Ypu$8DnTYL=lKchbINB>7}l~?m@V0
zg`FI<@P48GB!pHsizc<?<j<geam7x8!c!Qai4R2U<CulSC8HXE8~KG{kr>uOjt*~5
zky1H%Y&CvEW-Y-CdhzEA_>9RSIvfu*60n|`FPVk;h;-HkG^7avvxr?#xxKm6cB*{E
zKXuhc5}R8U6*}f%h@Xca5HJyIXJ~8Fzam+~4&z-77|QQ$GjgEB1)W@i=Rz7WhykpP
zCX)Omofor;g9OJZ8ouTl9{wAZU5`?Er}3A371_<D&?{Ae)TUzWmp%7#a6f{Hz@&xd
z@oCE<1$2%(@cB_{Rjz|L{APksZlNOVU!tas&b=K)&+%09#MW&bgH)wpcFIWgbL%1g
zYRHE$FV)oReNOtVzjWGppMH$bVFwO=NG)sRPjba1Y{5?TOh;m=3n#hobbcpJ+cs)9
zt!9eA1Q$>X3-4IILP}dAT4mj)<wLNqxXN)=it0x=;AUC)DI5jiJv0_)vj_YPih^fS
z;BHbZ<6{*1YI1F7RTjiGQWegUk)~b9lc46+#Srf!5-w*d8O8WTfFs~D{iBFt4ZCvV
zL|)%(^uvXp|I2r!zg5#l?P7a}qe7eY3djsC$RYUsOaZNHx)q~WD-xdA6mNX=2N@?l
zIOll+h-?9u(N&fTBd#mh?>9UJgKBO6F!HZv=Gt<T=j{~7|B&bVIz}#=ev8z$@?G<A
z%#dKy`}L5t(j%?M%$+TLHYv_Emzn#XHTm4KYK{|5j9}DmeE_gM5P>4s#a~0!44-C%
zjT=DT|Ai5XaUPWtLgGUoA2VPNt`>9#w(6?^tl}M=7T1;Y>~!PK0X215CJy4D+kNNX
z{^k?t+5lLH$qs_3aT0H(RU)!m5wL{kY5odfQ9UlgNca|WZTdMsI{fBpvpH28F2m$(
zi4Z3vyXrf_?%j2t)Oir07Ahbx4~9_tOmhZbRw=v}x_&Q6OXWN0UQCgmZlB33zMMw}
zwC^!|0GHD>ofj(i4ooZov`f$z0V2z)n4Hnka53GK&ayl9`tOHfD8S4f<TITCqXBin
z%hAg&;wd24=Coka>KHOBL^nEio9n1!LMa4|zeJV=T%|#lK}xI^9|QlT&_BHrhoB>4
zdB0m8>oQilELx<Y(`6rOZKq<@8Ev%yy-J@SvcpSG9%86f=_(j&9N<Z}2naE)6r3c|
zl`H%O_$9%|1vw(-m9M~gci6kFr~G>ExtEb$QED;mDif_i)1#wF_}W<wTzH*SWgu-R
zCV;c#?^qokP`;cos^I>4xmH%W1%tM=CFi9^mOjVB>ix=)$fDG4IC-)u4vE=7m}Sth
zfXHx1G5hC+Mv+awS5ydj2zdcukDr_P5JD-Tl5*cuWMA*7Jv1l>Q#=c1=yu0;3~ELd
zTg0LIB(+QCm0DZMY!m@VpdisUr#x3L-8A9(a+*jA=GO;EfK+R(GiFCp4395j=BF-K
zU3wn~?ttp~EAQ8`psUu47OV_VJf__mMNH3G$13ii7YkCi7&GR<%H1YC8IIuvY$VXS
zoAyqi6wp#U%BRucycGz(Q3zh1qVK~)^p<`FrAXCm460O?zB1Y{W#?+#+Vpt1SZK$e
z&QI<rK%512e%_)}UJ45l&pHT>%6L;9%f)(qmdn}4P+*hTR47|c=|2wCQg=eyLBL*y
zG!hn$x81RQdT5?5NP!fSq5i7sh=s0IQ3><^WFS}8RF}j78?fFKimQK5`e+nV@4aWi
z`y*IEcP!pRA7|hfx8c;nAm&Jp)BH<_fM0N#k|wr~S;zR&e6mYOTnR!^ha!UvGT=ke
zvkwLH(G7ea^ZNLJ0~G*#t$!xB3$o%R`zw$iaBRwzcG1{z15S3AdXedC<4`GzY7{*y
z3j{4?_v9TE>23$HlRe09#o^N|d%g8@^V4_+0f8BuqDEtt#T;V<`=bW1S?!X9Yu~ya
z!36tP`v@N$%q%a1gwzbJih@~#+}&{hyYH65FNa{7LE-5hd`1*_faYJQn8AFkT+BpE
zY>ui{g8$+(9!pTpEebq_Tr(bOP1@zLn4^PmlYE3jFfWrjRbhqU>Uug7>m?Bcfv_Nh
zzq(T7t16A#v-ON5@O*nm4`Po$6{m>cb)q?daVK$MZxLBFV|M3i4F$(FRh+s+bBRDt
zr?MI3m4}80NCg6YBuap<8IW8Xqg@j-mlxLQ$30_&eqfv@6K6aMAar3TQTN^+OP<DE
zx0|wAZF>FOXq_VJK9tVN2BsQBZIzonQ?vlbky(~&1f^QPq(4o%;T=wXIG|rDn65GT
zPWeN|>T?n3?~+FH`V}4YJs8ipU9w@rJa)O1u@C}p{eOTX3fjcz8al@~9WlNc1bTtf
zTA{S%hQDm2nr>Rf_($Wj8-HWYqE@~ii*f5UCCDV6#yc4<AY2j-GYP_oqQtBq18-WE
z{{)XhW6dBQ_CZU0%D5v<?o90MiW#w6QlcB3Tst(IBc2d<^UQ%{xn;U$+u*|)P(V*H
z)nGCFsYL}2u-bA@;?#vgTZR^bV_l#HB<GZemM)RfPL+pIZ?Y@&v9)Is7P^PyMkoP(
zGe(|Phv>xIqR+YY;!Dm&fxq=RS=Qh22|D}9unV3$#@j@DXpK$v`gyIY*t1YqGV<ZU
zTdpo_79fg#oQKk=hmO`Gi+?GFHWw7%8K`B`2@(QxJu$&SW#lR}|K$mw;(wV>K*$3$
z^wp&*^@Ak|R>nEUUl^G*-V18p`)5*)FQKaRcEF)vv5Xd=8kxhErX|R|4hs#q@}hF{
zbA-TcV>)5~%38U>Stiis^9>IzYNgSPHz>5_O|xmiN@LvTSsZ0;yMT$(8q~!@967W^
zj&B1+kxHGP`))j=*1gYo`PbE>tyXE)o^eN|AeTJ!Xt5WN9fljycC#n^M;Cgx4t!Bu
z6ry=7rKq_+nCNVnE3=oKR(c&xNvyK0ICowpoV0zFrp_6zmO>vG;Q|A|6puTKXja2?
zpY0redrrRWMtG1~ETQ)dKC0$udtAsWr~-g<fpRIK#B&`28CCF5`-6LP3d{K)kSv7y
zswY`|Hg*bqAoz(B7)M+kW!*@wM`OExXOlFU*K(=fO5_EQ-9Y@JOLZ88aUV^hDo^%a
zhe5fhyK`E7eAW7++NT!px|u=rL1OLW()IWCwYs)Z-%y+fT>@{Dct;kHa13QuxYmF#
zJd)Dp1{T**_)5k!e)r0b+jr>@-bL=dK{%xCVemv*Q5P8qyhEIDC#tQebrXM}qRn(g
za3It3TBMP@3<;6w>7Q`EjRG`fTpU-><0}tEG)gW`_#VjMjR_M82;lWv=X6LWK4JBs
z`t>@MN_jRJ()tF+Tpf1))N=k|YiS39#R&g2mTE(*RhrC}16AKG<?2gdycq0S*M6P;
z4d#-7Bo<0X9#Zwja*5=d=R-=@WA;*39YQ5jypxwyJ<S%mM*dqSKusxn*(@*pAW0qy
zF>a%%!|Y;zl+<uKcN0>Vs&3YWM=SIM(WkP3=JIOSk#Dm9NPS(`_jdmQn@bn?lh0H;
za0|s$VoktNCQPAPpKH?>brH^P94t><UtNQS7$W>G;!-jP(_fk}B`B+#zL(`1UkU7{
z$N)OX0ZzLz=9B<05C(ogXd+*KjImzekyNJiS+Vc~L|CMNYI$BP7gUC+AVSp5F6~r&
zS0+K6{$0rg|4Ly^z6J)x5A6XsYJS}|hgECHAgsDrm$x#yBI_g-he#@tE~49!W1Y1)
zcN<@fsV$97@di0M5y_|2hAT~8bQn%Q>p(~kIo#!K1}5&&7|Im*NJy&ODt9c+LMgDB
zH|)WN7iH^XyHAFl<iz>X=Vw9*air7=PF7;<q>=eqr0~OGA70QsVh;jnLK4g<dzn9Y
zIm>k1xOeILy%>YjHRYM)xw&BtK1I@-M{!miYo0o~$?wEUHizIWc=vogGv-Jt>A+ES
zW9_rCS!XIgLhDsZ$57=S%7=!rB)AAwGPu<z(XyO4nKdtETEr((Whp-ff12+{3y~U_
z7rU=fuQR&kRYtJ9E*b;0XoMIOl++YJ0`$D2huMPba&2tC4s~1j<k6N+y4nWy<=$EE
z)<Rx&kePE_TeLtl-d1P@b)%k>+-A;sDR`vk75k;m*2dQD!AVG+MSv!dJoVFYuL&<c
zKMv9QAg+I^Pf%=lgm~un)tSRzPK7)rK=LX9p+!62!V_M$Ti$_vBinBGJAK8%wil`e
z8P|4qz~C)Zj0XmSQ5Gr$b2(9z3D=lx!*XU1jzL2HE)gNGd4)p*JGV8BQ6^(_sfXtu
zQ->}sEzz^dJ+VUFt3@Wqj>?Wy^ef=BbrGcbA(6+oUxuQAissq{0wA1Zn(POX&);hu
z$-g+GiQUM1f$G3hLl}k>S3Ivc$h2TW%w`C60;g0R#4)r^?*2(c*o%u_KQ+>lmUKQf
z`AFp3VYPp|I`cLV5feGr4X|x;MlCmcP?D6#{YyZg#Z4OR^%xysUiT!x<%>ROpec|5
zr54LqhoY^FxwdW9Q86Pp-^CoE32FHZK@)<$6XbdDO8Emkt$S3oI4~@$nC})ZrF29T
zgpW20Q!1JUWq`7Hz2L@z*#|Y`PnH&T92xl-(b$3ie3Ls~iIA04)a~52-~py~k%55|
z$c`h^MTG6B%Sy-hldxCe?0Sf03_Wfcp;*%oZ9wnJr8h*oPUiASkG8L2M_Qb>tH%Tl
z1T?F|dkO<}<}}KYDR*rMEB{VV3RIVQO*T8VS(to)ZEMNZx`$*CIUnj+QK&XN+xGEy
z)%m<$NYS8tI$kH&-I^bGp<`LI`ZJZlOZ(L9X$uf}vk5Aie5bLvzB60aY~uEHCpEDB
zR9`FGZ>;4e_l<eEzx^B4MMFRxU<sN>Xt_0T!Z!-sfT-8MRgbW69o&9jKkTzf*bUc_
z4S1A@y8s)%biBq}KDq|1`_CcDJfn8nd3lTlr7?NB>LA^-+Sl-+hpA1&RUi?3j^+*q
zxm04Ip9WG1&Xoqp!sZeAf(6ek;n^19)Rhknw++!>HG1QIY93e=*>>06QNSVT{|%-L
z6#fK$?C2<}O?X@5{8~kKjKj^mp`rW@3&FEv5^^pU6jv6!h{T5+Pc{V*ngA043s|-)
zp}%mTqCY+j*b6lgP-e-#+zR=k4MSlsRBv5^?j_+f-Q~PPgI-eYFa#DrtAvYl0s45(
zK1HZI;sQ8&hBS|1s49>sVUVQ88F}Z|=;(m78oUfmDqt_Uj_;gr0b~(y2jdu*(F|sE
zT4<*3&U%?YR6D`{&Ty`z)+NOdJLom**f5rBH&A%mR!6SDuG?IlHrEd_oa<<7;A~O)
zwLiTLl51E7aB?%-r(?vm4YiIjHmnd|$=l=yCLD)#HJt#{NYRa+lVsn^c9**|ZT<pV
z7(zi{s*|)6<uhYdIy3dQejzz##3`7%gFFlmdSL*VgIp&*V&f_E;g*xrQU>o^+RV_Y
z?J(yJ^~%xHf0+An28lAa=B{}A?YJj6_>H6vGEGX3)uEVW6xPn>pQ<C-lTAt}=%rR4
zU<=sS+mAB+5V3!i$zdE!cNi<IGv5J{-cKN89qgEfK+rJvV$|TTOmE*(WLYn3i_=_p
z*mP2E7o3c*Ej&1YSp&9wCK|MHI3elcf=VsG_5t)~_4Lsn{(Gx`MHQn}nZjeAQ#Hh9
zS*ET=g!%@=HcUhY$)Cfi0htabkzPL>n~+q(=_3(*_Aj=djW&Y>4W2RVr(S^lgGsDa
zLt_yG6EG7^^i%u^JY~$O$XoD?93zd^2mxq?z?m>B(B$UFVZ7|z$+@KOrc~|C55v2N
zzjKQZagbliGrKb{^o?io_pPeUCc-#C5;NsS6qXE*yLhu!zc~71a`6x3AIkdX?u_Mj
zjM*)ABnE~-IF#MSXFSm%uLi(dhMOwN@O_R_+G?5XLYGW~H!05f+UOhtqoidb#vM{M
zVR>zMSYUZ)Kl);vNqB&)&Q7#!%}ABik+eAj3ScDWG5%cd{#MQYS%FX=9(_dT$dnUG
z4y^}QR)KgxF<8CJ2ye6MhpiZ0_;UrD@id6}6`<5STds9~pP4=Fofyc%jp{EBi}cq2
zDS$}9N#9496f1lt2Ft1RNb<!R>cQdRcowDB(Nare<c68VK2Lw)a&gSWvolq=M$$s?
z`%YD-+7?11J75Xivq|hqrBla$Cuu&>e(aY?ZS7te<p90bj#m`}i@2Yj8>0MAVY{>v
zwSjaD5iX`v%!_%i95mo1_vsVl2KLIXEjHvk;9{L8IhWw#RFps~eK0W&RxY5z-;g%<
z%@FE=IdBVaS=_2(8r53+;eO00XSzA;Y(j!Pya6L8=MVHzcLsu>r)Tj-O)07r=%^t1
zu?XhzUhiWc#n<U#Hv0?+sFqiAf#D>${EkQ~L~W-sgi;MASrxEhEkLI1yy1oNg2jas
za(RL|5~H8PRKr|C^o#4nN45sydovOBxQ!4VNijAf`%gSOpMQiSK~+|tugPpHc~?pX
zR1>4GX##+_-!ZnB8$V?m8Ztm(m?SGdQxKO?S4pM(<YjOnKgiY!<Vgz0_Xy*Rz=2k+
z`ik|JMz!0i+$~VK1KQ3j1cx4U>)qAU7%XWoZPKsu4E66+O<9*9SW1f|+^mNjes+1s
zM8u695+BYoE<9Ws5A(<Hw=+leSCYG7HQ_gYABAH8VCH8P2b&Pc6&~godO^g-UhLm=
z)EImnjRV_xNq96gt`tP>cQXt<Gh5w!qdTVuj%?+&QzGEra!z_!f5i6(Mc}KPlRTNM
z;)gUmw%#fEn$*o*!G&zXDBsp5=Gr-WCrcL*k=C+zLa0=?-PFkF`_fX%Y;Hm%WSz?1
z9>!xQP&;{O;?eCTNtOHN?_EJk3I^Mkc1R{m(N2zzmz-XBE_eHwk&V&_=RBEgtQB15
z&~ILUhFoAY!qC<bZ}_7Dt2Dms{pqg=U-6UHc{evhd7|=22{S*L1iR8Kpo^hG7gWV5
z{68LJ1-H#PDlM@lHeDU?h*bkw<-2i+??Vqd=)2!yRb;RDgz71&@~;}I{I3r7C6$p5
zT`wbNFQkD_-lewBx?!l{{atdUzXGh;=a2g>9#BA2zR7ZZ3Ag@1F*jxG>OYRX{1Kv}
z8gPbFIiWa*`R#Q629I!^LPZr-NA&4zX>EvX-hE0U!`eIk0!Ffi^VLUly)q%1@A=JU
zp%FDvn4Z7%8fzD+hEWGdIZxB~BssG;jV9D}GvdQxrI&<SzDK-sbbk#EHi@)@=Q=_L
zs6qifssnuMk~mqJ)AB2<O&vkf5!Ks2O#0U3(Zblq;~(%)EXcbLt|2g3b+@arj^i2)
zl2DzmO+o)8uTBfnLB)Dlx6$=8Kdz=84K+3GI<-odQvKu<yo|b1Fg>bq;v$i9u0Kln
zO`Rd2_k7q&1=b>`vtFP2y87t$-Zf;q)m{Tc!l$Y22rru#T|4B{<WS?*rdQ^rnS>kP
z7=gR9FT_vPekP+tOy4qcD#P;yYi>pUk*}A*9><kZyGnZl2dwJ0wM%_yhjBvj`MrWv
zPef|i;xM-8sb6uY%+U6Sy`(+GX4Nj)CLS!Gu-Rb!=YzZqh#8Sxq7-;?JCo??aJ~yL
zSn%6^RU<m&{(@b@JH8DjB7wtHk-9P<fA}8J#;bbEU#3S5X%(UKxx`d{oH1z~qD1&n
zjfrnQmrbA~KxSyQDmYUbT>UCu_Tt!ORYi}z5<fR8)db!c*xKgPYc9W?`!r;iogiV~
z{p*XGXDj&o0hhDx;{D8I--3$W$)*YD#wbMd=T@txW(#mQe)ATEzMq{BsQxThG`Uk+
zKF9mLane@3(9hRFT7Qi;U+?|+$u<B`mPnIqO<Uhq?8N<k6cH0otk%CNW=H?#`78VF
z#fQ7m(;2pR327WcirF?Gel)%Fn}1csPPsCB_*1S|rZ5<7sYwtO|GJ^TVHF%`mELlS
zI9ER;<9=#(Y4S^erlk@Qt7}NubYgz7H;RO^wBx6V@{svoP=CHp;O^fobW9Rsv<Bxt
z!RS*JZ}~)5)b<Wex*e&WYU!KgDHz{mGOPhnj*d+}0i&OAE+{XYYZS=U7cNv<k^7$7
z9f*C0U$iVWuO86%h$?h9&pB2=r|m0HjJkZBK5SnCvZEoA+~A)EDVeO-nVpg=TTB2p
zGpImL9*Qs)e~@F5Cjc?s@8hbYAoX*u^A7KAlpZXO`*#d#b~~}53s9Iu1BPRRrxhlp
zU}6qSQ?tc<y^6x)Qa9?Q9xLLYJ_pK$L<9Y>X78d%`+@MutLh5dX5T4bsTA5YG^O}#
zRjt2C(dMz!`SIU<EgAKn8JJcqw~o+IMsXrCJ_;qGESVF#`UpmSNs|*f^y!gdt18lM
z(f$hgQCZkB^MVdWHQVWd5V84EL_`hHm{y-u1`Wblr1#gcbE=E}*c?CD-`7t~X9;*S
z#Cs415`ob?GRk5II}MpYyZ248-!wg!g5fF^ahJH8xV+S;#1q{MeQ=sxH|ouy-bOG)
z^!jN8yXtl+=MF*y`eMiHiwiQfn*~oP@<#Ha7Ug3<a%(_fk#qtaNA}<=)PFV<G}ve%
za)7|X3qH0(5@@)Z2G*9O5m0Uw=_mJqSTDE`yvuX%wE7uuf{oAtIk^nFt5t-#vokF>
zXW5E`*9kzH2%J3)PkfEteaSu60-9d#U`NFyvMCtadmcHyy-f^8%ffSsj?N>z<<e$W
z0rVG{PWoU2?^Yw$1LWYvWmmNB*o*BBF!qQPrlLyUDcD^Z9sH&t!I>p?%)3|48zu1G
z84{skWkl0l%*B|%=+w^28F%F~xL)HI;_^yeqq{Ve`*SQmnRKtwi`zVXV%`t?)gN+V
zM-yT9t6(iuQ)Lv{^tdusw0?hiIULe!Kzo<MZr<Vd`qG36SNjWV#d^SAanr&&aAb_k
z?mpAQ27tJ+ogx0Qie)u+pvI2_>%%cg651JANsySn;jjrn@2AQWvkcuY^yw!4Trt5b
zBV{4ONRu%0nYrb}%J-7v$SM^Xy3*!m1UD_gQnz{yl9IaLugcUyk!(0X5H0QB{uj2@
z)Vp~@`!l-6m=?)`pixz?1~;*oM&BVtXEm)YrWnaQa3x@?KN{S+12%A@my<5U>KmV$
z?E}h*Y=5i(NA>g7X|t}?@dt4Y$UPEw=xw=Xy0oH229Ywq#LewSu=aWclOui)t|X*?
zmO1<-mhC2QP3p|6#Mr4;H|yva9z7F|i19WsRI3OzgC&2m#O=l?8DOo*5MSefH8xe2
zeeY;t9|`D0xowCyM*kJlAAUY7hYM2ESKhdAyk{E-JYbFvrXU*S9vg9=%V735qlT(Z
zf4;d-MpM`MbraNGm(_?{3DdA^r|sN;Iax*sD%^F&b@20OW-@8IKmsHDmj*9v+lHW)
zj0=l)lD-IWu%JA{*=dM3WT`wM4VCflrt+u}Vgq6b_}+BgJ*pJ8=8}?yPra{ydOiP?
zI6>s46J8ksu$mklLPr18)Vv$u0|`KZUh#U;0}QA`JCHrXqYc(?W=fRSAza51!hHxs
zEwP(6eQcDH+AX%W>o!focZ{4TUk=lxXaA7j=Fsafq|CT)pkf4R`$9HMow~H0T9J`O
z@e7KQqqm@d?4uM6$_kWXmQHh(fMzg&1BnH)s+pUmbrzE0Dmv94uaj6=n#5{gsk3+&
zA*)G_6F3Q+zonvIQKqJpX0F-~5ib!3Hi8R!9T$*km_&KM#^69737<}MCzCJS)5N$2
z<R|$K*^yQwHnT2{)@L!maIwV)*|lNo2cf$jUzdvtFX4s`W3T(TMn8*ug;O`G40Qoq
zM0SJ_gMcMC7b&rL$5cFahf{<uJ;d$1Fki{MV!-wIuT<&>3K!+@_=?1j=JuBMKc4};
zaqt-rOS0oy9}If5c6g9;gYd<=xYhX-Vg1I)UX7B|#~ZhwqRx}|{PyRN?7tW#iV?A6
zLdgZTkNCbBUfKVPlGhL(JOK7zQ;*NzP=c}YZ|Z}fKtNDHU_gy+jpQ9{?HuWioE@EP
ztsC$I0ieLfB<Y9^2GpSEpfBixM{_UIjX1P;fI9-fX<T5Qt{t}CD+|+VY*lLA=@eKq
zuO^X)gJBDS5ms=c8y!vdL+_l5!(bz6Sq8QP8aa24jeg2Uiq8t)Ldt)dGNED|J2Rfy
z<<Q{iY3i`338A@qknR?_I3qs5af$=L?cJ;C{0#Kjc**K-ZgS|hdd{N_S3DR$H;Nh#
z!qrDTH#)KUox$&LShD?c_$GC%s`sztal`Sz-Yh|H|0K6mCrxhbf=Z)W6_zBi<|v*?
zAD)VslA;jAt1l(Sq5DhB|JWflp|^Cs<*U=(W35XGOO>0<KGFXWHNG>K5hJn~lW?jv
z+!;8|Oj@{F6*W#Z`T0rCUY$OZWocH;yHC=&oN&v&0aO(8rer@=9p6JBh0c~oVlmVr
z8`h32cv&D=wAVW~bAtBdUZ47r()>!0E2%g8yv@blkhOAN!P+;Uo<I3XP4O?HaaY<x
zC>0{tQt;ai4qzy1)aQszt{_#k3~4gz&<g}xh%^acA$((FT$zSm*Rv*w5TiOu7qcfc
zuLL#6wkU*^pbUg44ma35U~be4bW7p5i4#4eV|0l^z%*X3r$1J`vb{xah0pKkt+~|8
z-Fy5__5Mfp{yz=~3Pua^|0B{2`CrT7|7i(!VKg}Zts(qRaS8ta?fKv5l7yBpJe>a)
z)cr>;{pa2P(bf}g!+1b16KKQ#?NR-=6ekD>=6~3LfRG_1#G<1mM1-T^{*R*9|7{eD
z{?7<IVL2QL_kZ~0|M8~(d&Dc!1h5EFvi}>U`ae(ep#2}PYC=o|8t(rvBSHVo#ecSS
zh6JAoGTi_ELH+yqpa0np!s?UI8^Mb-;|l`v->zd|XO|Egfhzw0^{xNBEj!>p%>R$4
c{TJX>UK;YB8-joU{vFW&D6rMR|8@1h031p%9{>OV

delta 32431
zcmYhhV{m3&ur?eg6Wg}!Ol;e>ZQgMvwmq?J+qP|U;=FmzIaS~HXIHJgc3<u4-fQ(l
zB1lOZ2!?_*C>Sab1P~Mu5D*a%GUoP{2`~^4W*r782w=vppAmNWCh-|wwOScxmr)ia
zWZ(;zqp%Kg6kC{No-_h3s3jN2Afp&QSYW+K5$FBg&(RoR<YL&2=8r`ujcCtlIIPZ5
zljDO@r+n@MPdpJ-N%9lCR2?wt!Q9i5L;Ej(EOQ=OQCZaMqQUY|F~dDj&h7NqRm%Mp
z&Qw8F7yuh2*Xfg;=@DK)L6#OA6E<JJ3>}@Ry!BTnS-63s3BpG2as?_im^HPi47Ix4
zx6_zAJh*u=W~FQ|&M;#ALjKn4hC%AT@uF}sVRprMJ(U4WC)=Zv*hqvMj3L8#cq#tO
zbm+#K6gc&~UPM95O5oBuQLRWZtd<kL-P}OMVx1y@VcfHi<cmm5AHO5w4o}>fryo_q
zWPA{bE$wa*0D#PUtWyE?7ESDaIt1)zMX<m7&J)f@=<XD}P*H2Y#Lk023l<OS!(qKr
z^zC*?<>0oKpUr~p64oN)Y@3)1ivFufm67D}$M7-@-Jp0N0Qmt%*w7n^kFe2yOIvY>
zLelPn5*<V;e*Ti12u;xiq&QnW6u5{g*g>G;fG)p}@r|wD(dVN?&-<*Ek;te#B+c$s
zp{Z|<u8`E^PAOuJm3xCoZc9%~&*|b)o|JA~vD6i<rTNlhJ0xNYcOrF&GxX}%zfg*B
zL(zHD1GI)^Z8W!yUaEnYgp{wULTg(%^3D@yG65?o#b<E*f4F2W=hM+fosG=bs(nUn
zh@M`tRh2EcENhK&oVbZS^-XMgA4D>HP(FR=<g!MUh*^<em}kUC$nu^5T8*rC6WN}F
z9KQxCMsLRgBMC~kffMsVQGXR!<PqI~0s;9a-a$|R;=tH+Lx9$$uF9nvuC|qr{C}zS
zO=Be%s$T(mn1UO(veeqHMZ@tn4rX?uda(3;)>Vt@^6Sk4<z;;AG9ix2MltneCu<@H
zvD3w>pk^efIJ47c8rk`EzrHqx)J98+5al6&ZoQ1qrK&)K&l~g5%4UW#oHWKlD*puL
z>*RX@=%~id1C>;hN9$|}RD&HGgrN?pFo|b0rAXr0(T>VN;~Pn#PglUTS9rCOb3oLQ
zUKcB?R8*|}HR=<}PS6)w%UN5s9Ery2!CKr`S=^Aj`95mlq8D<(q{YQmX_Nn=w{b&S
zEXMQQ6Kp^oxD&17jqI|LVo0_dzQH3@7Jdr?)V_cx0N?}93<ZX9Y8A;qf&T<qZ+fSg
z7#N(?=HKPoAv9}x;-q#|EV0STRI`{w8^XDQ^H=BHQR+3r;AjldHt^kKTs-3*s#uvb
z5{p$}5S<VZLc96he%t=)PfLlAl0(h@RV@(a-Q%a~O!r)gnCD<D_idF{7^jiPaEqn|
zNPsZW+(A~wjHaa^f71$jumCS>%V!%ug+P)*ng|(1+zaGazqHSAMOjWLlut5OYcViQ
zIE1dkPMJ$^T>TQ8KIC-&3d)l#F9;@-$)?%*CJ=_eAIrnIs!D+P=!vM_+rJ)#s74x0
zxN7*2+F96*FJbPDWf101AKo)ClO>q}G}K;%E_-kX<?}n39o!MhT^{mql6(@P6)Fzt
z5n+27wG)OF6yelgsMq2NNa$I1uD-_>y%S{kU3Iu=tn_<}wLDd%JkGB2GUkL|4dTMu
z5_Ec9kHqi??ltTB8l+SE2VGeu+Fi4lR)A3Q(7U;wONc9HrZGq!iWu(C&{9YOYS|(;
z2Q%P@SF!i<54f5!-s-lLgzPz+Ofg!Uy81R$G~=>&|9XW&*F-wum@mWy@QLb~YIHm;
z^KHjl>Gp%(S|O<38tfb+og)O&g6NuZQ|+yC6nyT*b|k2u#Qs`nLq!rzDJ<qzS6147
za_PMZG{styPxM@S_&lKH8|YgDoUp940j&{C0~dAiqva_{SZp;-N7r3NHL1IlR9i1S
z$4SEmLNn#SU)5Q!-SswX&aKvoUH8_R*&PmUGsf)CF4WJ*>fQp9KG=(bzR;FvVThN6
zgfjX!cuG8>?q=;SOhCHr$3nL$8zBYeWF3s!JZ!WLPdidD$UyD?6lh-RH*w9zFI}Gy
z(6*8+UKfk7DMY#8S&anPC4OESGT)FtV|-MbfIUd?)bD(<4Dj4`7gAtT{G-60?%t%e
zlWXjX!H7i|3m;y1^?5rX{#v#d{Kn3^265dOhksh}dqn{HFXJ2Dpt(Vyoi*B7$$tR>
z-OwcR!4UuwH)1jw5kqfip77#sxIzU2h19qx*Sjj(d3A7Dz-Ta)H@M2qJKPyFFQwxD
zT9EYy-T8d;KQnrBhYxf4&+9aE{p#}PoMqO$cgsx7<!8SR=3Jj`E{wJzqA;I5wETLS
zxTIW?TLBst6smAm!dWowuF-@Gw32t5-A|RG7K8(Imsi#BfHyWu{=F+8l<*Psl!g#0
z#y1=---lgJxB_o9^QW{Z75r{L&hDNC^9G|RUBBW<m7F8`y9>u*4nr1Wur|@09DxqE
z><eu?o|V{7)9>vPU-!Tv705!?R2da!0=V_j{#wj^OVX8WdEyWLWvt&9@DK7OCW6nL
z3RfSXImcu3D5>ET^0ZM@&&%L^?~YP5Mk!HZhaD>I&K-l|-X=+L?a`$rVp*$2Ix)o0
zoSTd*-&!-SsBmP0WH#d{^6@&!KFa_v{z>EpOQ)9)Yz8DMwEy_2DbaR;(Y>qUFJX)E
zC@~Jp-wT~VPC-Mf`dvqi`PUzy`huyy$leSn=%Fgf!&a+*osw2AApPPZQ*qfzySaaX
z_0h)3lC8b(cCEkfgqW%|pNlXzO|yv$mlwbN+8IbGDCv9mm+4{*4<f}z3A<{F-zQ$m
z>^#o*&I~(n9E~)#XO0L|Ts23}n+pA>cCB<9Obb53A%$t|BaX4g4m#2jMfsEf33~uY
zSrx%$P&#|jE9>4W`~E41-~aol%rLauWJe6CF}eh{N=#~Ws@2O=Y8+#Wn)*8yOD?+X
znz>;v0lnWT&J5i7v2q^L;FUpiLUK0n^l)^4|MhzG>hbb*)zfh!&(qM+@%8ZWME(6_
zx4HFc-+uDYA<w_9UwtyMl3D`T8X$0U|DE;8|Ec^{^}B8Sy9b{D{$I_=z^CUDc~vxM
zL<4%2V<~+eJa0J#u5>(q-um8ZY-#c6KO?_)5cHm2^EwOsx2>($or{T<9)7*<4>bJG
z<BgY^M=#b#Rnq6@A&JbU<@gKHNVhx&xBD7gr55lOvrRwj%{KCD9S3v3SoWYCg8<cv
zmbj+2!LERz{8#eYmhqbI%AhXB=A3vA>GN?+qo(y%&bel!=k*6oB2Okc%As6@!pszh
zni;|7++y1Qe1g@eqHc(!(U{f&x>TG1sV|J8FMKPCVxF*?$uMvB-SK$ltrzv^k(o?h
z%8o|Ay1`M`g79o{43I(gZWyVkTyAGIG+J*=D}htV?EdwV@I0G`JF**jJV{!|p<g(q
zby0Rht2OxmUM}kj-;JO7;sx7n(JX_^Ll@60&sz1oNPv!+(FCMmThx>uM!rlMWpAgV
zlo;EcPT~krS3>3o%*G&|WJ~Qbnn~p5dGJPQD0DIXM{FU82;ln6pM#zOYZ+(R3K%f3
zR_-h4VK*^SV>M)tKY^A@lM^`V*A<v5!5eQ5Brk@`lt_!?FGeBY>%%BxDdj!DC=Gc7
z^RGkWWU@UK=?4Q$Qt<iQj|78Q%>Y4I5dr)es{<*D;c_L?c4L1Hg~@+;oPjl&gMl{f
z&h&643RFpL0A?e?TaD7x58Ir^27kyXA*}MH0@QTChogqku<n*sS??nZ4es`o(Ho-k
z)x6EnF|}_Y7x$@I%~+c^cNv@_4IS?G68Xh26d=to6kt@LANQ$M%vigB_U<Fs#USjm
zd|nP?sU09(4FZ9i;`j|P)$>^@u#T_3NM$rkF^vE|FCrG3M}nph+733|(qXgJZXbD6
z#}I&cqeV65<C%RdsH=HFJd0>u2b*gIp$_OGO<5+6mq^rt=A;UKPO3fn8^G_Y)Oz8R
zoveEQOX?&uwxP{kdtM{Mh##SSol+rPcj;q|A3h9ErM??7jO=bPsKl=5Rz85O9KIj;
za{%`vp9qWnR9H$fA@h~RX*eIE5sKcEO9VNow;v1Vy`M8ZTI0Ss{Bi$ro?`gn{PEW<
zqk`Wb_8Ratve2FLPEZ>1A$VHd&(I9lBZ0X?u&C$!1R2-&IrHuDKiGl%-^VifP1Lr+
zOzcWg>yFj*z-%523<XKj+Y>=r0Eb`sKhSIJs3e9$=&zW=VLSJQ&n$hPu;)4d?(>e5
zLY>s}Syw`hNM&wEP!9$u0G&T7&FJE*OdvWy+smnzOQ190tk*_G(hhiL{O83k{6*e>
zUJ5YupP7jh)k1~UaB~uvxzbGxk<N2r@@<DP2<Lnq8n0|~y#^KZ*#O2!+dspie-+>B
zmvV>UMTZ>e$0?hZ9Y!FV;zS9tU9W<_))Aw%YocFt#BwS=?qV<&dEI>!V7~k<7Kc#Y
ztc6+Wk)zjBt6mpY^GiLZa@EAIUyzki;OImtk~-Ft&2auY##^+4P<U3~k8~j}#`Ey~
znCq1Tu)YUw7-Fr11E`K?G)&%e#v<_3Hbv#B)?7Rv#UmI-*8yQJ%cQKFXBRmjo^!yH
zyVrT0;Qsp`IwLy;cG6Nb>i_XJ{u_TXuD=Y^#BGN6y`nCSxL)o}b-U6;^wZs+Cx#D)
z$$Jy<<>d<Ex2+xQ!dg<gflGF<Gm;o~3g#FkBINRr8$3foIJ_pQQo_=IL<<I(EuH}#
z*TGG>#G5VB)49QTR@>ZD@s+Z76bo>5ME`SY4%j!&cz@)O=Lc@UKnnwg#&L`-ut5X@
z3b+2L=U4z{dJkKhtp8tCr`<sTC0g?rQo~6o^;WO)YIU1LtXxf7pEgu|+Tw|mWmhVv
z*7}7R^aNlT_{ibIZzA@tmCGP6nIkL&!#0#!vvGR++@MZV*#B)WRV@R`<qIxOV4lk_
zi!f}b3%C0V89Q}h{hi%-G8~)L9drR86vUHUm*MTxgmbI~(|IYXRmTZCBICR^i$c`!
zk5NWd5*UWW4I3K}sG+cF{8^n+#k0`Z3R%*&b-gZtxkYS5m;6}6n}kePe<Ev4t50+J
zj!C8yS1?2~?Cl}90O%PjEUFz&A4iCrlw;dz&aF>!bR^n(24Ij&rG<1|Lc9QCBKXym
zSles&-B)jeYVW|8Kj|~COwt#221s@36OMjU&Kn^GKbYVb9(ZDlL>eX24!lt5$bQYP
zH70THRnr*dkDn<gq0I^ZD89~f8WtSXp_MotXKmcPHOxW|9ls|Ka9SzI8On>Ary_SU
z2b%Gw9(%R?#{}c}>1|T~i5&1{HI~6c8TCdbt$$$IH=ram<UZb$Hh>YAxqh(1#J<r+
zMx&3h3$~6Li8ZK;ZHUTzC)s!zgVP>G@b1A$BtB=r95rBw8cT`9a}v!*;k}TX#F?!Z
zekY4H67((Y0MP|@pvjD_YpNaeK(oenTQgb7@X7H1RqZ5z?p4gD7`zXfF~RQd#g@RP
zfQ_+8Og_-pWF8Z^lk2P4spFV-%|g}>jHrkT=1gT>VYcLzfBb$QFR$+{xjWt6Ur#qZ
z{GU%pA$ojW-zOWnHy`>v(G0m?(hDs&J)akVo^OxuuY;LfeLcHxOug=IKZaQV`ekbB
z-VqAmYdRP3_0~>TlMC?m{ru1+vWNB5>3mwb#^jrQ>-8}cLQwOGEzv}?nTdccyJvWL
zTJrH4X{9q5@bt`(?aOJv(q+eNvGubn2FncOHD_tFVYJ)uWp@sQGbR`^T(NNTY(!eP
zWYIu|g>If1F|aa4!arW%8NL#Cbx-afUq!v-%3K1N206aRPsdE97%11C*s!O<{p`PS
zvwQys(qyz^;r<^;zBC?ayXj%I|9e!F+O?g~kdII5#$)_@z!_E%7$zAiX8a5k$-l90
zK1DGfaG&@B>Yg}~#U0+4P-QWHm={H^xNPd~-lFLAKwW?4ewtlA2Jv=N4qs!5wG_bQ
zh&zQ-Y&jQ6w@NQYR5=tVNz`TmuIXT!f+~@?YD_?U!APH-B$gokuJ{#DD)n%0QDnG=
zNpPBiVk|@GvRty!!`)W+W{__tvk~oXx0}BrnyG<`oiXkx-70rj6er9}7P9a-#-x%H
z@frGMZjj;$e=9e-UXF66P9VOj$pc^zLsv;PcVpBLzB!8MC`Qq&%KW59oiaW4#tEmx
zrEi+g1XZi|lK?_WwIm?npxRzBh1rQWZx38bwK^cdxX!+Bn%m^D-Jd`e%%ofiG<})@
za_57nU=HMZ<vi}ITojh-$e6F2C*B2y{e_5R9;7=@r3jlc-?3P`wgnz*2pw<>UR1s+
z@T)1uZZ38|$^@YbFO;mp2+m|ZjZ5K-sbC)D8pZiCuE__JI2&w%*5N-bs*Q(*VO|22
zmMjJyuSMqRUJ|0QqS5~YniCka^iybbC}S79_!G9~m0x$xGHY3IY#@)v(obvfAU*y8
zVJtzFXG~OBeJw|-C_)7wnJh34qbs7G5%@(C9*E~US=#8&P_Lr;BV-~uwA<p32;d*9
z-IKaIFMm5sY$tKa$bU#EYTW9|nK|@v=m;rN0<(Q5B^vyz>go&2g-EDI<dthH<gki<
zB%&IYAX#E}>(YRJUZN^k0{3x&owD6|DVHyK*b!us#|l6P)Jn$K8Ze8kuCh1a;9TA+
zi~R-n5tYiE5*TNiM}5jvhBF_57cOo*fi3J@H2`EYN9gv7V*%sY@`7fwm#+bLJZ~k%
zTLNdIHFU`iOJJ?RH~yeJDvOo=pp>7xHmIwHyBG)Yx{aSU``1X6*$EfpZs7+`nT(&h
z0TY;l!2n7k;9R(s@g$zI;?F_&JXX;u^pipAdF9$dWGx9}oW%-ZUV>vHSZDh}S>gJw
zxy>8f{pC+fr9kmUBoO9|OjW$>=o}9!&tnO?&l%Lr3xld$rlFjH2`uaUa%!LvHa3&A
z)BdjgRh8m}z9hvuEhYUS6tJJ8Hcj$0yOnfP0VD>*80TbC>~D!NnX|V2hm8%IJ<SJ+
zZah8e08H@Ph9<E_YHk&xVzZxGR%HMSIEM!qf}6TmV5DwRI4+y4U;rG~JglaDEna)|
z5^ULe?9>4`cUBRvdF|})@gH$9e++Rc+wTOX1l*0@N29P_5PB>u^x84*I3*?sr5H^B
zKIlc039DwWdZ9{sK$3CFNUs+imMQ&iK@_2Q`J_Mz%fwtnQH&MmzSVnLBy@wV$^FUg
zq9rWtZUU0okJ&+$ej;c5j4w6-m}Vv|htG+0mqw|4>BoB$#<hJ6SXKXrv?Ndxt@W3L
z9V=e%4pIC;xTT$O_z(7)8=x4a15Ce;tzZ$Pxq6({AM?Q3$>#x6Bae+_1Eia{s2(od
zi4*|q_VKd@_fd)Wb?H_A#BEaCi!e>{a$Q_zXTu_~v58!Y!~^}VGfUFyH5>9zI%kV>
z%6i1S{IV8n{x6zLaU?wJ@h-`JmM|}rB%|@r>_1tNV(_lP0+6EH<>UG}Y+)`=ivRq$
z9-K#|G7&3Ne;kpJirrkBu0fGjc0p$%*}xfRk28wOq@qYEHh680vctG7h>DX_wb5v$
zxBA8YK}WI#!ftBPkr5StxLRHOLnT5@vV_xq2rQx6*POePt&stOQE%#^-K(Bn-X2|u
zI~6-kXpgl8_+R^|*2T-=G>MFjNj!x*Z9Ga=uo*=q#a~%**P-IIZ!s&;88jF*FO6g7
zCLPokEM#emwfv`-D-QD!=OxvuWy^o^D2m0AsM_Q$a9#FtUSpM^|Cd=(EMjVt&ALC_
z1MvVe5>5Z*fB`7gh>>`S;d7K7%nKkQ>6|^ziPp`f-)QFla^indA`(yIllMQR#_D_x
z|I4iD5)|pV*MR@t{rDvit`Ij85ASS~rJe3Sk8cQ!*R9SqOz{@{xG4#VHjA2l_Keo;
zw!q>)uCh)xC234bV$B%mgY&qOCSv98BSxT9Xf}j^qsE$(T^R9}O`k~Pdb+B6iY=2R
z?{s}H=h|SOUT!vz1uWab!hTz2GIvkZJ>=}69;_+)u=a_u?}s(<aOM!xj)Fl#$rRhz
z6qq8CwKB8XnK?R=oj|^Bk5LJ5TrA!ZGLk(P;fc-PmUDC95Rx%AH#3pNr{Q1(WO8Vz
zR&~MvnGoD?PbvIrJ+blE7bdx_H8V?Ka4hG=-{%?kb^9vA+`Qsa)Te0`>~?T(C_V`s
zLq)!@T&wg3uf_@Z8_AXKOwedeps%F%5lZIW@d*)JN=}Qvt>_f(wCeH@h=8Pg)@Bk|
zDkT&%1LbGU>Q!dVlT=2Cq;)s39}{0rZ6aU**r&&1f2~lyB_$JV!I!<)l%V~BAAr|U
znMxduw3CkHAqKO;5~X)FDLML2Wr(@4l-Wk2xULe(?&+AbULLKXpx-EICX>%Om8=ey
z^GGC^Q(k^!B<&ur-HL0f0=HmXKj}4B5+fwzn4-FTm*5$x4&xcg(U7sKFuT3@4A&9?
z_7N*Gt`VKrsiYe*PC{{E-W1i~i^|X7i+&XLDoe_+Lw)QUdWM=fB8Hp-{q`bk*d9Vv
zc_jW-zYu)_(TZc;=<Y`Ypv^mMRQ}r{sbJNtIBTvsKjypvTI0^78KHM7P_`x}n5#Gs
z>{7V6e#f@1X(D%bX0Ihkpkosj7po0eMr)w!cLI))4_2dRTa?&RF?J>u4oP5;Mj|2`
z2@HeI$#5tP<eNya;!wJWFAauCW!^Czyo*XGXIDC(bUy@9Du`B@g~Zq(piMO$vI$by
zzdUreI2v!<f2bikH^a#!VI>eP6pBv5eZV_+wVIBHej}CUKD21tCYv^+@`3{(6&>S(
z`-(|EVb`l%-~Z7j8A-u*AT{r=<1#J07$&45+aP`XYZ+ahDUO0tL~3!6VDpgRvOdRr
zyyQITo>iwpGlZq@!dwg;gY|&=`#za@_T{lyX;xg*uv(=r{wF4c>C3LeS^lkNh5R@Q
z&EXWCdk(crB3x-87R`1XdL59)4Q`3$tjTrE<5hw@_UGWC;v~(Uv^XOM>j(eEs9;fs
z6zx$_O+u0lkIMC!$Lh6MjObMZ?j`q_H8Uj{UU(hm;|o7ZuYiEE%u<3+^8uD&$<^ZJ
zhe<amH5>j|iFFQ9@qNr-mU!k~MV=B#f=_)>6}3gogXx-MoYKiKU|>m_>Mb~96BqQO
zlv>s0w1Rt1dr?;wPCOwmT1~JgRWO0-@Cfta)>pO6Qj$+TP&H&wWh*|-cxGTlt%#hw
zEDxbdNXlv^UI_=IMz5UXT1JZfgp<Eq3LFo+YCFsHaW@OW%p@y0PgYY<IYUrMO=7a{
z+`I6)>`c-Lf{4i&z%6RYu-Rn+y;GN*QBY_XH=keF58rmapE9ah6iWH}2<G=MZ*H7W
zlh>k=d#*9GB9-~lG-tj$2`Rj+nuMuj1-~mMO6egP&GsBGysVRi>153EQHhx^G47QZ
z{W1T?ZpnC5O^(`+h{ZB;eBTqgv%U!#ER*GGu+*le47ct81Tx>q_LnkGY2-&T247&p
z&Xv`0d^@7Lq)wiOB)R_bPM%-FJ$xcJ(gn=A=^A6p?mS85wLD4dtqxC0&S{5HD(qpi
zP31253wo{IbEw$Qiz4K|)|1d4@3Baa;OPu0GK5wL6BFgXVO@@Cv!hf!-I<RupA`s|
zj59uV+mL7gVM=IjVM;hHqB90c3+abZ=Iq8`1g1syjv;!L9Gh4x-coa>ISWZ>F8{Dd
zO+yB=8W`trU?j<@av5k)EhvnsZzLwUU{Jc4;*^Xt1N|-o;K@|o3KzMaOWSfYmPyTZ
zoGs+A{1%g~xEsy0Z%@&nk}_5+Eu8zOh>FL5qCyxDGq-^zDMpi9O=FI@AekQH$i6`P
zrmzSTt5+{kCMhS#4?S^ExDUTZ-Qo!r3X_(xOKKjxKz>l=FM^RLcmeM(CY6z~Pb!Gh
z7f2z=J+(IZ=|h`qzFwe@!fgBMW0-&C#$1dXi}fJmy+|t+?RI|<?M5)DQ`SmS#2(Wh
z&Bz9rmz<U<(Iu;<Np?M*<(?CMjFFOxc2#REqwyf_11Le`hZ|=4{@F$x<JV`oUd3Ae
z$u;EILEH`eE{cRIs|XGA4JLK!Yl$+R8>o{Reu8h~^zWZLy8k<r{T(9+AIOL(S~LF$
zq{0{~;V+`maSzrcV@YxqcSh>uLk9tH|NflvwiVikw1yBg;PI@;sH?0|vM~%VTSLz%
zm*YNeQl!R$6f7b35KfzQGGwG|T*gtbB%4)s0>VXC%^uf^=dhcvq*-fOV=>D5?H$Fx
zqQEZfR@SZh9o4P-1nVx_5GzS*(3V*8Hzn}nGG?mv`bIQ@g4vjJ)EC8{IlBn9_K%N%
zTW7qUxBmD4Tr&dtFc7=tAc25}34wr6e*RQFY#3ZDOl?j7_sR6%amA(PR3r`uY7fR6
zKdiI+2irj`+4k;?P2v`*Np=!$Q}d;w8VhqmCk_e-8P}5%WnodOkUekGyZ|U%*JJE2
z(#A7_If|)OlBy%pOdBaJH@Hagudb4ke>r|$4=#Ya`K~lC@idtJgcSX5g?rwtsMR#m
zg%p4_Cnc+oyhKtIlIbtIR~Xt4>5W`JCnVc3sF79BR}q{16aq=E4QliusL=S<UNg>s
z9rCCViGGq?^buUVpzSntnj)ntOp=5by+9)cZ(n92l1sQ`DS&rbr~DpMybxRz<&JuJ
z9T_0M?qHx^=ugP0(ls8@`n_Qe6A%8r_xwLfWMn^!SF+C&j1~s;IW=;TBM41lyS#7a
zHW>pSjXCH0vp%bNLZ~1u?;?HBQk{{fi%+ed=J^s}3)aBo;^tNEi)6bvLpX)ErTh-{
z8`TN)?OA=@hBmzN*pQVx6+mq$0c`uOC=8%Rkcv-dAS~Og#Qb6<4^>}#U`6^$Pod?}
zT0un8sWp^7q{+&?Z5_>||1<_=8#YL=D}ic8F%GWcQb}1xgP7w;E9#n=56B-xiBxib
zYzS6<7OK8Al9Fq8aD!|C3fVpsncSdNg$hne^`(X{;H#J<qM4DoFj?0iTmwhx*#lrS
zI40BlL6f({LCBE9>-}|m_7K*?3wS(z9ni0DYoeC6gCtW{zFvye|Ni{M*w*j)x;?++
zI9sH+>mTg-c%4Y?`M%?Rs@>m2W9at1zduXF*ztWjk&ne&-@wI7yCn**yRF_cz9Ek^
z41j;X1Ln^jWE2`q5I{P0E4`i=1p(-36Q1|G)?W2*;A#wmcmD3NUTY_~Ya@+GuMw*Q
z-!zVL!*u7~Ezg*^y>-Zu*-Ct93-1V@jkmt0m#PH%cfyjVzOS?vU2A#_7l9mJ%-J`u
z+*2nUg;&ub{O4$emw8{NHvI7#u_oxx0-3Or0htngqp;DRiGEYU;Pv~dZCgOiK&kZ-
zua60d;g2AUet*i2h9@lO6)%;zM3~s{x+6^vnVkTA;^fr~q#|AsR1a^)w87HH++k1H
zf<4f%2k`Isx`XTq(oU!IZIPHP@w{%U(F(tv*JTn$2mQ$5iA3YwgCsG0V%K;?c!hBl
z>X|lMel_=hni02xA6jK3Q2_qDnNH)?bw;Ik5n#9k)<&AH|88DwnhIy(;eIGfUhlwE
zc8MCs^lssE)|fS9nK)^iQzte^#=DfNq#2!7eabQbHccqEUZ!$Ng`zS2cb8;aYi{ot
z=z&fdj<i$wiY>AwrOSDgrQ($x124PF269Aj7`Z^T0)EPv(9t7#5e<OSG*9(HzxL5}
zpz*VB7%|Y_=Dq3$!}77hB7AOno<dZ#4*YEx3Iz>|u@(3S?Mp`_yF$z6Iw^BClN|vR
zRZOi5CGjwNXePX#;=_F$-yPT)0z6jx?mdY+lhX7=B%tBfKLT27FN>VbUWbHA=Veb-
zXT7DD@Aq=E1wFnR(`kTp`h(W+)AN&{ReGmSz&QEM{b`PTXWbDCQPTAU_)v$CyDwPh
zTofc@>4suEMVl4yH1SIYTN>?V5((XbBRM|>^Lp$otd_9pR&Q2>%#(@-3wfS#VVElo
zTJCJsyWE3EZ1jShd0S<BMi~rv!m9_BPPA~URPm`6@6C4A;swC(RK;C06@qeY0n<>%
z3`fxwQ&AsY2vyHKSZ^&|W6nimPT@Q?UrWsK2%6Cr4b9`|c~`XSC`@o&Fw_h;>BJbV
zq%plSsv3GaUCb+yr7Rs-!H9u{FxEwRt=-Yn%GI*GOSF)VB+8{BnsJ^n5Mz&)XDa1g
zbGSV{Y>`>M%?Qwj<HT|vjeuk=N=(rjKu)eaJIG`A+GGXQLQTSI{fcsmIk4gZ(MGbU
zjqz8x)eTEB$L_`5Fa-;vK1?KuTPIO&9D*r6%{yt3PM;2t497Z$``4C6-5-%p>mWmb
zh9J`s(S>K!gSn5yGIR@5F-MLdU{AT);j4UT2d|QJ4HwYgMGzg^1<HNGfmEoW!9W8U
z6Yd`w<a9p86p&eq7Ju~WzHcyYvC<ha&y^HI!X2sL_BYKWr=KmndU8&lh5%E3Eu%00
zg8p|}Ip}kj{1ykn(zr8(<*|A35cT<@OX67=&mmmJz3^f^b&=ht9Gz3OHGLaA@{*@i
z=iZ`kBq*SdkuG<VSyr=CZXlweL2;vzg%%1{ev$pf)>Vv?_pX|Pe>8hi%T<8(LMr>^
zZG5wH$qdpx;J23pfU`vDR6)o-m4xzb9%nR(-5_!^Q8OB9r<03<?%R*b269Vkl`aX}
zum@2kNGTtwxgx|3Q*Gk2R_EN68e!KUUQq{r;R5gmtYbJU>SkFpvO<4-a6~s1f)p7k
zqd$q!wD-2(t+VFic!NZk{oXX5r)leE6=K%JO9|E`S1^0I%pIavrF{eEwN*QZ`}?+w
z1P*?E$xh*d1G>qnMH|YB%+#+yvlKE}il?*%=QHn<kjB{Hh|1Tb8|a@^NAvg3Aldg%
z>yTIi3J;z)NEFAB7)^%>s8rLA&E!P&)3^K%I&vTG4YolBUNT{pNN!gxN>6@X@;9t}
z3yfkRt9tJFw;C7x*v)bTd};j7v(uLGxI_r<WmJ5kWy;wO&16(Q&!%o0`t3;>h$hxm
zR9-AZld=bTaaZv%!#}@`57q%NnI!gC@C_xXx?&H0Tp~$q?3u>{DA&$gkd%e|^xivI
zVi((Z34w!#t)vM~A>zT&m44tNN)LWJ;K?a?O`V5<8$l!e5^9+%Rr8@KAf@ngfoc|i
zQpm-ExTx>uYaS)^u(mFS^?>Q;WCv)T*|yj;QM9t-fnGf&6ovX<`k(uLqgV>UdhgTw
zaLVIU*~C(Jsk09Nm=Im*S3A|;f~Yr<MLgD%OFqRPMZhJDWbPa1g>X!WTz1<=B~g=Y
zHXWtG8Q|ReL#6293s!R<=5n4T;k(^C{v0sXr=Q)G7T_<WV9`g+^7n|RudD?r(GO07
z7ZA!5snfEQ`>V1>6TsuGmJ?QqPuD&!Y*polQOcP?{!vc@loYYECC$yfPR|rj%7a_e
zdJNq@&-qqe@9J7v6D{309ycyUK%cZ6gj)g~tH}KER=4_Q$5<5(TGT_I@2+Nn6}|ZF
zhZ{(=;4p|o0S|~_H<~d($@};=oSV(M)px+2t40aK>C+}lpU^uI80~P3;KN+!t?ir0
zCK7%CUm1EcQ1@{l<|+5?NF`$lxlvGF)=#_D7SOj^qisc6eYx88Gfbm#GoNK~dB+W?
zOe@+J-OpBnYJ-U1Ynk>2(V9wvDBW~6Y<m-%2R7r?DQ21kXgPPGce>eDbUn#hS>d~L
zBz`mC0=}v>h5z;QWude9;D1k9b*Ikil<3~PBsSv{51icLs9(;_&jmI5E(r4kGpys}
z?8&=t^elID5W}nOxuMZkYa&-BUeQaSw`^=xYlJy^yzgB0d-b^<-Kdu)ThyI_>sXmF
zyAcBbDW)FmSZD9-kc}ssD|gJDl7AT~s|P4GxM|O*HRx&*^CbRywCLE}BoL=N%IA1i
zg^)%J!_3Fav!_Utw{j1kW9GM^27)aRU<$^>6Q1Ozez5${m<)XTJjBj~A`p<AHZTw>
zP~zSnbik$Wjq}E6{PVwx_HW>$_KH>2gq4oAsiQ8Ng!%D%dWPo9#KS3D-6K$mK-6W@
zJfK38qZ&YNNryQj5Ckdd1djba!&nA!KzdHj*Q?7v4uDUO9@&bf>WS&yySP4|?=$6C
zgeKQa<k1a5SC@z5%Z9jQmt>@8J9XsczgWA5H^3ah_ifGhy{xW1@<($i;QQ36q3x}P
zp}W*Pb&b0!H$`1DpoezcD%<XM#_CnnSJm{avwO0B%Ij%JeJ1DgIMOu(BQ`;^jgGws
z@c2}7w{08$?V5>qL81S7%un#Sm&yG-z>&!>bG+kI_d39#f2;pCmRXrFg3&<BmAa(*
z0BC<NI$5J0nVvtRzWBVdV4tYI75?~Y9p}(YF4@Y>HD7X#>CsoQR6N0%r2xiC7<;oy
zu4*t!yf3(prLVW5(?0+liazp~YsPOC(!8#Zy~~D{{3CcIzF_cD(n)=Vr6A$=P26_E
z+Ct0fgnYgDie;Gp_ldBDA6sFQV{heI4S2sab<3_wXt2q!d*lCL&+gJz<D^C`Ts5gs
zW#6!=E8#$s>sjA)Q+L%tkMxN-IzFSm`F?Grh0i^CvQb^$puYHep#^<kj5%x{=PyB<
zHccEUWt~|T?H)B(JnxxYY0J@7qEATm<eoC7@lsUdd{;k{*EA6vAxk5~xNaNc0Hlsh
zJc_BirqH#}c-qDu$g!tt%uxfA9dE3ON%#iC;o_&NHg!cXp?o>1su2R5^ri(kam9R9
z19kVMzm(lFca0WJ6?b<>D_;ECj`(8KDwyTqXWf#ggYzX3zTdC0ZiA;M&{k`Rwttl>
zY>Q#C?ZzBT*gQ`&E!#wPxMkwj0P0c0I3jf>+NV=RqpD_F7Bn?&%3YfKz)x8|ZJMec
zE`XQ0rz_Und}W_6b{Y%lH2AqDQd2Xx^Rvw+kZEz=*Jw7=P6=YlEn{3GdMRlfR>}3n
zdR~evIl=<6B=qFfpO?ObYNMdKrX9tJcK_mjoFvWL-*6?!d$b;&*^oHV1D<g<r)hB4
zl{kwiVp=q~I1kiXuT{0W1`-L2_eFd|d?^^_FOY>OxVD!wow8N+v&1Z2bd+)^ncC(_
z7@?NtDk(_i99q#heKk$Tr|w;A=d&&sNlx9#{wO=dw|3TFenU7fKj3~Wogh)55N%fz
z4VM>o%cxg?Nf%&Cv8T5F1(egDlZNF;RF^x&8&;XdSHmaBc2BFdK;CC$)_b+cMXG+$
zOW%Hrs^JO1>?^Izf@O*vO2Q*4+LvoDbk5q|FIYnK>yDuTF`OQ}G_O@w9!In8Tb)<f
z9E;|CwU2+bgNFoTOJ>_5)8f^`AjBOVX#HH_n^)eQ#qnLv3rG?p0DiGmYlBRCoT3Sp
zkM1ky?0q=EXqFUCM9TcDoz9=&U=%suz8~$e1Wp(m(<xp_r!Cv>l4CbjGF|a3rhxMe
zjTI<b_PWEPl#}rOI!iJCYpy-6E@)!TI5}y6DLiOW-#fPzYA=Ou*<IdN$TpduA4VXc
zcpAEVMu+~5f@-5=4=_*ND@XzlO>5`}WvBV_$eyx45`BQRVhRg@>`E`pETl|yfxn~h
ziJ(iQFY<oSfKOY)n@aNBYWMtZbv^B}@`Ks~zEjAQ4Y?rtCoyWEBA@7`o3bkbH8Z<A
zt_^{atm3f+-zyUL*{F_?aF(LIPD*p`!MI)gdslX_!ecHH7SK{G=U8<cn&tjYn4YQt
zJ6*5f)J-#<smiV&h|n4*s`dos=$O6|P`LL?mSq;p4R0GdKX<M&^Ps1sWz35vWe%<t
zf`Gh#)2C=-3`YTC#L<5tdz|V3>=3%dniklsu%7Ql5uyATCKyG4_Rrr_^?B@mQMIB}
zs`!cErQ5ORVF0iCDRj?G9Xg=ffB4&fBl=|g`HX(Dg=UnRA+j}>mSLC~A1c%t0(6#k
zI0JhbFM;+=m04I%ptm0$^kik2gokuV8Gs{u8^o>xR13(*XgOr-ftGTR==^@)=^=f1
zL@#LqGM}vfuv*wy*#Oyx-P!H7zh95M!lU6j%?+oQ1Ypii3L~P`ORJ@&^YmKRSCu-}
zu`g&B3VWpHC~55hEic%rdYjJv1`htK4$7W`KtEvT#yrE0=<K0;5gLxoVzuZOeVzQc
z=-|2tn44HlIrp<2|L)uNl8W1o`s`{bqNy_?!9FAnaXH#@kRlaQVyt=7=lrI50b<d7
z2<=`9FxQC!-InW0YnW)%3Zx_I9oI4iKH5{FML^=Noo~sUP>M3bg{kH=Ny3aVg1EK0
zEEVa9JcS{P#nrfp*~clqpaQ;AxtngKw*cA1KpNL^1o`Bi%45JVQ6hQT9b3kN6L|45
zO6jFSO3db<1c*|ok(x<Jz*)>zGV@rTgjhcirUm*9hIU?&Hd!{Md(I`zJjZtuxL{Ct
z1s7i284P)=kRHLo4!tq=>`TTkI{Y!*w>8)o_A(7y^InamUIDSkO;zl?6R9M0IOWp~
zKM1Lk33@zV{)Es%glDtyYT!KDS%r3sJe6|-O9|Z`02CNA<RpG+1ap8O-3Hj~(L)5s
zVL1@8{G-KQbUuE*zOScn28C7@7V={`2a>IjDOFc5>V=JmMegzUb|IsOcPlfb6ALPj
zs^&Abpb}>efrOqwH38W=J5VmkRL?W&Yh!l3e^JCl5`-P%f1X33&Lr1D{+hB7MiG~1
zwx+Xi2Bh14(RgO@OA><g1~1q^tUxPiFUNRi>Isuq47Q8hnt4isI>g(lZ(|~@`Ao_F
z`sEi^a&{1mgT9fxnmB8=;>Frop1nf~gPG$HFnBG!cwN9rW0)n2^rObmnKIPeAbg;Z
z<k_dbXH7R|w*o|T?<&&v)@|Y%^HypHhi&p0pp}ousHaSSDG2NfZ|s?~$1h>CH&9AF
zN^6_E5o#}-GRQ^WL-hz%v&b6`4@z76-w<M?f)uOIUJtZ6PXQuA2+WGR6+Q7GnrqF-
zq^y^+W6qo{v8_2(c3Of>YyL)W4QxGX3Rt#3Mfm5TpAgc3Y?%1sJ{!KF(!jJ{k!m0(
zfTFqTxn&dMG6B6>gJV}}I~moH%8<8u`XwUj@|m$!pw6V1PF-7Mz@yyi>Aq~Upl!E)
zm)uWiBC6SOLg70*jbPWp0bPG<^HUeBU%C^g;L-<ZB5*se<0U;ZXwN^DTA&Y^UPo2U
z)yY|td_SQ$F1eg@RHYste_4gN%ph|QKtuF}4Px#v=V0O{hx+}3L5~qFZZ96oRzQQH
zp^9-JW?b%*gF%W@nMq(0@UGG`p-uzU(nGwz0fwb=ws0KCUjV{}PEc2X;QISRY;`{F
z<=J-${fcm0;BxR6G+*`6)C36+-$xjvC@!R+z~D~lUr$BBRg-gPSKZy#92HX@!17(b
zjL9DyA~KIh#2Bgf2`9D@M^)=KcRgz<13;ZXTwJ`*C$(Dc0{)|zNH~MQ&fbhOShyLE
z1KsLx0~@c0{!Q|oqn+89L-9?yyJyFU2Gxw3SJX7vA)QXGP67s1b!nFaSal$<{*u{F
z#NRIfn1M)w-|{OSi5f&rAE-6=fZ{J>`~F~NvMqx?Q8(>xsi<2D$p{U6aK2=Ck>u5G
zJ?)Cy!*U$o#T3+}U0s?5%v64wdNSgs{Q>p<PKBt={MD}uoqfML@!OmIG!bx!%{2ux
zjm63nAl7`b1vON2C$QQFws~5N)|q?{Z^R-WMsnWQor6RUjIqcS^Rc@LK*3nW!{Moo
z6Cc+nz31mMvF9f-m((_Hw(iGE#e<2{+sEP3+2PRP%c;@*8>{E%)x?<leeMb5n7et+
z%uM1!;?3>a*xB8fU?9bp=l%UrWD7&0dg8;uO3BO)zCP|Q)!5m^;bB<fLgeAcdqFBg
zV&d4)KMM1=jKht@!=uAfz(y*?*w6)7E=5fczf-b!3BMCrVgrir`rRQHzUw1$^-N~s
z!LRRwsf~rPp+iVrP(2^Ndw%;nybn50zsK{_4wOoFC$EqDE9c7x!dG-0USHpUf87~6
zS-(dj5fV~sW*8DU%xm;z=x<G5SFlz-)Ck_LwBt^}aB{Nrva+(f0KUS3xTDnxzbu|V
z!p69A!0sJk>;*E$S`t$eBMDyTUN;VIwuHQd4p@Vlz>iiOO+80+41j+B4tw&F4lR5j
zRh;RdS}^HGBQZ{ixMG~LL&{@bDV%$fSxfrkf8+Su!JSm$URP4l>^qGpw_zXJ(1h?J
zxHbD<%AU2bl%NQ$8o*SNDkymV82RlKk3U#ctPR*T^jp-UGB8Y*i45J-4gB3Yd*+tn
zcl%M)L3pMV3Q*&$HdXIoFgjfHLpa3bQa=(4<-KSp1~!#0EumEYbbo>W`Eo0*3%E$D
z57RAor;nQ<H_KZ(hksw)<e?1_ZptbbLM)Q<U;^7z;j;nx4FD~|2`m0dQSU$nJz8zV
zJDrwD5mV9RIs?Hv1joy=#cmMnYZ$H4C0vh@4}DNVZ8U!0A_J_<jy2)@4@@@`#5TRT
ze1QoM`l!u4(WHa)FnRkfZ<O?Xx3AY%66<tadvG=#f&g(AcC6wUiS+Zh`gf9#_R#`t
zXH;x5NIN4oJV3K9ct3HKjK0)_pjTh{vrq7zKDR5A_@+9`nu**ydj|S$<&$$hDCaNu
zolmhgo?(-fAiuQcN=AKg_*`M-Kj^^9*69i*=3c6M>+{~;wb1Z5xxS3-%atQ^wNO!x
zVQl%b!?f(X2-5`@q=w{hqz@cyjBaS>(*OX{dc|JbD<BD}p6V$@3^k`d-;^xf9dnuS
z#t|*ePaXNSQl5rrL{uU}!AbX@#0(MrF^KB+TA)vAQedmwrr<;xB8F%!)N$;=ce@yZ
z&rv9@6xWvMWaADRs#_VQAdUrLt!M2h%mX<wBnZclA*z79?4V-um4qs<IP=QijU=-S
zYfCa)34ntmU0WaSU(^os$uIPB5nOx)$ABGt0g>m&vW5hr3yXOo7=g@ms%<SM<PS_S
zDp-p<<gF5)eC(wR;QpS&>4_eT0j|i*9{VW4RBGrTWfv-}LW4=yA&belF3f9esX1b%
zemLZI2PUY_7|hJkj^XXfTY7~z?Na7_{KOYLX8^~r&bC&x=fk-IN#SH=j##lsyLqR1
zQevpQP{tUM!cX7k*>A|Yugi^CCj(wQ`I|9BuL<Gr0G5M#<jDHqXBlz(yhAM4a9V*R
zp_SGIqZ?|K143)xkQaC+@w6!7US492OWRC(Ad0_uJ1lX;ZBL6RA@|GT1S~$;GS#pV
zJ78x9YBQ&-Zu%9XesM^3>#m)YjtqtvK^TkPgaI@93417NEk{SY)Z^?PLsPC6*fw4k
zyAiKuR&00RfJ>t|-@RNF%0v-c*C1qu%OXp(=dhOqz0H_bMEQ`A-|=UH?pOb>y1%Fz
z@q&udJpD(zIv&&D`BaQN`Lr5$?_fm-^nebKMJT4Wxh6RNdN4UN{Dr0Xral6RZviu-
zGkP)mKJP!j4^>Dtt_$fDqmUt$OHqv6jSNu+3Fr8ODX)Whxn>y^5P^!e5M=O8^Az=~
zjKD7Gg5n4@=(}O2rDrXXnrw)SJtv8?=R}E1LB(MWP(Gmz4}c0=V|6?1;Cw}7?EsNr
zqZbfuwJh!PZ5Zdjunv3e2(viejHCSu+rY@k-TS&+jHx1eX9PEg`tIJs4E{}Zg>zU|
zAeqmatibe_j9Wsky|13bxd|NKThozAvKEm6HGq2H3_(QD5eRas_VWJmeg@!+ttNT_
z&g#;yX1iP<9x?4Y%*vJ^99SP<`~l{;*bJyMe+pI{wzjkufT~9eFQ=D6SBL54ze3=f
zUXlu<cpyZ382=4k4hG~Y*?=EvM5^Bn4F;+k`NcWs4;e;&pc>r2o&M?zW8<{0r@DOE
zG-T*N&QJ`L3*C9&A2qe3Dby@GM+Bp^PaNsYT~z6mPH0W(p)>&l=2+zz-~yn%&Fz<f
z0?XTQDa|S$3Pu(c!SDo1;zj6bZM0QF2VC}6^e)144!M$S024#bQUSw&)ea78pnHyK
zb3;v>$78=3n#r8b%!fhB=o2@XF*B=dz`buny`ch#u(E5~^*|45I1jlq@+}j3cA>C~
zp_?5ta4PvI+Lf7a66Dj(`~fP!qF@@}PDJ3u9aK*4sUHe+-x=n@^%gn5(IxTIIuM09
z35uNrX@!e^3#PeS#m=ha@(K2HJ#ZaLM3drxP#Dn+FpG$Z=KzNiF50QlM}FA9MDI)g
z;v>~R`7^@Xtj-By=G<-b9E`0O{ELMCx~|bxt=U8p8eBSAxtWp0sSD7IzCZ>(K_4e;
zS%z%BXbk>}hNr@V;p+(8s`UWspYp*n1lm6q>scsPaN@_4@qM)LNaYu~iG?I0<39E|
zE=g}jk^<I;TrgM@H+QJ?JPP5BBq16qRlSQ{?78zZl2U{z1hyyk!M|!}w6(A2U$rYr
zlsXib1~zx+L~EgKG6|TNVTO=XMHy`YauNFtQs;&audzPitC+V6*JfFl5cVkr#Dzqn
zf+A`ZvxTWJ0}gYh2=ewTHQ|}@l&R~A2hHW{&kZ@6Hu1L4Yu{w3c;uR_)K<`C7$H?4
zVFC|QT0WVzRvB_FRbRME=xNcPLTigDved{Df#eSHcXum;1WkZ+kW*y<U4DYimh0f$
z<9y$BQyhbR(u~@E_uen^T?vTX^_#gfW9@uvk*p9XmGQw5oV~adVRRTtDp2WP=NWvd
zq4wE`AmEC-M3vn#H2GfQY;mKozQcrM0mjkxuQ)fxCI!r(^xxafi7;6V3(nGn7EAJM
zuyK)c)WssN0C)hO$T)^}Dgz2l;mfz!JFmnlaElkLp0z-1s2xE#Eu-46j$gy*zZ8&o
z19FmP@f2ZGT=Z+r1QRIvPVhg<+n`x0ED4WPxFib8E@Gm?)ml{eF)n;MdUFjp1+9sV
z2#YO#w}#Pls=Is&%~Gk|h}f*NZfq(Lg+UM=R&qW?nX&>DauD$ZB?U)m1>3d+{-olv
zvH`7{UKYy%@hTsp;TcaAsfF>m6t~j4Ugc58VKHBB3f?P+Kl0!f3f)no8b};Wm$tgw
z7u?)erTvqlx2y3=rUd;kpCu!j9$Ui^fyTfoEG3k-&wpALuI@L|mN?I{qcR>`yG&qT
zEZ5!-kogCYGSWte6wx&4$ODbAf}gttvQ{&4I<1Z4M2hDZ4Bi?U!VF^wAYpT+k0O>A
z?3NaUjEO<+7H@@1ks~1o<C%p*+D$F}N&zy9)c0?B*TU9kZrBo7_=?W7R3Czh_mJ!j
zHNc!Tu(Z45_C;u&->IY((E$$sh+Hqaqg1egTYmwd`CACg3j+}fQ~#l>f96RF3uet*
zfviXo$Q=QAv6SUTAu1b}9qnHp?-yhd(p5rF1i`SKEYM4K+CRg|Ax9dpdc<gCNsN<s
z3iuVt8at{yZ4eU1=anshtAwV#!=FIW4|OfogQsLVD9Skb$EJZhB6&s13(nT>HzuR6
zO)LS7&n&L}uOa`O-iO-T3x+~f1lBr)ieAL5A0>10wnn;QpIiTS=X3{T?~yYjojTmC
z(%?ln(+v)iEsP@g>hz76JK+^dVC@8R+@c@uQjs7Q^&K6Li<hh75A1du@G3{w7t+w|
zg%ky^SNr`jQDBzLf5fwB_`arg#bl{uZZ!s!PQluDZpnne5w(Fn6U8fpRyO0QVD}D<
z9bBH>QyryXV`_D{#UTo623Ai{cL^bO`27uj5Z|-2zevEAO%j%DV)<*Fe!uLct2hU<
zc<w*&2`aUCBxE+q!G~XR)xI%odK<QDDbUvK>>6w>KtsRhG;TWyO@(;tP0B=3dQS|n
zN^xUp>qAC^Y7}(qCp%|E(L?}0egTeFlbt18m_z2|#qN$@)Z_z&7bK1YF>v{pJzK2>
zyMupb!8Pb&FvAsZk}IW`8W=BCOnz11C<le|^#95_$KYIoZc)d!ZQHhO+qV72PIhcN
zJGO1xwv(M5`|fk<*7+``|IAdc?y0WoT2*Um`g#5qq!cb^oA9r`M;YUk@#1;ukd$I1
z?6)Ag*;9oXiGh7Ve4_UFJmyP{N1FTM0%#Y)J2kX=LkY5=IwP*CZr7TCTf2ixCw`ML
z8K+o$-0AC<#Fbf6#Si_J{mrUTM(hA_@0BdS04)r2lyOmpnlp>4rKC|rn_9gpM^bpp
z9x@=lrbG^cP{m0iL73l@2P83pgUxgnFeD(8kZY4Tw!k2bzSb2*LY+Un4oj(Z1lVxF
z40KLWfwcu%Fu`HAuO#)4FNKzES*UIx+0jUhM63(3@>h$UtO*Yhh);`6cOh|P=>VcF
zuW)lHiua^hi`9Duf+f)aA+3_z(6y(aqT!NJ67?teW-bC+`8Xgvi5Jc)2ND%#e~riA
z?G2|t7qB>qC6gPKaSt+-E{z=G1h88!^rpH`t_xJIR62}M!bB3P?(q!rAV5dPFmPnA
z>BZgPF8+f16)bu<(w*E(ZM<H!0Y?~FLE6<~1QAYFJqpe@OGPu3rD8g-yh8Fm?I5{x
zM1e1>l~#_tIkaynDKpB@=2XZ97s=O9<_wPrwmKJrj&YYn1xiQDa*qRy1Smpina%k;
z5952qBxWCXBX<prn(02STP$;9i9B7Bh=%INC>kN%CNfAgY_9kl_28IvM%F;(fgF;i
z5CL7M+(CeII#q|l%u-JsLtlk}KdoA?q$?Bxw<NohexL)S5QX6^SsE-3!T&E&R5$A|
z2MQ$Qx$KpIBMoc!TrnxZ0~V+cH7>0aA)e4mK({d=3Eo={gGZGIN30U=gu8(+gaB)u
zc@7zwoZf%gxGyZO!~bNsm^jrNHAB0}v(Eh7WiI3Y{7x=gdyE4+j}$>!uN{H|*V4dj
zbiFrFcABJ-+W?{(LV^oYo~YZ2(PL9JWR90F49zxj!i;!oDQ*Rk2DF_cfl#vz?JUkp
zfA(qzKGOE`kXcPR;fxB@WVGW$!C}!3wxRLK39LSMj17veXziu<t<+#c6EjpEc6EqH
zk)cJXXuu;6tJ+)+XIl4cb@;!n+=jqzg0`dhz-~ZBk{P6)j&vi#xjx4q)2o(;r~SP^
zhB!>Udg<t$4&(EK1c3c6%{)&ppcLQN;6wo*BkbhA#qbBANAvIuM-p&+w{Lz+lVs`C
z40V1)GLjiwq;p-yAOX65Z8eUzNV4_6d*vu$#xigyR0r}A#@LVAZb^z+2!jN7QiqVM
zz_r$u*@Nq_2d$T{V%_(5+kS5`0E9V@0^uU;6K9rj*crq+03zmtU?QBZP-Ae_fsOR}
z+c~<a{L6)H4|GGh5<)yRDDjN7WL3U?siME_g$|x8XZ9?5ux278nc)mBY_J1eJXT?A
zUPt8X?l=_H@Te?Hb&mxQ0a?|5ZLQ7a;q&=E%f-vPG`wgoc;%M}7bN_Ejs+t9wJG%v
z8|H?bBpDkT0#H!OALT*D#)(8gsg+cK>&pMc625}aflso7cNqqJ-7&PcQ8!o+Y8^5U
zj<Jf>hlWdfZQ^v8-tsI;90X9F2J_rbe?MHUCbs<D=z?Dn(gmU*D`<UF9GAUd1{STj
zLTFFn0~V8w3*f524;~&zLd>$fOCB3@+^_K6g&P9B1=LD`@fBG@$c^B~>6*ZmKpyG{
z#!Uh*&burs((_I%^NdJ$flS+C$N~NA1InVz-mt5T3^N<zWBq%AV3P57f?%wc40{5l
z$zh>uW@0^wc(duc`3g@!yCPk&)~ebx;r>4Pnf=IMirQ=SoHT#~*E-Z?V;y`ST{$>r
zBNF8}142mEt8;&$F9YIqC_(;xq@F~L4SJ`)jRhCR7Up}2^vg}xCG&dCVgC4z+X#a<
zI0t>M>F2MB-&kviNM}`n#%YPiajmFKz407{x#U@Yf#r$%I;f>0)EY7BkalZNbST0J
z2o{}$lV2(-UrQjp=0NY~xn1_M31lEPqCd9K1@y!y!#pAzMe5pUqhMYpV;SxMlbz#m
zakQR<=y2HO867x-fG*NB64-l$<Uerta%d-wgWXj03FYf|#a5Ojuu$xF5`|e3r6Dim
zHJDfh`dGaHU(7danjnMFHfzxtLs<^x@OCc?d=(KJ(@!<B8YK~+Ygf+{3I%6cnY~n_
z12%6~dBYJh=oLN}X_tK<#LTO}M@R>Pk?kw~Zqt>=r^9MObr^mcWF>H=`#A29M22@m
z>EgOq!3xxbD;fjQxRg5YE&KrwuWT-E6e{@+@q_HNYZB$sJXQ|q9+QfySINPv;e;-b
zGQ6~hh%&Q=4HRwRZ+1+vjWcif-J67>2$&m)>P|lB$(PFfUgFg|GU6n@z|k#lld0T|
zXbs1SBh?bz&+1%Zk|y9lLlyrb>KWEjVY&6WTgAJekM8`U+0q+ZIrJ;2o|lyGs5Xt-
ziKqdKpC}_)Y^xsP$YbnI`gJcp3|guYS4#ZxHOv#1yecI<kasisd(#V@(+(?Q3BVzT
z4GoJE%{@2Ijv8`qhSw;Eb2g$aV;~zbfW%ByI-6kh!Z>o2S)7XKj9FsRj@k+*!~R46
z`iSf7Dhj$+Bk@u3l;Mkl5jSkx#z#Lxd)*UEJ$gH+r!fx_a-F~}YHA<upTk7tK^u&1
z^IpbLuoT#Nu8npvEwLmS^?Aa22OvSfx<FoKfkitIO%J$0y}Z@Gx`hh0Zfq_abkc@u
zNgQbr27%e5oXKwHXXYFJMa+BLb#zl`p00Y&w|0*3%9e*22U`*cxUs(c(uKr?k|Sne
z5IUG;T`8eSu36Q<*-eDJg2dJog{R)_ko5E@4`Fma`}RuIXxyceIF6uZ1$fkCYDjfC
zZ!D_@KBqmPWN3ehb*>$_vKE5#uSUt}o-rYd-mt|rIhPzNd%!-3C2`6V7o<0uhy{O?
zObx%r`!OqU6r#IbJlwdtqn~1izTq<le8u4|ble5R56-O+FnfF&6Asr4lA!MjDT<9$
zl86pmH$Zh@adfUM)!v1)0~B_v84LOFCV9t73adC0q%tL_oXH6<T)=$iD2q_2e9_Dx
z?r(0P<JoOZZfKxm3H%|^qpB2A4t9~vM8-i2$R>(yhAM8&O`jqAwYvQ6Xx7k%f3^6G
z?%@R?A8~Cu)GWQuoLrbm3w#DV#uHaKV)@utUEAADO${uz_K%(11BQJJShy{prWH|1
zdOGP*!w_KXwzj_JwplQP+b9B6c&*c7hxa!GtQ=niiw^rmKYU3VJ!EuAWpicAn-0Ht
zD0VA(Nz7q@y{l0=9n%NzYY5)`X=?h6%b`Iw@s$>|b17sIUShx>jh()hTaW@7s@DUV
z@m<U1xbvD5eN^N(0lrqUq(l+zUcYc}t~eu2jVFG43h@`{6-&bwm<Be6USK_j;kyap
zJ8XLFUHIGR!wy0;!D|$cKyrZ?;My5X9|f&ud<7m1xhZWTy^@M!87J$IbU|(&^L#)3
zd8?0+ZssZ7X)r6Ny@c0dV--b`X0ctJ4&mgd(+O1ER3+m*1|-jG1xJT8{y8vHE%4Ko
zjAM;|w8PSudtzpM&f6`d8X7r_@QrvEDD+9r3Xoo}t4bmM@!g--zp@}G+Mq<2n7Y0p
zmhmT}*(@A=V%M){t`j5U?+*9p-8hR^ynd#^Xa642NfeR3HYnuNtCANq&|UOp5$y+)
z2d#w?wF(P70q8#6U2;KS6)~TPHHg)$`l<%FSG&h8zsO>HW?$WoFSsDJ6ihRBfqvJs
zTE%yr5o3Mu37z%yx5M^Cagc{k$@<cEQR=cuQ)YNs*;z@4dUP3E&ssD^5EO7t{wDQP
z<u!-B7s^Vsp@LT~*VU!3-=6gpJ_RHx8B=nPvuO6A1H|Y|%<TusdnS}-3PsZ<nSF6V
z+?NU<=hFfWiI_zC%Z<vFa9hVZmD|53U$)Klp?72Tzkdg*zUrYrZ=vmVaP)}nZt6z0
zC2IV=Zl01Kb>=-vKF{aHWjtVdL-_4^YX>*t`)hVo$qjK~9c$a626bk<&vsTPTS}-B
zo}Dc|3~*(P)HcbdB?St3ON`^xCi+zT?%-KUw1am3HV5CH?Tmf-ac8Pp+(T{kjCIG>
z?tsTHRk_|DM`5-W4HZ|#*UO05qNVk5C{+%Z&CZT)9Th;!fjz^H4hw3SQhY6Gfj^3$
z20KdXyha#^eLkWn>CBeCbgA^2S?FCf@R{xm2axCS31%HUwy54#ejm+0;tjh_955XO
zq9@2JVg`cC>lWf<z=9RHDe!*}3DP7M8N)K1gzG-r+xy%vGF>1p<hGn^Ki_8Ps<U+V
zb5Q+xu~*H<>kD{-sCi+A*gs_Nypc@~xUu>r@O4IMDJU1eaQ=P$glIJepg00sulPBC
z1b7c({M;{qoSy<b{-U6QG1&`sekn5f?{_sNCu`0)0dbt39W*ft>Ren+8Rq2Vm>TpS
zd;h)p<zVh7;)w6a+_(=XXvhEhw#DjAN)SO)sadDU*gLkwq_`jY0CddGlegbBf%pmZ
zfb_`*vN3LX`#Bs=^@t!aTQ)jGn9X~S1Ay!1I*WueUQRA<QmtpydYb)w%bvTYF6If?
zU=>J8CYAeiGF2n_>uNPS5fVLDmlQKWJ3f<v6-E}|`dA#R|HejkdB#kYKUQEByMtGT
zX?K#*Ed!WbKN3IfXlFQ=i|HyOs$8C!AATHp3}6DC>ax!O?b~m{fB_25?M}F_2cTSo
zN{GSK`7w0E3Vlu&<YPYyz+I}E3>HJ7GOdnKc*rF)Y20GB$L)4wCL=71N!|Pbg@1nw
zGyvvx9a@9|<KDYMYhJJx=rvdTS4PqKcI}GaaZDO3y~bn75mNrp4-)6T$svj)c99!B
z4`Asr=NlVno!6LIDVK33LE}eq0MaA8gJgjB)|1UKgm?-DhR$nEj8Bh%QP_$tByS3(
zd^?qFk524b&G#rO;W|ST#(-fh3##xTgB|}Mx>>cTExTpcmFSXubUaZn!ZtO)61;CU
zkAh7}iP?*g=F-ncfC8g=c!)Wm;-`Yh^&{+VvbNB`n2BLs?y^?RSF^Gh02D4~782lh
zu*4><Ovz=%jCRq-F|rN7r72QDB7=5qjA=yp&d-wQoBN}M=V!$pb4fWNLe)JPW-?wG
zZI5o2(PYLoiai9PUx&#L)+PDrr1a5ZU}Tx9`6Us}o8wK>P2%gSHYj66N+)tDJW+`o
zOm71vJQNU<xw4Bn{*qFG0Zb;H7(dG}%OmNw&d3;<%STZwGaD3K{7;P@+gF82YFKzB
z5|I~%Q>a?=V+sx-YsNmPPaU#&r+H%YcQBG^2w6JpE6ikNeubD(@r+7Qiaytgyg=^F
zw0t>mD4x-2u;E#la+h!FT7=*Ikb^D!R>GhUwhh`e0zP7zCiZbv2lNj88Pn3=i^@iK
z3<@37fx@^}!{z}tDXp}_Lm$t4O$vv?kl}F%h%L!>^@xIl7csAfqDzq}w$gZ2YqUWl
zAUM9`jc}T00x!6VUy{2`zB8>-$|-*Mt`$tliAbla2?5_JT6PLl88G1&^2Xi5W++W2
z=cMNVj)*FfW_5st1{@9`KR(#a^JPU5keEU(8fP-#TW2@090?my;q){<%pd?EN)o;s
zo5t%ZYlmG71v+F97Wi|v>`Pvv?W7zuL>ReFtOv>A;K;I~UAWtlPuV1wY{DSD*m{{6
zzN}uDSzpA`{z&H%^;tM8-XPJz`xV6GMCl(wm<fp7?KyLh0<5M9`Ua#VYS*)%WSe#&
zuT4=3dB^_PE&PZZJLq>tU=<(G5{P&j1>QWS>U9a>UzzlLO|Od&U7+iv92qWhCft<6
zUzEgk->D_ActPt(WPx(VVHabk(Q?H3n%|PcF<seVJv*+%7ZW;B^Z59D)<8}Dsjgy$
za0{vr<{F!(0=T*F0Z|u8HI{w7&kHT)LJVQyJCEruL{m0jp`w#k#0_-G50%PtZH2&Y
zolAkbH~V@1(HbZj+Wo{kl7o!dl0)(nDV7hJ)piO8x|et%Wve<t${ihqd)24mSmtX8
zaDMHp9mdOf@F}1AvR1h`JIvpK|MzyZ)HigBu|p1jz+$m;-#Z`H+9DJ%ij5}suFwz9
z<b*@l6k}LxN><-;=1_wIXRIGv6U}JIDuI>6{TGFx|C{cW_lK-NT-iRm2Uyq0GNX;a
z<LtBMJ#dH$?dt@5+$yv9=F#9}_skzB(B4u<+%v28iXu4hV?RipxP|bo#TYa$KA#FX
zr^P8rfVJm5J%(m;W-vW@YnvuUkcT^Cie^nKpT<T^Lu;4^E2RcI);j6ZxH(7&2hNz#
zP>?ueX}k*B@10UhD<Ec$?uFMFmui)e7P^HKnN1;L^8t`3{^EYmcwoXSGQQX2hg|4n
z!+EwxDATP~u2ku3_0VZ1a#UeVxi`0v^{pj%0G7XtTxh!=4+*$?Irp(LbEEW?=bve^
z3NrYnZ)b|+7r6yv8)1>q3IjJBODm@8o~*(J)Un17puz$-TWn7?PvM*5GMvxkWIiZ=
z?#<DX0YN5!1n+~WYeWBbTi*iKM4%@5WuO56ZzkrTbg~u|VZl&mO|eA5`pl8VOP@YG
zKt?)}rCL1-!YJBBcbYM=a9i2{i;G@{$B4?2D`{R*;W;>HP{A?(9|MjR%wSP7TuGKG
zV5e4%!$`JT{1CWaJuu!}P|l!rYSPV&DKgjl;MG>p_(WE|p(283Ntjc1R}L3N(jUC(
zMpfLsd`-S&Ey;+lINB0Lo$AD(xuDP>03kwnZ7p}RuHGz$q+r68jVtrBx9kL69n<fy
zrI8X07<aiyAE}|AQ^Z^r($Eq=5_-HjYX1~1e0Aa;intou<vs@V$|Dh@40{1JttVoB
zSNWfYwX9~&8X{~g!=|9RFJ5m!MmMwi6V;;20ObZs&_aJ-?q=|#{#X4WDy%47fEF2N
z`MG6WpP$U~?#<BM>?2#wRY&IA&du^p<<|qm<|TS9k)<Y>w-0U|2{mgj`ERW%BK81i
zP-Rw`3yi2KEg>8kFwhFNAXF~+T!yJGQy`>Smb$o$?dQN{569XbrOsJ5_1*8xeK0?r
zR&YvOoLpbZuw4d$@03V^S*F)6fKo4dwN>#moZTtVHV;$dnrl0yn!t|fx@G!ju9l%4
z!qpVE0(%KxWS(%s>4~OZCu<s7Nn(Gab~s|>!WNAV<Vy~sHn8)UV}E1kVXXC)d=S+d
zivFJcd=)&P-r&0-h?yg?;EAlrEP9BVQs1cr6A5KA&drEQyX6E;D8`2nU|a$*ES`v`
zzLdj13^l^v2yy*-R~Xl6zh92g-6ZdF`)fIo6IM98?{=GsZK|pbDsUrfY5&AjgFomY
z2;wC?ioaKm*+%jAoHKEK;kX%G2?gP;pWW#2oU_19t^(6M#a@Dc^9}`FBHryZuH3U}
z`^sowUgC~f((M?34?0ONU@Ck?@1-ZKL$kR;IX!nx=-SDi@MU(rKSlBH?6@2&r;B`e
zmU>U3{mrb)he~6Bh1UgdMw6o2x~-V++5AVak?x@fj)jCjy`XUsF60Lip_r&G*Ee_l
zYJ+wXUN1MAFlR-k3DYJh=g>wicsEY7=Q4*RijTTEH&ilILOjw4K*4md7EBB7#{4WI
zryAkYz*5fg-?{2m(Z`uyw`DFOu7f`+@C-NH!(S5fV|?KUZ9j*zgW1d$_mUevbH>}S
zFi${j#Lv4CJb}Jt^^%3q3CMnud>A(9Mzp2s(GKpiqb&0oOkvxHNM1$@Nae=BXjf!G
zGU4x@2V8!rtiGBmfYgvqthGea>zj#o3Z`)cxT}cW1MA4|>PcPe*LcS_ra7k5cTks1
zUh^A&6hE|Jj#s#7B>YRcQ(q?Bo8B<EY#6h`D<i%^_xJveSY)rYUF|s1u2%nk=4%9P
zun9B5CNk`@%(NLJC+K9S`KGHIn;{-H9Fa)iMZ|>IB@`M%z@dcE3SKhf=xO4eXBMH4
zm{fO_e4AtB>3B$#T26~wcZUJW4r14o@h}gpyAq5U(|6B|x3BB?=p*VTs=>lBoMI=o
z((dtzE*CKVsRO6Ox~iQec%+^|)~Aa&*O@~5g7gQg(j$mMs$Mu$=k=F4f~9;rtbZF*
z&oCKrgkB{8&>z0a(+!?;iLd|X`jld-d7{NtoqTC#01t#_?ae5+)j$jYErja*hu$--
zusMN$j_O~PGtlj}sD%WiVhmn{%`8HQIWwwVcp1vBXjuBhzeW*YSM`Vxw_}PLsEQPY
znYz!IHiVk0gRw~?_;htJJ`dwcanLp0_F9}@5>;jepuW7E=X-K|Ep#M|t`Z^R)F9qs
zDS9^ZtY&G*Hoc(4hInw{?X)ds_8H0-9`sO)xjD#tC0xG4*Fi5{WUE@F`3Yo>d3U0@
zH^{+kY!pkj5R+H2lPYJZH|*L4pEQKhw%$V@jN?iqziz!dvk0MUpS-S{Ta^5Sm4s$f
z%$2SJxG){}Q#}Jq(yc!E0phQVIXnelvG~`<26I8GCUPrMsM<tc1`^-nU%R$4V)DMU
zXFJMEO(^-k!*98*tLmA&@DvzUYw}I8nQny72#8tIFCGahwOgw53a$iZ2Mpol$NHt1
z(8QSoqo&xMvH{wbjtv8fG$qiLP&lfyf^C5SXVjJAX0VVJ(kz~Qd>q*nW=YY4b;aUp
zLcDTV$x7|Qa8it&#%>2XIJn#-X!7fh*t+Pin4AhO<7WCz<60)NDpD&9Z*|jf(d4i_
zbY4V=vbMqVAnG6<u_k+}7yHc%cMmGnqfVP{&WJlgi=$er`RM0iw_~Rda=Wiy?uTCh
z*$DO4(D@r}$53v3k~`R#z+T<lnocsVBx;h3r?GJ4;Xn(WUr;f+@K`rA(XUDnI8E4N
z@-XqHB-(O%%-f0Q`i`(Ax>yLm5HI9D$;yl*8X}iuH@5<_W~^<d$P63e|G{rY)XZaI
zKyC~kDB+^^hwMhs_q*!#8Q)^ZOs*gS_2k<eU}|I}Jx(Xzit{U6o^$hWQtwa(8gf?V
zWZ0~vL;>xt0=N)ar6wg>RvHYj%t^A{JxD3Ix@D(O3w$2*;IY9QdVAq(8#(IzBi5-G
zA;Ob>=2aN9j9N9*_ToP<8tSG65jCUzdg4)z!8!^68JWG(?)vagn3H)d3VKOEaeDXo
zt|{v+B;LtQUM9o(rq?!U3$J~^%?l~9MJ8PBuf$>em+_hgX2Ekwy3#k&6b;$e9v8b$
zm`wYonn>e$3%EQNARtpN4qAh{{yFP-%gkatC_YaEfxWZt-qAm)9_REC(ss_n)XN90
zlJgd23djhL!J-O=KH##&SSb(yP1pO4nq9;>{_+|8iSN%MN3<rIBv=H-7*pNhWUw+Q
zT<AY_n;B~NhF$Agc_$7A9|%y~U486nR$d61n%mQ3eF2LmW*%OYkhcAk{GQjTEg9)4
z!sBMXQ3f~1Y}mWjXjH9oGXg*#LDaaNm#TtIW^&`KHvDwSxnv#}wOv&JurVP-vX)ri
zp3%3H$?q<G<Q02Fs(k0$8cTuKo51X0tdekl<{EB1gAI;rR1JV-)*lU3a2--crsG^4
znsjaGc{{E9)^Qjv?xxs4_H5K`Ku}wh%|4#h{CNNGT2^6mg{SCQuZnl1Um@5?YZ8)Y
zF<lMC@8mS}Y|+{a3nB%8OhqA5LaOR==u=5qJCOu*X0@OPt`c?i{U{+enTm#^YbEY3
z5t~{UL2i;14E6*H2`Od^`({Pak@30n-@aEs9tbnEScvWnVr>^|I4sXYg;0=WWSuAG
z&%}5=)LT3%>=~!KmT^;d<j+_78AS)JA1on&K`RU+sNpSHlYlLNoDzph@Ry>2vwS{|
zgA_1hNHVahR=jj34OgB8C5|v~$m;dks2e2ptW;^P{1UtIzSg$?pSf$uJlTpFzmdQ=
zGbQHOgv&zk@j>!HQ@xpG*E3)lY)JU&Y`8>-&x9Tt<2n~7_~3IDZ*@vZhHFQK7}+Z$
zNT`aKkK*$W6njyCk>J+aE66BR0@YD+R7OaR11(ZQjv21e%B+TNiXU4P;wI46qzh4_
zk+o@;?+6d?TAJxXjDDkS+&WIpcI^+iq4pP1;0XjP@NMrO_Y@(Xm(DA>q=wH*y3Gh+
z<{&&UFX6(el*>uJac|Jdh?uR~;&s=(<HtX8iUx{waWnmZ)KDo#dRFLWRx!>(v;NMx
zVoP{pdd;Bw1&Y08JT59am!)JZ0yuvmZK&+DS>}pjXR8xt70B3K1*>cgD2JIuX1J51
zL1F3Rr_u+BE$MvKYhi7NVQgRQqQ$&IV%Y~8aDv-w_qxHqy6tMM!{Z<1=;p<h+ksLp
z!DT|y^|J*4<F_`76!(S0A3?R9AV-dRD$T0D;oZ|(cSMo!nB9ARs0&DyZNYS4gs4{&
zmsRLkKtLmY;pRuC@vmvTw=Phh^}wIL8VR;_wG^tN=ROknGJ5u`ie3Kf6&C)J0u*gT
zIH#Lgv44H)#o@frco%Gd1z7W5C6cPN7V#+q(Me_jV<`3bAv;dBD8Z*X{-@Egx>e0O
zLdw4oeseJOq57aR%Jc?!w1=B1&@|s~N9V85sG3^pNom^e57L#2bNToMV;p<ogvuI_
zFm_7my{Wl=J6w&cTa8;0M&9@0A&UX<^AlcD1<BZHRT78O0EwG~LEf8%m%i@#>tlu}
zoNJc=xykdy&m+baQKrT3zmk-`BDd#HVHfwR2}(`+ztMgAUOF0^78aozOBYlLlptv3
zQJ&G{2y`g2pe5v^`r<~@N~Hv^)FyUc8$Jpqhj}pXq7&4ZqltcbXvp4g^>!i>DQhCc
zb~ViE2&Y%kKc3R5<l!vS&ZnSWfQ5nMqA?%?C}I2KwkV&)(p5PuQOr>kp`UZtq10O|
zv;rL;!b)+;(!Uh_;b0VvN5YSUQ%&M(OqWH|p0d&=@J}3mC}^HR-ce?-v3o3Wl`;*c
zmK7O4aaWF2_-4bvw&Q8mLGo^e8)?$XXYp~M@;paY(e{PEOu8$k*-HMB6XD{)?SFIt
zuIPXS*L#6~?<s-+5D6jX;;B3(nl9$q-;=hK{iF{i7D%Kys^-BqT*#cw<Gz}8H#uU`
z?0WR%<yulx5{ER{f#f{eRq<BPp9Gg%ymxjHO1Q~-3m>aS0eyFx*<(Z!r*+@>it-9e
z1F0#L^^(mGD-1E?N<$mw3O51ezB&$oSJ4R0<gVbh!ZH|)t02jbDz3{m10sJfk?yF+
zSnuu{@0w3iatz-Mo^~eGNim;6vQ{oNBMTo;2Ah^dq;8Z7eV9hoc&N@4J9)Hx4HIi#
z)c&;Q^d!s|8wF6WQ3MEH@UB}w4WB(d*d32zdh*#j2B(rGe?%+j&KA_0!XpeoTld@r
zLWg_DBzbE#`!C82Us0l1t}-_aO(zuUHV!0iW+w_8rzYFS63AR(`xyt3o#MY>29Q1@
z76_;}$XN*j=Pw}^7$`o*T)`YoIgG+R*f`=)Nr@Mj72KJY@ZcS^O)-!VHTeFM3Y1l?
zq2~-;(zCa<?^tR5I|yB*E0suq`lVUB5JeQ7Egmike&)$Rrj5;Z6_MHigO;hym?J!=
zh}UddAWe+4OaKkjxW};~SYX6uu*6Mdo$z?(Iy!m-dLXWE!poT4-hJ6{uw?JFn}igZ
z2>a@b7M;C2%T6lUD+I_1OJ8)v?fyxmDopASc7-O`#Nl%&`U`XkU5-3J3<&GSzBJmO
zNK{041p_mALGEHvZkmlGMn_Q@-v^QYI-^j&eSReemQN}mczw5ku2*PsYt;Sxv)~UW
zGn%X4a|GrqMja>@8r?vVYJ-vy`q1$j>Q&&B_-Q$l99;V*OP<H^tSPX|5m1$A$JRv~
zDk8|u*kP{w4BwdGROJL<I~2qcaSo)NB`9q|TH+W}agJhTn`mDp-3B<|T-zh@BhFU>
zFj4ro(83~8xp90m7yvJ3s5H8)m!J6Fe$?KaMr(=%nIIl?Ld!FWbYNvsxSI%sa9A{k
zp7<+vf0uB$ugfJwF2arBn366o9J`wqP0a=@9?PpD6k5*fZkq{kp5GxFpQGa?i63E#
zX;P7)V{(V}hJXIrFv+tmH#+)DB2-jf#AadDhJ0i|gkYx1hKKzRNiK}%g~=A8nu0B-
z6CLTZ|0f9@xYJpZT8<sr2;JqetDPurcIw48!UKEhd8Eq|mbQ=9tT+OPhXOVpjhc#z
z_u^bBF`Yl;ANvacGpd}CZKgsj4DrUfkA{_f;@#V-4Z^;j!J+D(Xmx1j0$6}H$x<YR
zj-8J4^dL_{g?2HckCGWBUodvGxK({I<d_%L-yUnaUA!Wi*7XH7ff<J+!UHu9Hi`Fe
zieQTpyh_~3Bq9AlTbreVbrKGaNW%UM6$TWk%iQsT4G}KDfU1^LlWYxfi&x*LyvinB
zV`3!XL#I4X0Bs2U=X~zV`0i?~VHiJA_^%D*;rxaVqrC+#%$;$kHdn{AAExv(65o7?
zfmr?*37&@Lp15uiMnt9`G+~}y!_7m8R@`>3Z9zH<H&th4QW^Xxayq5*2pKDrEZ+3X
zkLJOfKh0?Xb3k<!*aQhEjP~Ss_J+Gvi6v}we`kJvw<H>vt)cyz_?@HCa7|g^cZ8B%
zC)d|rvEv}kRlsM?7n3!c&W|;Gqqa?a{)_KC3Nq4c?4z{!M8EJU9g_M=U|Lo#;ByUd
z(L4GMF_rD>2zB|WgDm0Q8~f@GVShZK0(+O+%gYGJ&!gAqnN)TYZ1*{JpiazQ^TOfk
z4n>9%;RR}fGJ+O_0B^A|lvE$}2zpnYrs`dT1&ckReI!hJMJ~MvZiG0z;|ej#cX+y$
zG*GM}eu`Z2d-V_8pSOwu8W*!;OXOO^;=+?cFBHlz)IqI2FWX`hS-oDoXYb5rXN{gd
zatH^s?469*)&!;3xqcrAQ3`s0>}vkaW3=cb3^GK6_;%jYMnNfRM4*RY@4;dt2rrv3
z4u^6`a%$z5TrH$Xo=XZ5ODLZ-Bh&tXf_5jGjCzkzR;w)NQ{jVkp@|GWyU6QWu%9d@
zk{O^Y#D+R-jvQ^A0g0DM2fDSQ2a%=PH}wIeK$@X)*uboKAZdesDMv|@#;$2ML@aa-
z8YeD%$@bk@ZPSvyVyN@(%=Zu$nn73LU-ce|`X721V5;z+svFbg3yU9OmngBxU%F3Z
z0V>0V=IYCglc@(GeR}f+Ze_DTI(NVD!}<|R9q=wtHcy3(`5!i4&u2q7p5`^isv!aX
zE~w;btbuc#nr>W8QZf@#V`Zbs=5}%+u_V?HO}IdP<h5`K`Dv}etYTM9=%B*t#gAh3
z2vP)A&=Jx@qK(ZWwW;+k!D_iQ!TctmRK<r7%S3G^%v8lDM5ApCqU9JyD`ykMyH5cn
z_O{Cw4dV`hu&@;^>GN?!frF^~j`4tCeWFvXL`^f09@5>Ydi%ZUaa7~Bzlo4c`F4Hj
z$R!p`1v$2~^1pusT{V|**POxbAU+A9^zA?!{9cFyld-~4!JtsEpp1^|^%zUzq!{E~
z<Z1f^)K>^uA9lMLqoZA;Nv-$%=G-(jHOtW?7rkw%5$;{PWOoD(cFOV;ER_H~4HD|}
zx)2PYH+r0=XX)T9<`C<rmaoEOqLTSMM<rU9s>b52s*pj5#H{VtzBBD~Ol6)-ypvU}
zmb*~x{fz5J8R0Xls(i_tUsMzU&fxZyUP0k^TidE?Y<2DIbOa-m9PtU<?Dy_EisR6F
z?nT|h-iNElK)>Lmd%h)ln^pnoGkFX1+=-V)W6h1y8Z}SX<Cn5F7d@_E(SFL-vt7XT
z2gEb^0z~O-FKi+UsQtgbd||Vcl_j_n?$i7N;c-ipSP|Ouoz^l%fI9d%dUqGweZdz*
z|8)M_dp=F0B&RUd@7-spKJN#xbSh(o^^q_|i9`_zkYgW0W~Cfi7`p%lCd`N*^l@Jv
zm94ONEtinBcJtJ*m}A4VM)8OCuwR_%N-Fh2VE@i5QOC^6?}Iz+kRr-t_SO)T#X95*
z(FXMcOUkO;J)dgwH{LXwM|2s1u1nloE2ly-#G~<dlJ=omW-HUn%|4dU-9a9x@-&iU
z{jm{mbswwT?l}Yg{W}=Ie;Z)_(Je}ov_bIHyXTa>ogiD{=Bd*hetthWh;K;JfAtC<
zH^S<gM;9@cR3d>ZZ2JBN7u;3vDx^)9aTtYZR55vbnvn5jK$5*8oU?B1@jhf={Ny}S
ziNeSx`AMYdaw>u4yMHuf$irnP+qCVjyWY4bIvELfM!U<$50nU)N<iq>@wDa~Y_r&#
zKEV~pGlCA5!YsD1i_{9AA1hOhG@nDm>1JC1(L!btT@hQNnq4eC6stXF*_3cAGG`f&
zN&8B%czEa%9OT!0QMHnTv5Z1n4C&#>lv$AvG=j;YonA_Q5W!oAa0Lm%NYMrnpC(wn
zfDx13UAjc%hRg=6qG@}zdpwtSy=a_PoOHuT5JRT595RLPrd1MP9SI9YA#l|eKcZs6
zuI*m~&r*S11E*3UYh|V}y>c0QGn5a+nQ-C~i|CL!AhWw7T($4<_W*(NG31utC_xqC
zsY#Hj7ZXc-B0Ec1+2Xw1e~6svcE*<nNU|WZ!g$kDaLxmOEPF3aCRBwkFmpKh2Pzll
z$YhiRXu%Uh#IGJbdh7trZ5b)kgH!XLMghrQWwo026TsM6EmHbokfxpcLcMl%G!9ri
z8m;ABlB=qTcaK?;`xzS&j%MNQo5tU$8N@%?PdoagX;Ea7CPe#n+DJa@hDU}+j6K;!
z`H7F>MRb4y1pF$e6n$8qn8GE0>OGloq>-cgX{yv&pb1_hvUbw|iTjEYQl7X-3EcKd
zCMn2;B5b4@#K5M`Qfuhcj2W(^kq<j{JF9uAp?rkth%x$H1K(~D@TeQRIOEtM+n8J;
z&-NN~PBH#7n0>n1Cl#+>XJ@CYAbJ-T?gvyGG06a9k?qvLpvSeP))^Jc-MoxI!wz4j
z0!J;DwxvRTXz(Y&(SaR(ec)o2Y;a)|$u(2|q1ezG*Y@75FS6l^gI}s-Q!bnR7LI7`
z=v(O`R(d`6&foBHm5Zqp;S!U2h?buy+k6ib;-rX+P|4avj$wTxuME(`#N9&gukcCm
zPp<&lh>)6c)F<x);MMn$U;C$f1iONM6rLwB6Ssw64dRXI8L+&T=EG_!kG_4O5#dL$
zY}OMx`x7X!pwZ(GavDwR8B%|t?Te!bs1$*#mJ=b-rz#n)&94s)Y=n8<{-KjhIt^OM
zoQqEvMb-`#zA`k!S+Lz2P3oW@Q{(H0;zR(PprZkP085#nUR>U$0|*5NgMzq8u7;)3
zP!Vk?wXyWC(VzAZGJJLC6Xh6J5ce*s-5UQr>xl<FCm69tsi1OW%Ar#bS;bxIJiZ*J
zd1|4odFtgK)vv6kC!&Wk@tRIS+Lzy!bGoTOmR774!ws9pgh_b`oia^enwr}~3QvH#
zkzj!5{V732{zla1AKxoQJ8wJp!)2krK56O$Y+iLX)~qn<X_`t97>PwJV#?iyG8U3B
zcm$p&2C%U9_jd9Ibf0DGCT7Nz(}TA}#yL%4S{JuHd@AY1^`WG)#g3sV0FiMBkFh)z
z_=*5;uV0n>yXd+6s&pyrPMroFhHL<e50l)h=q~ZCi!M|S`Okd*CrPhdqIZA4lA4rA
zgcH{R$^IX`d<8WFF|_l0dbtYEMH{|6H8PX(tbm9QU#UtZW3;$^!`%a}ZM>Io3id$c
zUaB5=AITlh%^`^l(BBf9-CTnqLt=u#EL3#~nuz9weYfBK1rSqh)An91e{KOs@}P2|
zHAb=$u87pGo=6G>FrMp3d2*Kf8%h<AMN8LzTjO-c_DjQ3Fpc)e{Rg#TykV<t{W$_j
z;mLhqwI0-RoeYaYft<smpRRq~*6=?`a2CYLNg)tPu#<qO=M{5WMaUAZJw8#Ub^6MO
zBW@f4*3Y`}eP@gFK&i%Z`r&{NQn$Z83b?BQ-{p7lAD-!5UtPN#xt|R;c~(1+f&LQ3
zk?P)*N{by{didj?2Ty_quGk1lGeP;~7s8p1ukV~YvdwS(h78|EsxAY7?o4@PUF~Z&
z6XK45hbLy=2(xjytCf{d*bq6|F4B;B#MET|(zqnL(td|>a8@Gix&uJ^(bvT)v2Atk
z<E8dW9F#K(Ur?Vk3(bf=YnYL1Oh30%?_?vOIea&7fS!$<2-=|M(JA~<j6(MaqNVcP
z&*tCH5^bnP*u3tReMoPyyQIk*0sb*D2IOGtK=k)BF%8YB={cOI<A+M-@0S={M(xQ{
zlGjxk4F#?|U<2H4mXH9LUNI32f;wa$c^hz&CzD?SITwGFebXaAs?7}8g%OKamVkgo
z)R1es%b>owNO~xW(#2|-4d(*|hda;#Lo)(9&(Bws+slDoV3*D%<>6#|M4c-9MgG_b
zyG}Hfs7T;aXN0c5$ix_{m9e<>v1DisWKq-fgEWO?)|i4<^<n|v$m+$^!?EXoAsy%g
zhgwBT%+2hFEzIo+{ybW(GK4>mIoB<u<z^-}55KE^4sa>!>jjlTEV+CjG^50BzT<dD
z(uOkeZ%7RZs&)FyB!pord@c}K@~2K(6iNd}M2c%9%&l`WrrrMDGh!>3mH6dmuWUt;
zxB^NAR-%4WcR&D8D(b||$2LePmY%oIAa9-;dz5)~GlQd;BP?m*$j1K+`<v<;ktY19
zQsGc`Jh@80(6cktn0YQu|7?WK$mX=Bn9Br{b~Kf3;#!wZuwnwKOK$Q|O;=s?!o~*=
z<1y6K^{ZZ7-cW3!K;nU#34Crz+Y5^p0AHnf@{Cp^Erta+L89}u`TE7p88r$c;L}^f
zMs?mL<;mXteJgtFtAOa-*>{Yx9vu3tlOW~2!Qq5{NunfOxAgO!e)M9ZYlXi)toi0Y
zXZ8D&-*~c+Tiw0tEiTNm3J(y*H3hEKol)v<%3$-dA-1Pq4}Z-9O!&tE$Y||ZOUN@@
zl<iNdnq~sv2`J-4kYWsq6h}4);oXEkr){I+MO=E-1MPb%feyPTu|;vD*UdVuHy}!_
z?kt)g__1E+(skEux=!?MVZ-UW^U$1~(-Ti}GREX!sk=!9sV>EXYBAwq2J8)_sN9mV
zlOP3aJ2=H?`+H{b>FDd*uQ+-?Jioo5=$6gM>un9dQn6V@wy>t-Y>J^x_0L@CCTi<!
z=VZGNJhEdO9S^6(Vo22T2Pt%8xR}Fr%QK&qc=%o*B&b*!a%05#+E;IaV6|m>VrMr*
z(Dr&aR{$0Pcn!&bn}}yNEPlL!A)=w4S_g^yo!*x1&oj-S7#-65;R$d}qeEQ%g<sox
zDZ?^==`p3|!Pl!TjUzvw<`|Xl(h}+z?y}O(v~|n)`8xB#e*IE;H|nwv(X-kvzXUeY
zOBh?HGM6=G9z_Q^#<U?df-(Bz0DcMn>9<OVj&fFS5*Go=QZ5JX?_R)K#fZj!G`1OY
zG;00k7Ncl32(>H+TG6-s2iR^`ny8ih#6=+>D{?-(!1pdu1w9|{_GATCRe-n}CvrmH
zjxrS?8Cwz%MK|r6g7;Jf)78C<md&YQ0&<z}T9=q#duaxBgyZWX`_{r9(YWS9?5M~z
zpPE<`)!Xx0hI1c1Z*!&TP~8y@B;u$56FngpM|I25#d@FBh19gsu8!Zn8`~_~5!DEg
zd_nV6t1D8^rDt1Jy?ZpY%Bt=^oY*U%V>skSt}vmebr@FZ{q4}{yOJ5uEo11dQ4sP9
zOJ0xGsr+nN0JEB&De?DX>(cll7Z-EHM*_0?S<)i}(q{*15Un!F={1)6PWD}2?qGPU
ztlFVO{X!cFl5Q&I2Cc0bD`gS(&$tR8Kl>7#)l~x3_V+EiY}nJ40dT?&ABQg)kwnaL
z1WUWei^WRAhQo~f@L>;bX><ER^7BBZg*(LI2c3NE&#LL1UJYCYI%4FpE+cT8o`~5-
zBAhTH(LuG2u}L+UU$KceMKSg(MydL5hUlXc0n2a(X<ng#`ii^ueM*U!!VqYHziQ@A
z-QtXwxUS+NA24Ki;RH2<t2KIq)EjTe<I+Qthg1bHMX&6IiCM8P!!IvUDK4a9WCNVw
z7a^^${7%2?dqIo7NS%R4waqZY3*2bnLq)QXx!e0{JJ@SZbi`o1Wrz9dp#drI96r|P
zI98rM?!W1;1#m+uG{9HhqIs-<T_uAOtcgY69Kx8fK;qc(Wi3N_QN~T0;?*lUusxGN
zRXYBH?aL!Zr*D@nNQpiI8L5|8%fi8Y81dGpVKNCkKAod-jk(p~mChDq8BWU7S5tPC
zl*0TywDi#O9skaIwJ<pL3y?~&8Tu@mrS;}TJRydWrt+t^oeH#Cz*hXf{HL4LN;n@E
zd^!^TQ1aa|vu#+oQHli;%a~wWfm;zT>m;3;Y{r8%Ee%1h?xBDyi!yA8nbJ3S<-{nd
zA?C1}To<5SyOm&ndUVvnY86@`Leg#Hxd+wghj<9i;*&iro=z?E+XTH#j<OBYO<gmb
zRCmumm&r{s+z?H=p}7%|&_7OAGJ#gW+>61`Y;-ixtY~?^8bg7sb}keGT4<vEP-Qe!
zUwI-UDFtz@&)>sj)*}mtt&Py4Kda@poC$1;-*+hq)x}yZ%-8fQW>M{FQ`2#4`1!`Z
zv4|5hwK+>K<P6om5d(27FNjG6LN#7zR$&3dkV9eUEBDi*z$6vm@UM)JTFWeLf}qS;
zAUac8Esc48oIM-pb;j~3Bn5xFiv5jHM-@cG@?<H%1GhU&$9Nlbc@4M7Kw+NcN{+cw
z#v4+#DasOm!Au3Kq;uV9hiO)ZJ8^!|KIkIKvQ0wooGUjP{fnb<jd4}8{Rj4NgBew{
z%@k5zq{70FU(E<0&rx!0SY-CnR#c^8eW^&yhxLPWJU;Ieg{53|R66BOm66u*NqnY4
z-R<Vg%cr7j{=THhQ1hT%8l6srGJ^z<?0<0;<46zk$%$+k6@RjZ?Nm{P^SAuZ^kI1!
z<liH~AM(&Q*18R3j*jAc2NpG#!#cq)v%L!x=%H-hVi9jZeEMqiiSfoEJL{eTO2mwj
z)s7hnb34+q*#P^+MF;~Ja!3_AL5U0x9yxK$5_<Ua(iN;OK<9LuP2kSZ@DqspyVU^C
zdACzB8GJ3t?8pgYreE$8_>zlef%rFzy+4|>Nf>VN{fJ_;#^^b|CKjThT$<cOr0Q+r
zyp$HiS(gw1B^tL{<>^s!vV!;To!W6=1RtLXfKs0=^lhi|AWf{q_Eiy*Wt_VG-EL%&
zurFDO2{}?Q1nnU(5~=HN-49~V9$~hCKb`WTwd&RWAaV`?lmF7Ffuz4jn$AE54>}5k
z31SiY13N8qo(_*^Pe-$cqc<I_E<63Gh1tq{IyNkT4);WR5hM84vN<cTp#y_~VVU~=
zJjZ5hLod(*q?O4s0=l<dSnZk;FM=k%vpiFBH0Qp?{7+MQrjLPnj3)*$F(#-~W&^#H
z(p?Oe#0YiXyWOn|Bls~Fz8^HQzx0x((+-V>T%-2rt;Ru}8^y3|t|)P%pvmks80bQt
zWC1;3)Yn*D0U5?K(kbf@+O-y4@eHllgkYCwSn^UkVNsjCdQ<obywE%m;aMtua{K5e
zK-O#L@1-@2rb{syU*a|XzZA@yLT-}NxWIS5$smhs_6b7VQch#W1_pk;5tS9V+?hkv
zf)+1N$=zATo;5do)4Z)AGvZ!2pz=+llE?`-SVQY4rd@23M-pr7r#%Mei&UuHyf54?
z#bw9|GG+No7Dh$n7;94?MWNaaG$NtTu)<qE>Q6_kGl)FPbPiysgjc^Q$bzkJk9zoR
z?JCw0!gt#rAF})Y&++l_QJc`gS7F2567m}h)n1%Lt(*ki!mmUaet#BBySJSuV=x%-
zyA3pYE^BuNzd*ehSK|~dE96rIMea^9cDJ7|c4^Nn+jLkOKx4Bw#Q%k{QXK)1AQ^eH
zcr8z$#QR=&iHy1-EdK?4DAcW>n%!*<b^_C&ca9r6mYA9UyS~^Bs>_S@9F<%e4TP55
zT0o~I(SlerKE|9+2qfH&U!<F9s)tU?1PeopE0L>oGL-(-Bfvjgi8fxPX{aVbP=HSW
zzrXIJ<|e##2EVDPV)7(UmrDI`y}zC?!uxW|{ifpF{Lo)nhLqJ0`!r05++0ymqcZ7|
z;qCI^;Qr+&xd0R$diIcLT=^fG)wfA5fCv~6nq(+D#Dq4o2i_+-;hX)v5gytKn##|O
zwyop`J8^?ymy{&d<?p-XQI$$9KykKhINL#HNMMHV7u+CH1wyVI3!)_FTId13>7a1{
z4^v$ny`)1+HIGcEleVVGZ40#okr(UG&jrl!hs+$>7N*&=mKaO76;j&%7=JP*l_Lqj
z17PFbR(e+O3|!(eFoKSExum)cG-gFvfS%Zhv=flq0p%J}3IRKzQz!xh_~K((1MtsN
zqf}u$?flABx2dz6gz<JDX(ddzT9vb(nEk%N`f3UDK7JP}?bKowu$;v*fi7FC)`GKc
zUQUAlQYXg((}krNLzQfs$<k?ij;WIe`?GaqD4H(uqhe_1h2XVcoK(23?LBdO%So$N
z=F9_o<efpD%|>o5VsWpVel+HX>EE7E&h~?XY23L^#>%27ohBb?DU^8>bEgvU-?;gv
zoxmXwOkfcDf8@^p&#Rt17S4tHKiY2)ARyR(Jo^7!xyd*Y1i1gB#s25WMf^|azq`R?
z)d)V|-Q<J_dc6NwbpQF<|F0-4_+-LJ^yJ$Jblm@_`TpM^w`77yTD<=kjsKr{FesDF
zBgy|axA#{hI(#a_f0OfF-MsD0U6YL?(D43mO6h-w0s*}+|6`U?;Qh~5`?pZ!|Fa+H
wF(jEZil4?W90<tF(NxLB(aDw3*vaX?Q2a`=;1K^63;VB){u?M8^<Pi_3-!B0(EtDd

diff --git a/back-end/samples/service_contract_example.txt b/back-end/samples/service_contract_example.txt
index 8fe03d8..ae5925a 100644
--- a/back-end/samples/service_contract_example.txt
+++ b/back-end/samples/service_contract_example.txt
@@ -64,7 +64,7 @@ Neither Party shall be liable for any delay or failure to perform its obligation
 Each Party shall comply with all applicable anti-corruption laws, including, but not limited to, the U.S. Foreign Corrupt Practices Act and the UK Bribery Act, and shall not engage in any form of bribery, kickbacks, or other corrupt practices in connection with this Agreement.
 
 20. Corporate Social Responsibility
-Each Party shall comply with all applicable laws and regulations related to corporate social responsibility, including, but not limited to, environmental protection, labor practices, and human rights.
+Each Party shall comply with corporate social responsibility laws and standards specific to environmental protection, labor practices, and human rights, and shall implement policies promoting sustainable operations, ethical employment practices, and community welfare.
 
 21. Key Personnel and Resource Allocation
 Service Provider shall assign qualified and experienced personnel to perform the Services, and shall ensure that sufficient resources are allocated to meet the requirements and timelines set forth in the Statement of Work.
-- 
2.39.5 (Apple Git-154)


From 623e960bd229fbea2dc37df23139f800375bdbf3 Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Fri, 1 Aug 2025 18:01:28 -0300
Subject: [PATCH 02/13] Attempt to prevent OOM errors at the evaluation step

---
 back-end/stack/sfn/evaluation/__init__.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/back-end/stack/sfn/evaluation/__init__.py b/back-end/stack/sfn/evaluation/__init__.py
index 4ef9146..d9abd6e 100644
--- a/back-end/stack/sfn/evaluation/__init__.py
+++ b/back-end/stack/sfn/evaluation/__init__.py
@@ -58,7 +58,7 @@ class EvaluationStep(Construct):
             runtime=lambda_.Runtime.PYTHON_3_12,
             architecture=lambda_.Architecture.X86_64,
             timeout=Duration.minutes(15),
-            memory_size=128,
+            memory_size=512,
             environment={
                 "LOG_LEVEL": "INFO",
                 "CLAUSES_TABLE_NAME": clauses_table.table_name,
-- 
2.39.5 (Apple Git-154)


From 7023d6cfb64ff4bd7bee12edf7e40a09181791cd Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Fri, 1 Aug 2025 18:06:51 -0300
Subject: [PATCH 03/13] Add draft clause classification eval script

---
 back-end/eval/.gitignore                      |  19 +
 back-end/eval/README.md                       | 164 ++++++
 back-end/eval/eval_clause_classification.py   | 491 ++++++++++++++++++
 .../eval/ground_truth_sample_contract.yaml    | 400 ++++++++++++++
 back-end/eval/requirements.txt                |   7 +
 5 files changed, 1081 insertions(+)
 create mode 100644 back-end/eval/.gitignore
 create mode 100644 back-end/eval/README.md
 create mode 100644 back-end/eval/eval_clause_classification.py
 create mode 100644 back-end/eval/ground_truth_sample_contract.yaml
 create mode 100644 back-end/eval/requirements.txt

diff --git a/back-end/eval/.gitignore b/back-end/eval/.gitignore
new file mode 100644
index 0000000..07f73b6
--- /dev/null
+++ b/back-end/eval/.gitignore
@@ -0,0 +1,19 @@
+# Test results
+results/
+
+# Python cache
+__pycache__/
+*.pyc
+*.pyo
+
+# Virtual environments
+venv/
+.venv/
+
+# IDE files
+.vscode/
+.idea/
+
+# OS files
+.DS_Store
+Thumbs.db
diff --git a/back-end/eval/README.md b/back-end/eval/README.md
new file mode 100644
index 0000000..93782f7
--- /dev/null
+++ b/back-end/eval/README.md
@@ -0,0 +1,164 @@
+# Contract Clause Classification Evaluation
+
+This folder contains tools and results for evaluating the accuracy of different Large Language Models (LLMs) on contract clause classification tasks.
+
+## Overview
+
+The evaluation system tests how accurately different LLM models can classify contract clauses according to a predefined taxonomy of clause types. It compares model predictions against ground truth data and provides detailed accuracy metrics.
+
+## Prerequisites
+
+### 1. Backend Infrastructure Setup
+
+Before running evaluations, ensure the backend infrastructure is deployed and configured:
+
+1. **Deploy the Backend Stack**: Follow the deployment instructions in the [main README](../README.md)
+2. **Populate Guidelines Table**: The DynamoDB Guidelines table must be populated with clause type definitions:
+   ```bash
+   cd ../scripts
+   python load_guidelines.py --guidelines_file_path ../guidelines/guidelines_example.xlsx
+   ```
+3. **AWS Configuration**: Ensure your AWS CLI is configured with appropriate credentials and region
+
+### 2. Python Environment
+
+Set up the Python environment with required dependencies:
+
+```bash
+# Create and activate virtual environment (if not already done)
+cd ..
+python3 -m venv .venv
+source .venv/bin/activate  # On Windows: .venv\Scripts\activate.bat
+
+# Install dependencies
+pip install -r requirements.txt
+```
+
+### 3. Environment Variables
+
+The evaluation script uses hardcoded DynamoDB table names that must match your deployed backend infrastructure
+
+- `GUIDELINES_TABLE_NAME`: DynamoDB table containing clause type definitions
+- `CLAUSES_TABLE_NAME`: DynamoDB table for storing clause analysis results
+
+## Test Data
+
+### Ground Truth Dataset
+
+By default, the evaluation uses `ground_truth_sample_contract.yaml`, but you can specify any YAML test file:
+
+**Default test data** (`ground_truth_sample_contract.yaml`) contains:
+- **35 contract clauses** with known correct classifications
+- **Multiple clause types per clause** (some clauses have 2-3 types)
+- **41 different clause types** covering the complete taxonomy
+
+**Custom test data**: You can use your own test data file by specifying the `--yaml-file` option:
+```bash
+# Use custom test data
+python eval_clause_classification.py --yaml-file my_custom_test.yaml
+python eval_clause_classification.py -f another_test_dataset.yaml
+```
+
+**Test data format**: YAML files should follow this structure:
+```yaml
+clauses:
+  - clause_number: 0
+    text: "Your contract clause text here..."
+    ground_truth_types:
+      - "Clause Type 1"
+      - "Clause Type 2"
+  - clause_number: 1
+    text: "Another clause..."
+    ground_truth_types:
+      - "Different Clause Type"
+```
+
+## Running Evaluations
+
+### Basic Usage
+
+```bash
+# Run evaluation with default model and test data
+python eval_clause_classification.py
+
+# Run with specific model
+python eval_clause_classification.py --model-id us.anthropic.claude-3-5-haiku-20241022-v1:0
+
+# Run with custom test data
+python eval_clause_classification.py --yaml-file my_test_data.yaml
+
+# Run with verbose output
+python eval_clause_classification.py --model-id us.amazon.nova-lite-v1:0 --verbose
+
+# Combine options
+python eval_clause_classification.py --model-id us.amazon.nova-pro-v1:0 --yaml-file custom_test.yaml --verbose
+```
+
+### Supported Models
+
+The evaluation script supports various LLM models:
+
+#### Amazon Nova Family
+- `us.amazon.nova-micro-v1:0` - Ultra-lightweight, cost-optimized
+- `us.amazon.nova-lite-v1:0` - Cost-optimized with excellent performance
+- `us.amazon.nova-pro-v1:0` - Balanced performance and cost
+- `us.amazon.nova-premier-v1:0` - Highest capability flagship model
+
+#### Anthropic Claude Family
+- `anthropic.claude-3-sonnet-20240229-v1:0` - Baseline Claude 3 model
+- `us.anthropic.claude-3-5-haiku-20241022-v1:0` - Fast and cost-effective
+- `anthropic.claude-3-5-sonnet-20241022-v2:0` - Advanced reasoning capabilities
+
+### Command Line Options
+
+```bash
+python eval_clause_classification.py [OPTIONS]
+
+Options:
+  --model-id TEXT     Model ID to use for evaluation (default: anthropic.claude-3-haiku-20240307-v1:0)
+  --yaml-file, -f     Path to YAML test data file (default: ground_truth_sample_contract.yaml)
+  --verbose          Enable verbose output with detailed logging
+  --help             Show help message and exit
+```
+
+## Output and Results
+
+### Evaluation Metrics
+
+The script provides comprehensive accuracy metrics:
+
+- **Exact Match Accuracy**: Percentage of clauses with perfect type matching
+- **Average Precision**: Precision across all clause types
+- **Average Recall**: Recall across all clause types  
+- **Average F1 Score**: Harmonic mean of precision and recall
+
+### Output Files
+
+Each evaluation run generates:
+
+1. **YAML Results File**: `results/accuracy_test_YYYYMMDD_HHMMSS.yaml`
+   - Detailed clause-by-clause analysis
+   - Predicted vs. ground truth comparisons
+   - Individual clause metrics
+   - Overall performance statistics
+
+2. **Verbose Log** (if `--verbose` enabled): Detailed execution logs with model responses
+
+### Example Output
+
+```
+Contract Clause Classification Accuracy Test
+============================================
+
+Model: us.amazon.nova-lite-v1:0
+Test Data: ground_truth_sample_contract.yaml (35 clauses)
+Test Time: 2025-08-01T09:15:42.443599
+
+ACCURACY METRICS:
+  Exact Match Accuracy: 1.000 (35/35)
+  Average Precision:    1.000
+  Average Recall:       1.000
+  Average F1 Score:     1.000
+
+🎉 All clauses classified correctly!
+```
diff --git a/back-end/eval/eval_clause_classification.py b/back-end/eval/eval_clause_classification.py
new file mode 100644
index 0000000..9b81fdc
--- /dev/null
+++ b/back-end/eval/eval_clause_classification.py
@@ -0,0 +1,491 @@
+#!/usr/bin/env python3
+"""
+Simple script to test ClassifyClauseFunction accuracy against ground truth
+Allows easy tweaking of prompt and model_id for experimentation
+"""
+
+import yaml
+import json
+import os
+import sys
+import boto3
+import logging
+import argparse
+from typing import Dict, List, Set
+from datetime import datetime
+
+# Set environment variables BEFORE importing lambda modules
+# TODO: get DDB resource names dynamically (CFN
+os.environ['GUIDELINES_TABLE_NAME'] = "MainBackendStack-GuidelinesTable52F2F85C-BLPR5YN3XTT7"
+os.environ['CLAUSES_TABLE_NAME'] = "MainBackendStack-ClausesTableB80AC60F-1JDQ7Q8DBVI9A"
+os.environ['BEDROCK_MAX_CONCURRENCY'] = "3"
+
+# Add the lambda function modules to path
+sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'stack', 'sfn', 'common-layer'))
+sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'stack', 'sfn', 'classification', 'fn-classify-clauses'))
+
+# Configure logging
+logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
+logger = logging.getLogger(__name__)
+
+# =============================================================================
+# CONFIGURATION - MODIFY THESE TO TEST DIFFERENT PROMPTS
+# =============================================================================
+
+# Original one
+# PROMPT_TEMPLATE = """
+#
+# You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
+# You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
+#
+# This is the clause you are reading right now:
+# <current_clause>
+# {clause}
+# </current_clause>
+#
+# Rules of thought process:
+# <rules_of_thought_process>
+# - Making deductions is forbidden
+# - Proposing premises is forbidden.
+# - Making generalizations is forbidden.
+# - Making implications/deductions about implicit content is forbidden.
+# </rules_of_thought_process>
+#
+# You task is to say whether any of the following possible types is highly applicable to the clause:
+# <possible_types>
+# {possible_types}
+# <possible_types>
+#
+# Examples:
+# <examples>
+# {examples}
+# </examples>
+#
+# Follow these steps:
+# - Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
+# - Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one and determine if any is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags.
+# - For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
+#
+# """
+
+# Clause type distillation
+PROMPT_TEMPLATE = """
+
+You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
+You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
+
+This is the clause you are reading right now:
+<current_clause>
+{clause}
+</current_clause>
+
+You task is to say whether any of the following possible types is highly applicable to the clause: 
+<possible_types>
+{possible_types}
+<possible_types>
+
+Rules of thought process:
+<rules_of_thought_process>
+- Making deductions is forbidden
+- Proposing premises is forbidden.
+- Making generalizations is forbidden. 
+- Making implications/deductions about implicit content is forbidden.
+</rules_of_thought_process>
+
+Examples:
+<examples>
+{examples}
+</examples>
+
+Follow these steps:
+- Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
+- For each possible type, look at the corresponding examples (the content between <examples> tags) and distill them into a definition for the clause type. Write all type / distillation pairs between a single <distilled_type_definition></distilled_type_definition> tag pair.  
+- Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one, together with each corresponding distilled type definition, and determine if a type is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags. 
+- For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
+
+"""
+
+# Verbal reinforcement prompt
+# PROMPT_TEMPLATE = """You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
+# You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
+#
+# This is the clause you are reading right now:
+# <current_clause>
+# {clause}
+# </current_clause>
+#
+# Rules of thought process:
+# <rules_of_thought_process>
+# - Making deductions is forbidden.
+# - Proposing premises is forbidden.
+# - Making generalizations is forbidden.
+# - Making implications/deductions about implicit content is forbidden.
+# </rules_of_thought_process>
+#
+# You task is to say whether any of the following possible types is highly applicable to the clause:
+# <possible_types>
+# {possible_types}
+# <possible_types>
+#
+# Examples:
+# <examples>
+# {examples}
+# </examples>
+#
+# Begin by replicating between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
+# Then proceed by enclosing all thoughts within <thinking> tags, exploring multiple angles and approaches.
+# Break down the solution into clear steps within <step> tags. Start with a 90-step budget, requesting more for complex problems if needed.
+# Use <count> tags after each step to show the remaining budget. Stop when reaching 0.
+# Continuously adjust your reasoning based on intermediate results and reflections, adapting your strategy as you progress.
+# Regularly evaluate progress using <reflection> tags. Be critical and honest about your reasoning process.
+# Assign a quality score between 0.0 and 1.0 using <reward> tags after each reflection. Use this to guide your approach:
+#
+# 0.8+: Continue current approach
+# 0.5-0.7: Consider minor adjustments
+# Below 0.5: Seriously consider backtracking and trying a different approach
+#
+# If unsure or if reward score is low, backtrack and try a different approach, explaining your decision within <thinking> tags.
+# Explore multiple solutions individually if possible, comparing approaches in reflections.
+# Use thoughts as a scratchpad, writing out all calculations and reasoning explicitly.
+#
+# For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
+#
+# Conclude with a final reflection on the overall solution, discussing effectiveness, challenges, and solutions. Assign a final reward score.
+# """
+
+# =============================================================================
+
+class ClassificationTester:
+    """Test classification accuracy against ground truth"""
+    
+    def __init__(self, test_data_file: str, app_properties: Dict[str, str]):
+        # Store app_properties for later use
+        self.app_properties = app_properties
+        
+        # Environment variable is already set in main(), so we can directly import
+        from index import classify_clause, get_guidelines_clauses
+        self.classify_clause = classify_clause
+        self.get_guidelines_clauses = get_guidelines_clauses
+        
+        # Load test data from YAML file
+        self.test_data = self.load_test_data(test_data_file)
+        
+    def load_test_data(self, file_path: str) -> Dict:
+        """Load test data from YAML file"""
+        logger.info(f"Loading test data from: {file_path}")
+        
+        with open(file_path, 'r') as f:
+            data = yaml.safe_load(f)
+        
+        logger.info(f"Loaded {len(data['clauses'])} clauses")
+        return data
+        
+    def get_ground_truth(self) -> Dict[int, Set[str]]:
+        """Get ground truth classifications"""
+        ground_truth = {}
+        
+        for clause in self.test_data['clauses']:
+            clause_number = clause['clause_number']
+            types = set(clause['ground_truth_types'])
+            ground_truth[clause_number] = types
+            
+        return ground_truth
+    
+    def get_clause_text(self, clause_number: int) -> str:
+        """Get the text for a specific clause"""
+        for clause in self.test_data['clauses']:
+            if clause['clause_number'] == clause_number:
+                return clause['text']
+        
+        raise ValueError(f"Clause {clause_number} not found in test data")
+    
+    def test_classification(self, clause_number: int) -> Set[str]:
+        """Test classification for a single clause"""
+        clause_text = self.get_clause_text(clause_number)
+        
+        # Mock request ID for testing
+        request_id = f"test-{clause_number}-{datetime.now().strftime('%Y%m%d%H%M%S')}"
+        
+        # Call the actual classify_clause function
+        try:
+            ddb_values, yes_answers = self.classify_clause(clause_text, request_id)
+            
+            # Extract type names from results
+            predicted_types = set()
+            for answer in yes_answers:
+                if 'type_name' in answer:
+                    predicted_types.add(answer['type_name'])
+            
+            return predicted_types
+            
+        except Exception as e:
+            logger.error(f"Error classifying clause {clause_number}: {str(e)}")
+            return set()
+    
+    def calculate_accuracy_metrics(self, ground_truth: Dict[int, Set[str]], predictions: Dict[int, Set[str]]) -> Dict[str, float]:
+        """Calculate various accuracy metrics"""
+        
+        exact_matches = 0
+        total_precision = 0
+        total_recall = 0
+        total_f1 = 0
+        valid_clauses = 0
+        
+        for clause_number in ground_truth:
+            if clause_number not in predictions:
+                continue
+                
+            gt_types = ground_truth[clause_number]
+            pred_types = predictions[clause_number]
+            
+            # Exact match
+            if gt_types == pred_types:
+                exact_matches += 1
+            
+            # Precision, Recall, F1 (per clause)
+            if len(pred_types) > 0:
+                precision = len(gt_types.intersection(pred_types)) / len(pred_types)
+            else:
+                precision = 1.0 if len(gt_types) == 0 else 0.0
+                
+            if len(gt_types) > 0:
+                recall = len(gt_types.intersection(pred_types)) / len(gt_types)
+            else:
+                recall = 1.0 if len(pred_types) == 0 else 0.0
+            
+            if precision + recall > 0:
+                f1 = 2 * (precision * recall) / (precision + recall)
+            else:
+                f1 = 0.0
+            
+            total_precision += precision
+            total_recall += recall
+            total_f1 += f1
+            valid_clauses += 1
+        
+        if valid_clauses == 0:
+            return {"error": "No valid clauses to evaluate"}
+        
+        return {
+            "exact_match_accuracy": exact_matches / valid_clauses,
+            "average_precision": total_precision / valid_clauses,
+            "average_recall": total_recall / valid_clauses,
+            "average_f1": total_f1 / valid_clauses,
+            "total_clauses": valid_clauses,
+            "exact_matches": exact_matches
+        }
+    
+    def run_accuracy_test(self) -> Dict[str, any]:
+        """Run full accuracy test"""
+        model_id = self.app_properties.get('claude_model_id', 'unknown')
+        logger.info(f"Using model: {model_id}")
+        
+        # Load ground truth
+        ground_truth = self.get_ground_truth()
+        
+        # Test each clause
+        predictions = {}
+        detailed_results = []
+        
+        for clause_number in sorted(ground_truth.keys()):
+            logger.info(f"Testing clause {clause_number}...")
+            
+            predicted_types = self.test_classification(clause_number)
+            predictions[clause_number] = predicted_types
+            
+            # Store detailed result
+            gt_types = ground_truth[clause_number]
+            detailed_results.append({
+                'clause_number': clause_number,
+                'ground_truth': list(gt_types),
+                'predicted': list(predicted_types),
+                'exact_match': gt_types == predicted_types,
+                'missing_types': list(gt_types - predicted_types),
+                'extra_types': list(predicted_types - gt_types)
+            })
+            
+            # Print progress
+            match_status = "✓" if gt_types == predicted_types else "✗"
+            logger.info(f"  {match_status} GT: {gt_types}")
+            logger.info(f"    Pred: {predicted_types}")
+        
+        # Calculate metrics
+        metrics = self.calculate_accuracy_metrics(ground_truth, predictions)
+        
+        return {
+            'metrics': metrics,
+            'detailed_results': detailed_results,
+            'model_id': model_id,
+            'test_timestamp': datetime.now().isoformat(),
+            'prompt_template': PROMPT_TEMPLATE
+        }
+
+def main():
+    """Main function"""
+    
+    # Parse command line arguments
+    parser = argparse.ArgumentParser(
+        description='Test ClassifyClauseFunction accuracy against ground truth',
+        formatter_class=argparse.RawDescriptionHelpFormatter,
+        epilog="""
+Examples:
+  python test_classification_accuracy.py
+  python test_classification_accuracy.py --yaml-file my_test_data.yaml
+  python test_classification_accuracy.py -f ground_truth_custom.yaml
+        """
+    )
+    
+    parser.add_argument(
+        '--yaml-file', '-f',
+        type=str,
+        default='ground_truth_sample_contract.yaml',
+        help='Path to the YAML file containing test data (default: ground_truth_sample_contract.yaml)'
+    )
+    
+    parser.add_argument(
+        '--model-id', '-m',
+        type=str,
+        default='us.anthropic.claude-3-haiku-20240307-v1:0',
+        help='Model ID to use for classification (default: us.anthropic.claude-3-haiku-20240307-v1:0)'
+    )
+    
+    parser.add_argument(
+        '--verbose', '-v',
+        action='store_true',
+        help='Enable verbose output (show prompts and LLM responses)'
+    )
+
+    parser.add_argument(
+        '--quiet', '-q',
+        action='store_true',
+        help='Disable verbose output (hide prompts and LLM responses)'
+    )
+    
+    args = parser.parse_args()
+    
+    # Create APP_PROPERTIES with the model from command line
+    APP_PROPERTIES = {
+        'company_name': 'AnyCompany',
+        'contract_type': 'service contract',
+        'company_party_type': 'Company',
+        'other_party_type': 'Service Provider',
+        'language': 'English',
+        'claude_model_id': args.model_id
+    }
+    
+    print(f"Using model: {args.model_id}")
+    
+    # SET PROMPT_VARS ENVIRONMENT VARIABLE BEFORE IMPORT
+    prompt_vars = '%%'.join([f"{key}={value}" for key, value in APP_PROPERTIES.items()])
+    os.environ['PROMPT_VARS'] = prompt_vars
+    
+    # NOW import the lambda function after setting PROMPT_VARS
+    import index
+    index.GROUP_CLASSIFICATION_PROMPT_TEMPLATE = PROMPT_TEMPLATE
+    
+    # Set verbose flag based on command line argument
+    if args.verbose:
+        index.VERBOSE_LLM = True
+        print("Verbose mode enabled - will show prompts and LLM responses")
+    else:
+        index.VERBOSE_LLM = False
+    
+    # Test data file
+    test_data_file = args.yaml_file
+    
+    if not os.path.exists(test_data_file):
+        print(f"Error: Test data file '{test_data_file}' not found!")
+        print("Available YAML files in current directory:")
+        yaml_files = [f for f in os.listdir('.') if f.endswith('.yaml') or f.endswith('.yml')]
+        if yaml_files:
+            for f in yaml_files:
+                print(f"  - {f}")
+        else:
+            print("  No YAML files found.")
+        print("\nPlease run 'python extract_ground_truth.py' first to create a test data file.")
+        return 1
+    
+    print(f"Using test data file: {test_data_file}")
+    print(f"Using model: {args.model_id}")
+    
+    # Initialize tester
+    tester = ClassificationTester(test_data_file, APP_PROPERTIES)
+    
+    # Run test
+    results = tester.run_accuracy_test()
+    
+    # Print results
+    print("\n" + "="*60)
+    print("CLASSIFICATION ACCURACY TEST RESULTS")
+    print("="*60)
+    print(f"Test Data File: {test_data_file}")
+    print(f"Model: {results['model_id']}")
+    print(f"Test Time: {results['test_timestamp']}")
+    print()
+    
+    metrics = results['metrics']
+    if 'error' in metrics:
+        print(f"Error: {metrics['error']}")
+        return 1
+    
+    print("ACCURACY METRICS:")
+    print(f"  Exact Match Accuracy: {metrics['exact_match_accuracy']:.3f} ({metrics['exact_matches']}/{metrics['total_clauses']})")
+    print(f"  Average Precision:    {metrics['average_precision']:.3f}")
+    print(f"  Average Recall:       {metrics['average_recall']:.3f}")
+    print(f"  Average F1 Score:     {metrics['average_f1']:.3f}")
+    print()
+    
+    # Show detailed mismatches
+    mismatches = [r for r in results['detailed_results'] if not r['exact_match']]
+    if mismatches:
+        print("DETAILED MISMATCHES:")
+        for result in mismatches:
+            print(f"\nClause {result['clause_number']} - MISMATCH:")
+            print(f"  Ground Truth: {result['ground_truth']}")
+            print(f"  Predicted:    {result['predicted']}")
+            if result['missing_types']:
+                print(f"  Missing:      {result['missing_types']}")
+            if result['extra_types']:
+                print(f"  Extra:        {result['extra_types']}")
+    else:
+        print("🎉 All clauses classified correctly!")
+    
+    # Create results directory if it doesn't exist
+    results_dir = "results"
+    os.makedirs(results_dir, exist_ok=True)
+    
+    # Save results to YAML file in results subfolder
+    output_file = os.path.join(results_dir, f"accuracy_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.yaml")
+    
+    # Manual YAML writing to properly handle multiline strings
+    with open(output_file, 'w') as f:
+        f.write("detailed_results:\n")
+        for result in results['detailed_results']:
+            f.write(f"- clause_number: {result['clause_number']}\n")
+            f.write(f"  exact_match: {str(result['exact_match']).lower()}\n")
+            f.write(f"  extra_types: {result['extra_types']}\n")
+            f.write(f"  ground_truth:\n")
+            for gt in result['ground_truth']:
+                f.write(f"  - {gt}\n")
+            f.write(f"  missing_types: {result['missing_types']}\n")
+            f.write(f"  predicted:\n")
+            for pred in result['predicted']:
+                f.write(f"  - {pred}\n")
+
+        f.write("metrics:\n")
+        for key, value in results['metrics'].items():
+            f.write(f"  {key}: {value}\n")
+        f.write(f"model_id: {results['model_id']}\n")
+        
+        # Write prompt template using literal block style
+        f.write("prompt_template: |\n")
+        for line in results['prompt_template'].split('\n'):
+            f.write(f"  {line}\n")
+        
+        f.write(f"test_timestamp: '{results['test_timestamp']}'\n")
+    
+    print(f"\nDetailed results saved to: {output_file}")
+    return 0
+
+if __name__ == "__main__":
+    sys.exit(main())
diff --git a/back-end/eval/ground_truth_sample_contract.yaml b/back-end/eval/ground_truth_sample_contract.yaml
new file mode 100644
index 0000000..2822cbb
--- /dev/null
+++ b/back-end/eval/ground_truth_sample_contract.yaml
@@ -0,0 +1,400 @@
+clauses:
+- clause_number: 0
+  ground_truth_types:
+  - Relationship of the Parties
+  text: 'Service Contract
+
+
+    1. Relationship of the Parties
+
+    The relationship between the Parties is that of independent contractors. Nothing
+    in this Agreement shall be construed as creating an employer-employee relationship,
+    partnership, joint venture, or agency relationship between the Parties.'
+- clause_number: 1
+  ground_truth_types:
+  - Entire Agreement and Amendments
+  text: '2. Entire Agreement and Amendments
+
+    This Agreement, together with the Statement of Work and any other exhibits or
+    attachments, constitutes the entire agreement between the Parties with respect
+    to the subject matter hereof and supersedes all prior agreements, understandings,
+    and negotiations, both written and oral, between the Parties with respect to the
+    subject matter of this Agreement. This Agreement may be amended or modified only
+    by a written instrument duly executed by authorized representatives of both Parties.'
+- clause_number: 2
+  ground_truth_types:
+  - Governing Law and Jurisdiction
+  text: '3. Governing Law and Jurisdiction
+
+    This Agreement shall be governed by and construed in accordance with the laws
+    of District of Columbia, without regard to its conflict of laws principles. The
+    Parties hereby submit to the exclusive jurisdiction of the courts located in District
+    of Columbia for any legal proceedings arising out of or relating to this Agreement.'
+- clause_number: 3
+  ground_truth_types:
+  - Performance Standards
+  text: '4. Performance Standards
+
+    Service Provider shall perform the Services in a professional, timely, and workmanlike
+    manner, consistent with industry standards and best practices, and in accordance
+    with the specifications and requirements set forth in the Statement of Work.'
+- clause_number: 4
+  ground_truth_types:
+  - Deliverables
+  text: '5. Deliverables
+
+    Service Provider shall provide the deliverables specified in the Statement of
+    Work (the "Deliverables") in accordance with the agreed-upon timelines and milestones.'
+- clause_number: 5
+  ground_truth_types:
+  - Acceptance Criteria
+  text: '6. Acceptance Criteria
+
+    Company shall have the right to review and test the Deliverables to ensure they
+    conform to the acceptance criteria set forth in the Statement of Work. If any
+    Deliverable fails to meet the acceptance criteria, Company may reject such Deliverable,
+    and Service Provider shall promptly remedy the deficiencies at no additional cost
+    to Company.'
+- clause_number: 6
+  ground_truth_types:
+  - Service Transition and Implementation
+  text: '7. Service Transition and Implementation
+
+    Service Provider shall cooperate with Company and any third-party service providers
+    to ensure a smooth transition and implementation of the Services, including, but
+    not limited to, providing necessary training, documentation, and knowledge transfer.'
+- clause_number: 7
+  ground_truth_types:
+  - Term and Termination
+  text: '8. Term and Termination
+
+    a. Term: This Agreement shall commence on the Effective Date and shall continue
+    for the term specified in the Statement of Work, unless earlier terminated in
+    accordance with this Section.
+
+    b. Termination for Convenience: Either Party may terminate this Agreement for
+    convenience upon 30 days'' prior written notice to the other Party.
+
+    c. Termination for Cause: Either Party may terminate this Agreement for cause
+    if the other Party materially breaches this Agreement and fails to cure such breach
+    within 15 days after receiving written notice thereof.
+
+    d. Effect of Termination: Upon termination of this Agreement, Service Provider
+    shall promptly deliver to Company all Deliverables and work in progress, and Company
+    shall pay Service Provider for all Services performed and accepted up to the effective
+    date of termination.'
+- clause_number: 8
+  ground_truth_types:
+  - Renewal and Extension
+  text: '9. Renewal and Extension
+
+    This Agreement may be renewed or extended by mutual written agreement of the Parties,
+    subject to the same terms and conditions or such other terms and conditions as
+    may be agreed upon by the Parties.'
+- clause_number: 9
+  ground_truth_types:
+  - Invoicing
+  - Expenses
+  - Fees
+  text: '10. Payment Terms (Fees, Invoicing, Expenses)
+
+    a. Fees: Company shall pay Service Provider the fees specified in the Statement
+    of Work in accordance with the payment schedule set forth therein.
+
+    b. Invoicing: Service Provider shall submit invoices to Company in accordance
+    with the invoicing instructions provided in the Statement of Work. Company shall
+    pay all undisputed invoices within 10 days of receipt.
+
+    c. Expenses: Unless otherwise specified in the Statement of Work, Service Provider
+    shall be responsible for all expenses incurred in performing the Services. If
+    reimbursement of expenses is permitted, Service Provider shall provide detailed
+    documentation and receipts for all reimbursable expenses, and Company shall reimburse
+    such expenses in accordance with its expense reimbursement policies.'
+- clause_number: 10
+  ground_truth_types:
+  - Taxes
+  text: '11. Taxes
+
+    Each Party shall be responsible for paying any applicable taxes, fees, or other
+    charges imposed by any governmental authority in connection with the performance
+    of this Agreement. If Service Provider is required to collect or remit any taxes
+    on behalf of Company, Service Provider shall separately state such taxes on its
+    invoices, and Company shall pay such taxes in addition to the fees for the Services.'
+- clause_number: 11
+  ground_truth_types:
+  - Service Credits and Service Level Rebates
+  text: '12. Service Credits and Service Level Rebates
+
+    If Service Provider fails to meet the service levels or performance standards
+    specified in the Statement of Work, Company shall be entitled to the service credits
+    or service level rebates set forth therein.'
+- clause_number: 12
+  ground_truth_types:
+  - Background Intellectual Property
+  text: '13. Background Intellectual Property
+
+    Each Party shall retain ownership of its respective pre-existing intellectual
+    property rights, including, but not limited to, patents, copyrights, trademarks,
+    and trade secrets. Any new intellectual property developed in the course of performing
+    the Services shall be owned by Company, unless otherwise specified in the Statement
+    of Work.'
+- clause_number: 13
+  ground_truth_types:
+  - Confidentiality
+  - Non-Disclosure
+  text: '14. Confidentiality and Non-Disclosure
+
+    a. Confidential Information: Each Party may disclose to the other Party certain
+    non-public information relating to its business, products, services, or operations
+    ("Confidential Information"). Confidential Information shall not include information
+    that: (i) is or becomes publicly available through no fault of the receiving Party;
+    (ii) is rightfully received by the receiving Party from a third party without
+    breach of any confidentiality obligation; (iii) is independently developed by
+    the receiving Party without use of the disclosing Party''s Confidential Information;
+    or (iv) was already known to the receiving Party prior to disclosure by the disclosing
+    Party, as evidenced by written records.
+
+    b. Non-Disclosure: The receiving Party shall: (i) use the same degree of care
+    to protect the Confidential Information as it uses to protect its own confidential
+    information of a similar nature, but in no event less than reasonable care; (ii)
+    not use the Confidential Information for any purpose other than to perform its
+    obligations under this Agreement; and (iii) not disclose the Confidential Information
+    to any third party, except to its employees, agents, or contractors who have a
+    need to know and are bound by confidentiality obligations at least as protective
+    as those set forth herein.'
+- clause_number: 14
+  ground_truth_types:
+  - Representations and Warranties
+  text: '15. Representations and Warranties
+
+    Service Provider Representations and Warranties: Service Provider represents and
+    warrants that: (i) it has the necessary skills, qualifications, and expertise
+    to perform the Services; (ii) the Services will be performed in a professional
+    and workmanlike manner; (iii) the Deliverables will conform to the specifications
+    and requirements set forth in the Statement of Work; and (iv) the Deliverables
+    will not infringe upon any third-party intellectual property rights.'
+- clause_number: 15
+  ground_truth_types:
+  - Indemnification
+  text: '16. Indemnification
+
+    Service Provider shall indemnify, defend, and hold harmless Company, its affiliates,
+    and their respective officers, directors, employees, and agents from and against
+    any and all claims, demands, suits, actions, proceedings, losses, liabilities,
+    damages, costs, and expenses (including reasonable attorneys'' fees) arising out
+    of or relating to: (i) any breach of this Agreement by Service Provider; (ii)
+    any negligent or willful act or omission by Service Provider or its employees,
+    agents, or subcontractors in the performance of the Services; or (iii) any allegation
+    that the Deliverables or Services infringe upon any third-party intellectual property
+    rights.'
+- clause_number: 16
+  ground_truth_types:
+  - Limitation of Liability
+  text: '17. Limitation of Liability
+
+    EXCEPT FOR CLAIMS ARISING OUT OF A PARTY''S INDEMNIFICATION OBLIGATIONS, GROSS
+    NEGLIGENCE, OR WILLFUL MISCONDUCT, IN NO EVENT SHALL EITHER PARTY BE LIABLE TO
+    THE OTHER PARTY FOR ANY INDIRECT, INCIDENTAL, SPECIAL, PUNITIVE, OR CONSEQUENTIAL
+    DAMAGES, INCLUDING, BUT NOT LIMITED TO, LOST PROFITS, LOST REVENUE, OR BUSINESS
+    INTERRUPTION, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.'
+- clause_number: 17
+  ground_truth_types:
+  - Force Majeure
+  text: '18. Force Majeure
+
+    Neither Party shall be liable for any delay or failure to perform its obligations
+    under this Agreement due to causes beyond its reasonable control, including, but
+    not limited to, acts of God, acts of civil or military authority, fires, floods,
+    earthquakes, riots, wars, terrorist acts, epidemics, or governmental restrictions
+    ("Force Majeure Event"). In the event of a Force Majeure Event, the affected Party
+    shall promptly notify the other Party, and the Parties shall work together in
+    good faith to mitigate the effects of the Force Majeure Event and, if necessary,
+    amend or terminate this Agreement.'
+- clause_number: 18
+  ground_truth_types:
+  - Ethical Conduct and Anti-Corruption
+  text: '19. Ethical Conduct and Anti-Corruption
+
+    Each Party shall comply with all applicable anti-corruption laws, including, but
+    not limited to, the U.S. Foreign Corrupt Practices Act and the UK Bribery Act,
+    and shall not engage in any form of bribery, kickbacks, or other corrupt practices
+    in connection with this Agreement.'
+- clause_number: 19
+  ground_truth_types:
+  - Corporate Social Responsibility
+  text: '20. Corporate Social Responsibility
+
+    Each Party shall comply with corporate social responsibility laws and standards
+    specific to environmental protection, labor practices, and human rights, and
+    shall implement policies promoting sustainable operations, ethical employment
+    practices, and community welfare.'
+- clause_number: 20
+  ground_truth_types:
+  - Key Personnel and Resource Allocation
+  text: '21. Key Personnel and Resource Allocation
+
+    Service Provider shall assign qualified and experienced personnel to perform the
+    Services, and shall ensure that sufficient resources are allocated to meet the
+    requirements and timelines set forth in the Statement of Work.'
+- clause_number: 21
+  ground_truth_types:
+  - Replacement of Personnel
+  text: '22. Replacement of Personnel
+
+    If Company reasonably objects to the performance or conduct of any of Service
+    Provider''s personnel assigned to perform the Services, Service Provider shall
+    promptly replace such personnel with qualified and experienced replacements acceptable
+    to Company.'
+- clause_number: 22
+  ground_truth_types:
+  - Background Checks and Security Clearances
+  text: '23. Background Checks and Security Clearances
+
+    Service Provider shall ensure that all of its employees, agents, and subcontractors
+    assigned to perform Services under this Agreement have successfully completed
+    background checks and obtained any necessary security clearances as required by
+    Company or applicable laws and regulations.'
+- clause_number: 23
+  ground_truth_types:
+  - Assignment
+  - Subcontracting
+  text: '24. Assignment and Subcontracting
+
+    a. Assignment: Neither Party may assign or transfer this Agreement or any of its
+    rights or obligations hereunder without the prior written consent of the other
+    Party, which shall not be unreasonably withheld or delayed.
+
+    b. Subcontracting: Service Provider may engage subcontractors to perform certain
+    Services, provided that Service Provider shall remain responsible for the performance
+    of such subcontractors and shall ensure that such subcontractors comply with the
+    terms and conditions of this Agreement.'
+- clause_number: 24
+  ground_truth_types:
+  - Exclusivity
+  text: '25. Exclusivity or Non-Exclusivity
+
+    If the Statement of Work specifies that the Services are to be provided on an
+    exclusive basis, Service Provider shall not provide similar services to any third
+    party during the term of this Agreement without Company''s prior written consent.'
+- clause_number: 25
+  ground_truth_types:
+  - Non-Circumvention
+  text: '26. Non-Circumvention
+
+    During the term of this Agreement and for a period of 3 years thereafter, neither
+    Party shall circumvent or attempt to circumvent the other Party''s business relationships
+    or contractual arrangements with third parties.'
+- clause_number: 26
+  ground_truth_types:
+  - Audit Rights
+  text: '27. Audit Rights
+
+    Company shall have the right, upon reasonable notice and during regular business
+    hours, to audit Service Provider''s records and facilities to verify compliance
+    with this Agreement.'
+- clause_number: 27
+  ground_truth_types:
+  - Negotiation
+  - Mediation
+  - Arbitration or Litigation
+  text: '28. Dispute Resolution
+
+    a. Negotiation: In the event of any dispute or disagreement arising out of or
+    relating to this Agreement, the Parties shall first attempt to resolve the dispute
+    through good faith negotiations.
+
+    b. Mediation: If the Parties are unable to resolve the dispute through negotiations
+    within 30 days, the Parties shall submit the dispute to non-binding mediation
+    in accordance with the rules of [Mediation Service Provider].
+
+    c. Arbitration or Litigation: If the dispute cannot be resolved through mediation,
+    either Party may pursue binding arbitration in accordance with the rules of American
+    Arbitration Association (AAA), or, if the Parties mutually agree, may pursue litigation
+    in a court of competent jurisdiction.'
+- clause_number: 28
+  ground_truth_types:
+  - Notices
+  text: '29. Notices
+
+    All notices, requests, consents, claims, demands, waivers, and other communications
+    under this Agreement shall be in writing and shall be deemed to have been duly
+    given: (a) when delivered by hand (with written confirmation of receipt); (b)
+    when received by the addressee if sent by a nationally recognized overnight courier
+    (receipt requested); (c) on the date sent by email (with confirmation of transmission)
+    if sent during normal business hours of the recipient, and on the next business
+    day if sent after normal business hours of the recipient; or (d) on the third
+    day after the date mailed, by certified or registered mail, return receipt requested,
+    postage prepaid.'
+- clause_number: 29
+  ground_truth_types:
+  - Severability
+  text: '30. Severability
+
+    If any provision of this Agreement is held to be invalid, illegal, or unenforceable,
+    the validity, legality, and enforceability of the remaining provisions shall not
+    in any way be affected or impaired thereby.'
+- clause_number: 30
+  ground_truth_types:
+  - Waiver
+  text: '31. Waiver
+
+    No waiver by either Party of any breach of this Agreement shall be deemed a waiver
+    of any preceding or succeeding breach of the same or any other provision hereof.
+    No waiver shall be effective unless made in writing and signed by an authorized
+    representative of the waiving Party.'
+- clause_number: 31
+  ground_truth_types:
+  - Non-Disparagement
+  text: '32. Non-Disparagement
+
+    During the term of this Agreement and for a period of 5 years thereafter, neither
+    Party shall make any disparaging or defamatory statements, whether written or
+    oral, regarding the other Party or its products, services, employees, or business
+    practices.'
+- clause_number: 32
+  ground_truth_types:
+  - Publicity and Marketing Rights
+  text: '33. Publicity and Marketing Rights
+
+    Neither Party shall use the other Party''s name, logo, or trademarks in any publicity,
+    advertising, or marketing materials without the prior written consent of the other
+    Party.'
+- clause_number: 33
+  ground_truth_types:
+  - Most Favored Customer/Nation
+  text: '34. Most Favored Customer/Nation
+
+    If specified in the Statement of Work, Service Provider shall ensure that the
+    fees and terms offered to Company are at least as favorable as those offered to
+    any other customer or nation for similar services.'
+- clause_number: 34
+  ground_truth_types:
+  - Cooperation and Assistance
+  text: '35. Cooperation and Assistance
+
+    Each Party shall cooperate with and provide reasonable assistance to the other
+    Party in connection with the performance of its obligations under this Agreement.
+
+
+    IN WITNESS WHEREOF, the Parties have executed this Agreement as of the Effective
+    Date.
+
+
+    AnyCompany
+
+
+    By: ______________________________
+
+    Name: Jane Doe
+
+    Title: Chief Executive Office
+
+
+    AnyServiceProvider
+
+
+    By: ______________________________
+
+    Name: John Doe
+
+    Title: President and Chief Operating Officer'
diff --git a/back-end/eval/requirements.txt b/back-end/eval/requirements.txt
new file mode 100644
index 0000000..8a431f6
--- /dev/null
+++ b/back-end/eval/requirements.txt
@@ -0,0 +1,7 @@
+boto3>=1.34.0
+botocore>=1.34.0
+langchain-aws>=0.1.0
+langchain-core>=0.2.0
+retrying>=1.3.4
+more-itertools>=10.0.0
+PyYAML>=6.0
-- 
2.39.5 (Apple Git-154)


From 682862dc8ba21f437055f6bbbdef373c7cd10f4d Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Fri, 1 Aug 2025 18:17:51 -0300
Subject: [PATCH 04/13] Update prompt to better suit the latest Claude and
 Amazon Nova models

---
 back-end/app_properties.yaml                  |  5 +-
 .../fn-classify-clauses/index.py              | 73 +++++++++----------
 back-end/stack/sfn/common-layer/llm.py        | 24 +++---
 3 files changed, 55 insertions(+), 47 deletions(-)

diff --git a/back-end/app_properties.yaml b/back-end/app_properties.yaml
index 2717741..10b714b 100644
--- a/back-end/app_properties.yaml
+++ b/back-end/app_properties.yaml
@@ -14,7 +14,10 @@ language: English
 
 # Claude Model ID (Global configuration). To switch to a smaller Language Model for cost savings).
 # Disabling the property will let each prompt execution to its default model id
-claude_model_id: us.anthropic.claude-3-haiku-20240307-v1:0
+claude_model_id: us.amazon.nova-pro-v1:0
+#claude_model_id: us.anthropic.claude-3-5-haiku-20241022-v1:0
+#claude_model_id: us.anthropic.claude-3-sonnet-20240229-v1:0
+
 
 # Thresholds determine the maximum number of clauses with risk that a contract can have without requiring human review,
 # per risk level
diff --git a/back-end/stack/sfn/classification/fn-classify-clauses/index.py b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
index 95a5f6a..f079bdb 100644
--- a/back-end/stack/sfn/classification/fn-classify-clauses/index.py
+++ b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
@@ -27,6 +27,7 @@ from util import get_prompt_vars_dict, extract_first_item_from_tagged_list, extr
 logger = logging.getLogger()
 logger.setLevel(os.getenv("LOG_LEVEL", "INFO"))
 
+VERBOSE_LLM = True
 BEDROCK_MAX_CONCURRENCY = int(os.environ.get('BEDROCK_MAX_CONCURRENCY', 10))
 PROMPT_VARS = os.environ.get('PROMPT_VARS', "")
 
@@ -84,40 +85,38 @@ def generate_prompt(prompt_template, inputs):
 # <contract_segment>
 # {context}
 # </contract_segment>
-GROUP_CLASSIFICATION_PROMPT_TEMPLATE = """
-
-Human: You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
-You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
-
-This is the clause you are reading right now:
-<current_clause>
-{clause}
-</current_clause>
-
-Rules of thought process:
-<rules_of_thought_process>
-- Making deductions is forbidden
-- Proposing premises is forbidden.
-- Making generalizations is forbidden. 
-- Making implications/deductions about implicit content is forbidden.
-</rules_of_thought_process>
-
-You task is to say whether any of the following possible types is highly applicable to the clause: 
-<possible_types>
-{possible_types}
-<possible_types>
-
-Examples:
-<examples>
-{examples}
-</examples>
-
-Follow these steps:
-- Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
-- Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one and determine if any is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags. 
-- For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
-
-Assistant: """
+GROUP_CLASSIFICATION_PROMPT_TEMPLATE = """You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
+  You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
+  
+  This is the clause you are reading right now:
+  <current_clause>
+  {clause}
+  </current_clause>
+  
+  You task is to say whether any of the following possible types is highly applicable to the clause: 
+  <possible_types>
+  {possible_types}
+  <possible_types>
+  
+  Rules of thought process:
+  <rules_of_thought_process>
+  - Making deductions is forbidden
+  - Proposing premises is forbidden.
+  - Making generalizations is forbidden. 
+  - Making implications/deductions about implicit content is forbidden.
+  </rules_of_thought_process>
+  
+  Examples:
+  <examples>
+  {examples}
+  </examples>
+  
+  Follow these steps:
+  - Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
+  - For each possible type, look at the corresponding examples (the content between <examples> tags) and distill them into a definition for the clause type. Write all type / distillation pairs between a single <distilled_type_definition></distilled_type_definition> tag pair.  
+  - Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one, together with each corresponding distilled type definition, and determine if a type is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags. 
+  - For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
+"""
 
 ANSWER_TYPE_TAG = 'type'
 ANSWER_REASON_ATTR = 'reason'
@@ -126,7 +125,7 @@ ANSWER_REASON_ATTR = 'reason'
 def build_tagged_examples_string(clause_types):
     examples_str = ""
 
-    template = """<example><current_clause>{clause}</current_clause><type>{type}</type></example>\n"""
+    template = """<example><current_clause>{clause}</current_clause><corresponding_type>{type}</corresponding_type></example>\n"""
 
     for clause_type in clause_types:
         for example in clause_type['examples']:
@@ -178,8 +177,8 @@ def classify_clause(clause, request_id, number_of_classification_prompts=1):
             })
 
             futures.append(
-                executor.submit(invoke_llm, prompt=binary_clause_classification_prompt, temperature=0.01,
-                                max_new_tokens=4096, model_id=prompt_vars_dict.get("claude_model_id", ''), verbose=True)
+                executor.submit(invoke_llm, prompt=binary_clause_classification_prompt, temperature=0.01, top_k=3,
+                                max_new_tokens=4096, model_id=prompt_vars_dict.get("claude_model_id", ''), verbose=VERBOSE_LLM)
             )
 
         llm_output_limit_detected = False
diff --git a/back-end/stack/sfn/common-layer/llm.py b/back-end/stack/sfn/common-layer/llm.py
index 4f35aea..fb263bb 100644
--- a/back-end/stack/sfn/common-layer/llm.py
+++ b/back-end/stack/sfn/common-layer/llm.py
@@ -36,10 +36,12 @@ bedrock_client = boto3.client('bedrock-runtime', config=Config(
     },
 ))
 
+
 class BedrockRetryableError(Exception):
     """Custom exception for retryable Bedrock errors"""
     pass
 
+
 @retry(
     wait_fixed=10000,  # 10 seconds between retries
     stop_max_attempt_number=None,  # Keep retrying indefinitely
@@ -67,7 +69,8 @@ def invoke_chain_with_retry(chain):
         logger.warning("Bedrock ModelTimeoutException. Retrying...")
         raise BedrockRetryableError(str(timeoutExc))
 
-def invoke_llm(prompt, model_id, temperature=0.5, top_k=None, top_p=0.8, max_new_tokens=4096, verbose=False):
+
+def invoke_llm(prompt, model_id, temperature=0.5, top_k=None, top_p=None, max_new_tokens=4096, verbose=False):
     model_id = (model_id or CLAUDE_MODEL_ID)
 
     if verbose:
@@ -75,13 +78,16 @@ def invoke_llm(prompt, model_id, temperature=0.5, top_k=None, top_p=0.8, max_new
         logger.info(f"Prompt:\n{prompt}")
 
     model_kwargs = {
-        'anthropic_version': 'bedrock-2023-05-31',
-        "temperature": temperature,
-        "top_p": top_p,
+        # 'anthropic_version': 'bedrock-2023-05-31',
         "max_tokens": max_new_tokens,
     }
-    if top_k:
+    if temperature is not None:
+        model_kwargs["temperature"] = temperature
+    if top_p is not None:
+        model_kwargs["top_p"] = top_p
+    if top_k is not None:
         model_kwargs["top_k"] = top_k
+
     chat = ChatBedrock(
         client=bedrock_client,
         model_id=model_id,
@@ -105,9 +111,9 @@ def invoke_llm(prompt, model_id, temperature=0.5, top_k=None, top_p=0.8, max_new
 
     if ('anthropic' in model_id):
         usage_data = response.response_metadata['usage']
-        stop_reason = response.response_metadata['stop_reason'] 
-    elif('amazon.nova' in model_id):
-        usage_data = response.usage_metadata 
+        stop_reason = response.response_metadata['stop_reason']
+    elif ('amazon.nova' in model_id):
+        usage_data = response.usage_metadata
         stop_reason = response.response_metadata['stopReason']
 
     if verbose:
@@ -115,4 +121,4 @@ def invoke_llm(prompt, model_id, temperature=0.5, top_k=None, top_p=0.8, max_new
         logger.info(f"Model usage: {usage_data}")
         logger.info(f"Model stop_reason: {stop_reason}")
 
-    return content, usage_data, stop_reason
\ No newline at end of file
+    return content, usage_data, stop_reason
-- 
2.39.5 (Apple Git-154)


From f7752356daa6b5f31b040d105f8a29197a17b4d4 Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Fri, 1 Aug 2025 19:16:16 -0300
Subject: [PATCH 05/13] rename claude_model_id app property to llm_model_id

---
 back-end/README.md                            |  4 +-
 back-end/app_properties.yaml                  |  6 +-
 back-end/eval/README.md                       |  4 +-
 back-end/eval/eval_clause_classification.py   |  8 +--
 .../scripts/generate_evaluation_questions.py  |  4 +-
 back-end/scripts/utils/llm.py                 |  2 +-
 .../fn-classify-clauses/index.py              | 67 ++++++++++---------
 .../evaluation/fn-evaluate-clauses/index.py   |  5 +-
 .../fn-preprocess-contract/index.py           |  5 +-
 9 files changed, 54 insertions(+), 51 deletions(-)

diff --git a/back-end/README.md b/back-end/README.md
index 6c74e2d..0274c8f 100644
--- a/back-end/README.md
+++ b/back-end/README.md
@@ -177,7 +177,7 @@ The recommended sequence of steps:
 
 By default, the application uses Anthropic Claude 3 Haiku v1. Here are steps explaining how to update the model to use. For this example, we will use [Amazon Nova Pro v1](https://aws.amazon.com/blogs/aws/introducing-amazon-nova-frontier-intelligence-and-industry-leading-price-performance/):
 
-- Open the [app_properties.yaml](./app_properties.yaml) file and update the field ```claude_model_id``` to use the model you selected. In this case, we update the field to ```us.amazon.nova-pro-v1:0```. Replace it with the model id you want to use. The list of model ids available through Amazon Bedrock is available in the [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html). Ensure the model you are selecting is enabled in the console (Amazon Bedrock -> Model access) and available in your region. In case of using a predefined Inference Profile to use a model in a cross-region fashion, consult [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html) of all regions that needs to have model access enabled. 
+- Open the [app_properties.yaml](./app_properties.yaml) file and update the field ```llm_model_id``` to use the model you selected. In this case, we update the field to ```us.amazon.nova-pro-v1:0```. Replace it with the model id you want to use. The list of model ids available through Amazon Bedrock is available in the [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html). Ensure the model you are selecting is enabled in the console (Amazon Bedrock -> Model access) and available in your region. In case of using a predefined Inference Profile to use a model in a cross-region fashion, consult [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html) of all regions that needs to have model access enabled. 
 - Depending on the model selected, you might need to update some hardcoded values regarding the max number of new tokens generated. For instance, Amazon Nova Pro v1 supports 5000 output tokens, which doesn't require any modifications. However, some models might have a max output tokens of 3000, which requires some changes in the sample. Update the following lines if required:
     - In file [fn-preprocess-contract/index.py](./stack/sfn/preprocessing/fn-preprocess-contract/index.py), update line 96 to change the chunks size to a value smaller than the max tokens output for your model, as well as line 107 to match your model's max output tokens.
     - In file [scripts/utils/llm.py](./scripts/utils/llm.py), update the max tokens output line 28.
@@ -195,7 +195,7 @@ In that case, identify the failing lambda function from the step functions logs,
 ```python
 llm_response, model_usage, stop_reason = invoke_llm(
     prompt=PROMPT_TEMPLATE.format(CONTRACT_EXCERPT=contract_excerpt),
-    model_id=prompt_vars_dict.get("claude_model_id", ''),
+    model_id=prompt_vars_dict.get("llm_model_id", ''),
     temperature=0.0,
     top_p=0.999,
     max_new_tokens=4096,
diff --git a/back-end/app_properties.yaml b/back-end/app_properties.yaml
index 10b714b..fd52fa1 100644
--- a/back-end/app_properties.yaml
+++ b/back-end/app_properties.yaml
@@ -14,9 +14,9 @@ language: English
 
 # Claude Model ID (Global configuration). To switch to a smaller Language Model for cost savings).
 # Disabling the property will let each prompt execution to its default model id
-claude_model_id: us.amazon.nova-pro-v1:0
-#claude_model_id: us.anthropic.claude-3-5-haiku-20241022-v1:0
-#claude_model_id: us.anthropic.claude-3-sonnet-20240229-v1:0
+llm_model_id: us.amazon.nova-pro-v1:0
+#llm_model_id: us.anthropic.claude-3-5-haiku-20241022-v1:0
+#llm_model_id: us.anthropic.claude-3-sonnet-20240229-v1:0
 
 
 # Thresholds determine the maximum number of clauses with risk that a contract can have without requiring human review,
diff --git a/back-end/eval/README.md b/back-end/eval/README.md
index 93782f7..ac514c5 100644
--- a/back-end/eval/README.md
+++ b/back-end/eval/README.md
@@ -115,8 +115,8 @@ The evaluation script supports various LLM models:
 python eval_clause_classification.py [OPTIONS]
 
 Options:
-  --model-id TEXT     Model ID to use for evaluation (default: anthropic.claude-3-haiku-20240307-v1:0)
-  --yaml-file, -f     Path to YAML test data file (default: ground_truth_sample_contract.yaml)
+  --model-id TEXT     Model ID to use for evaluation
+  --yaml-file, -f     Path to YAML test data file
   --verbose          Enable verbose output with detailed logging
   --help             Show help message and exit
 ```
diff --git a/back-end/eval/eval_clause_classification.py b/back-end/eval/eval_clause_classification.py
index 9b81fdc..2c3287e 100644
--- a/back-end/eval/eval_clause_classification.py
+++ b/back-end/eval/eval_clause_classification.py
@@ -277,7 +277,7 @@ class ClassificationTester:
     
     def run_accuracy_test(self) -> Dict[str, any]:
         """Run full accuracy test"""
-        model_id = self.app_properties.get('claude_model_id', 'unknown')
+        model_id = self.app_properties.get('llm_model_id', 'unknown')
         logger.info(f"Using model: {model_id}")
         
         # Load ground truth
@@ -345,8 +345,8 @@ Examples:
     parser.add_argument(
         '--model-id', '-m',
         type=str,
-        default='us.anthropic.claude-3-haiku-20240307-v1:0',
-        help='Model ID to use for classification (default: us.anthropic.claude-3-haiku-20240307-v1:0)'
+        default='us.amazon.nova-pro-v1:0',
+        help='Model ID to use for classification (default: us.amazon.nova-pro-v1:0)'
     )
     
     parser.add_argument(
@@ -370,7 +370,7 @@ Examples:
         'company_party_type': 'Company',
         'other_party_type': 'Service Provider',
         'language': 'English',
-        'claude_model_id': args.model_id
+        'llm_model_id': args.model_id
     }
     
     print(f"Using model: {args.model_id}")
diff --git a/back-end/scripts/generate_evaluation_questions.py b/back-end/scripts/generate_evaluation_questions.py
index 1f97fa8..13150dc 100644
--- a/back-end/scripts/generate_evaluation_questions.py
+++ b/back-end/scripts/generate_evaluation_questions.py
@@ -105,12 +105,12 @@ def generate_questions(guidelines_file_path, properties: AppProperties):
             })
 
             if number_attempts <= 3:
-                # Fallback to Haiku, in case latest Claude model refuses to discuss about Legal
+                # Fallback to Haiku, in case current model refuses to discuss about Legal
                 llm_output = invoke_llm(questions_generation_prompt, temperature=0.5, model_id=CLAUDE_HAIKU_MODEL_ID,
                                         verbose=False)
             else:
                 llm_output = invoke_llm(questions_generation_prompt, temperature=0.5,
-                                        model_id=properties.get_value("claude_model_id"), verbose=False)
+                                        model_id=properties.get_value("llm_model_id"), verbose=False)
 
             questions_list = extract_items_from_tagged_list(llm_output, "question")
 
diff --git a/back-end/scripts/utils/llm.py b/back-end/scripts/utils/llm.py
index 1923c90..d546b51 100644
--- a/back-end/scripts/utils/llm.py
+++ b/back-end/scripts/utils/llm.py
@@ -5,7 +5,7 @@ from retrying import retry
 from botocore.config import Config
 from botocore.exceptions import ClientError
 
-CLAUDE_MODEL_ID = "anthropic.claude-3-sonnet-20240229-v1:0"
+CLAUDE_MODEL_ID = "amazon.nova-pro-v1:0"
 
 bedrock = boto3.client('bedrock')
 
diff --git a/back-end/stack/sfn/classification/fn-classify-clauses/index.py b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
index f079bdb..a99104c 100644
--- a/back-end/stack/sfn/classification/fn-classify-clauses/index.py
+++ b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
@@ -85,37 +85,40 @@ def generate_prompt(prompt_template, inputs):
 # <contract_segment>
 # {context}
 # </contract_segment>
-GROUP_CLASSIFICATION_PROMPT_TEMPLATE = """You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
-  You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
-  
-  This is the clause you are reading right now:
-  <current_clause>
-  {clause}
-  </current_clause>
-  
-  You task is to say whether any of the following possible types is highly applicable to the clause: 
-  <possible_types>
-  {possible_types}
-  <possible_types>
-  
-  Rules of thought process:
-  <rules_of_thought_process>
-  - Making deductions is forbidden
-  - Proposing premises is forbidden.
-  - Making generalizations is forbidden. 
-  - Making implications/deductions about implicit content is forbidden.
-  </rules_of_thought_process>
-  
-  Examples:
-  <examples>
-  {examples}
-  </examples>
-  
-  Follow these steps:
-  - Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
-  - For each possible type, look at the corresponding examples (the content between <examples> tags) and distill them into a definition for the clause type. Write all type / distillation pairs between a single <distilled_type_definition></distilled_type_definition> tag pair.  
-  - Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one, together with each corresponding distilled type definition, and determine if a type is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags. 
-  - For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
+GROUP_CLASSIFICATION_PROMPT_TEMPLATE = """
+
+You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
+You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
+
+This is the clause you are reading right now:
+<current_clause>
+{clause}
+</current_clause>
+
+You task is to say whether any of the following possible types is highly applicable to the clause: 
+<possible_types>
+{possible_types}
+<possible_types>
+
+Rules of thought process:
+<rules_of_thought_process>
+- Making deductions is forbidden
+- Proposing premises is forbidden.
+- Making generalizations is forbidden. 
+- Making implications/deductions about implicit content is forbidden.
+</rules_of_thought_process>
+
+Examples:
+<examples>
+{examples}
+</examples>
+
+Follow these steps:
+- Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
+- For each possible type, look at the corresponding examples (the content between <examples> tags) and distill them into a definition for the clause type. Write all type / distillation pairs between a single <distilled_type_definition></distilled_type_definition> tag pair.  
+- Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one, together with each corresponding distilled type definition, and determine if a type is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags. 
+- For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
+
 """
 
 ANSWER_TYPE_TAG = 'type'
@@ -178,7 +181,7 @@ def classify_clause(clause, request_id, number_of_classification_prompts=1):
 
             futures.append(
                 executor.submit(invoke_llm, prompt=binary_clause_classification_prompt, temperature=0.01, top_k=3,
-                                max_new_tokens=4096, model_id=prompt_vars_dict.get("claude_model_id", ''), verbose=VERBOSE_LLM)
+                                max_new_tokens=4096, model_id=prompt_vars_dict.get("llm_model_id", ''), verbose=VERBOSE_LLM)
             )
 
         llm_output_limit_detected = False
diff --git a/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py b/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py
index d64c7ad..17a8a05 100644
--- a/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py
+++ b/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py
@@ -150,10 +150,9 @@ def run_evaluation(clause, clause_context, rule, prompt_vars_dict):
 
     llm_response, model_usage, stop_reason = invoke_llm(
         prompt=evaluation_prompt,
-        model_id=prompt_vars_dict.get("claude_model_id", ''),
+        model_id=prompt_vars_dict.get("llm_model_id", ''),
         temperature=0.01,
-        top_k=100,
-        top_p=0.5,
+        top_k=3,
         max_new_tokens=2000,
         verbose=True
     )
diff --git a/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py b/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py
index 8624360..0e4b12f 100644
--- a/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py
+++ b/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py
@@ -22,6 +22,7 @@ import boto3
 from langchain.text_splitter import TokenTextSplitter
 
 from llm import invoke_llm
+from pyarrow.compute import top_k_unstable
 from util import get_prompt_vars_dict
 
 
@@ -101,9 +102,9 @@ def separate_clauses(contract_excerpt):
     prompt_vars_dict = get_prompt_vars_dict(PROMPT_VARS)
     llm_response, model_usage, stop_reason = invoke_llm(
         prompt=PROMPT_TEMPLATE.format(CONTRACT_EXCERPT=contract_excerpt),
-        model_id=prompt_vars_dict.get("claude_model_id", ''),
+        model_id=prompt_vars_dict.get("llm_model_id", ''),
         temperature=0.0,
-        top_p=0.999,
+        top_k=3,
         max_new_tokens=4096,
     )
     return llm_response
-- 
2.39.5 (Apple Git-154)


From 37a77f758b3cc2f926daf12fdc9f131438d22598 Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Mon, 4 Aug 2025 16:47:38 -0300
Subject: [PATCH 06/13] Enable better support to counting token consumption on
 contract processing

---
 back-end/.gitignore                           |   3 +-
 back-end/README.md                            |  12 +
 back-end/eval/requirements.txt                |  11 +-
 back-end/scripts/workflow_token_usage.py      | 306 ++++++++++++++++++
 back-end/stack/__init__.py                    |  22 ++
 back-end/stack/sfn/__init__.py                |  18 ++
 .../fn-classify-clauses/index.py              |  17 +-
 back-end/stack/sfn/common-layer/llm.py        |  17 +-
 .../stack/sfn/common-layer/requirements.txt   |   3 +-
 .../evaluation/fn-evaluate-clauses/index.py   |  25 +-
 .../fn-preprocess-contract/index.py           |  22 +-
 11 files changed, 426 insertions(+), 30 deletions(-)
 create mode 100755 back-end/scripts/workflow_token_usage.py

diff --git a/back-end/.gitignore b/back-end/.gitignore
index 68b7f25..ada5695 100644
--- a/back-end/.gitignore
+++ b/back-end/.gitignore
@@ -11,6 +11,7 @@ evaluation_questions.xlsx
 # CDK asset staging directory
 .cdk.staging
 cdk.out
+/cdk.context.json
 
 ### JetBrains+all ###
 # Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
@@ -258,4 +259,4 @@ $RECYCLE.BIN/
 *.msp
 
 # Windows shortcuts
-*.lnk
\ No newline at end of file
+*.lnk
diff --git a/back-end/README.md b/back-end/README.md
index 0274c8f..8dd1f34 100644
--- a/back-end/README.md
+++ b/back-end/README.md
@@ -218,3 +218,15 @@ if ('mymodel' in model_id):
         usage_data = response.XXX # <- specify how to parse usage data
         stop_reason = response.XXX # <- specify how to parse stop reason
 ```
+
+## Token Usage Tracking
+
+Track LLM token consumption for workflow executions:
+
+```bash
+# Query specific job token usage
+python scripts/workflow_token_usage.py --job-id <job-id>
+
+# Query all token usage in last 24 hours
+python scripts/workflow_token_usage.py --hours 24
+```
diff --git a/back-end/eval/requirements.txt b/back-end/eval/requirements.txt
index 8a431f6..7255586 100644
--- a/back-end/eval/requirements.txt
+++ b/back-end/eval/requirements.txt
@@ -1,7 +1,4 @@
-boto3>=1.34.0
-botocore>=1.34.0
-langchain-aws>=0.1.0
-langchain-core>=0.2.0
-retrying>=1.3.4
-more-itertools>=10.0.0
-PyYAML>=6.0
+# Reference requirements from Lambda layers and functions
+-r ../stack/sfn/common-layer/requirements.txt
+-r ../stack/sfn/langchain-deps-layer/requirements.txt  
+-r ../stack/sfn/classification/fn-classify-clauses/requirements.txt
diff --git a/back-end/scripts/workflow_token_usage.py b/back-end/scripts/workflow_token_usage.py
new file mode 100755
index 0000000..96558ce
--- /dev/null
+++ b/back-end/scripts/workflow_token_usage.py
@@ -0,0 +1,306 @@
+#
+# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License"). You may not use this file except in compliance
+# with the License. A copy of the License is located at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# or in the 'license' file accompanying this file. This file is distributed on an 'AS IS' BASIS, WITHOUT WARRANTIES
+# OR CONDITIONS OF ANY KIND, express or implied. See the License for the specific language governing permissions
+# and limitations under the License.
+#
+
+"""
+Query token usage from CloudWatch Log Insights for contract compliance analysis.
+
+This script queries token usage across all Lambda functions (preprocessing, classification, evaluation)
+and aggregates the results by correlation_id (job_id).
+"""
+
+import argparse
+import boto3
+import time
+from datetime import datetime
+from typing import Dict, List, Any
+
+
+def get_log_groups_from_stack_outputs(cf_client, stack_name: str) -> List[str]:
+    """Get log group names from CloudFormation stack outputs."""
+    print(f"Looking up log groups from CloudFormation stack outputs: {stack_name}")
+
+    # Expected output keys for log groups
+    expected_outputs = [
+        'PreprocessingLogGroup',
+        'ClassificationLogGroup',
+        'EvaluationLogGroup'
+    ]
+
+    log_groups = []
+
+    try:
+        # Get stack outputs
+        response = cf_client.describe_stacks(StackName=stack_name)
+
+        if not response['Stacks']:
+            print(f"Stack {stack_name} not found")
+            return []
+
+        stack = response['Stacks'][0]
+        outputs = stack.get('Outputs', [])
+
+        # Create a map of output key to value
+        output_map = {output['OutputKey']: output['OutputValue'] for output in outputs}
+
+        # Look for our expected log group outputs
+        for output_key in expected_outputs:
+            if output_key in output_map:
+                log_group = output_map[output_key]
+                log_groups.append(log_group)
+                function_type = output_key.replace('LogGroup', '')
+                print(f"  Found {function_type}: {log_group}")
+            else:
+                print(f"  Output {output_key} not found in stack")
+
+        if len(log_groups) == 0:
+            print("No log group outputs found in stack. Available outputs:")
+
+        return log_groups
+
+    except Exception as e:
+        print(f"Error getting stack outputs: {e}")
+        return []
+
+
+def build_query(correlation_id: str = None) -> str:
+    """Build the CloudWatch Log Insights query."""
+    base_query = """
+    fields @timestamp, correlation_id, token_usage.model_id, token_usage.input_tokens, token_usage.output_tokens
+    | filter ispresent(token_usage.input_tokens)
+    """
+
+    if correlation_id:
+        base_query += f' and correlation_id = "{correlation_id}"'
+
+    base_query += """
+    | stats
+        sum(token_usage.input_tokens) as total_input_tokens,
+        sum(token_usage.output_tokens) as total_output_tokens,
+        count() as llm_calls
+        by correlation_id, token_usage.model_id
+    """
+
+    return base_query.strip()
+
+
+def run_query(logs_client, query: str, log_groups: List[str], start_time: int, end_time: int) -> Dict[str, Any]:
+    """Run the CloudWatch Log Insights query and return results."""
+    print(f"Starting query across {len(log_groups)} log groups...")
+    print(f"Time range: {datetime.fromtimestamp(start_time)} to {datetime.fromtimestamp(end_time)}")
+
+    # Start the query
+    response = logs_client.start_query(
+        logGroupNames=log_groups,
+        startTime=start_time,
+        endTime=end_time,
+        queryString=query
+    )
+
+    query_id = response['queryId']
+    print(f"Query ID: {query_id}")
+
+    # Poll for results
+    while True:
+        result = logs_client.get_query_results(queryId=query_id)
+        status = result['status']
+
+        if status == 'Complete':
+            return result
+        elif status == 'Failed':
+            raise Exception(f"Query failed: {result}")
+        elif status in ['Running', 'Scheduled']:
+            print("Query running, waiting...")
+            time.sleep(2)
+        else:
+            raise Exception(f"Unknown query status: {status}")
+
+
+def format_results(results: Dict[str, Any]) -> None:
+    """Format and display the query results."""
+    print("\n" + "=" * 120)
+    print("TOKEN USAGE ANALYSIS RESULTS")
+    print("=" * 120)
+
+    # Display statistics
+    stats = results['statistics']
+    records_matched = int(stats['recordsMatched'])
+    
+    if records_matched > 0:
+        print(f"Records matched: {records_matched}")
+
+    # Display results
+    query_results = results['results']
+
+    if not query_results:
+        print("\nNo results found.")
+        print("\nTroubleshooting suggestions:")
+        print("  • Expand the time range with --hours 24")
+        print("  • Check if the job ID is correct")
+        print("  • Verify the job made LLM calls")
+        return
+
+    print(f"\nFound {len(query_results)} result(s):")
+    print("=" * 120)
+
+    # Prepare table data
+    table_data = []
+    total_input = 0
+    total_output = 0
+    total_calls = 0
+
+    for result in query_results:
+        row_data = {field['field']: field['value'] for field in result}
+
+        job_id = row_data.get('correlation_id', 'N/A')
+        model_id = row_data.get('token_usage.model_id', 'N/A')
+        input_tokens = int(row_data.get('total_input_tokens', 0))
+        output_tokens = int(row_data.get('total_output_tokens', 0))
+        llm_calls = int(row_data.get('llm_calls', 0))
+
+        table_data.append({
+            'job_id': job_id,
+            'model_id': model_id,
+            'input_tokens': input_tokens,
+            'output_tokens': output_tokens,
+            'llm_calls': llm_calls
+        })
+
+        total_input += input_tokens
+        total_output += output_tokens
+        total_calls += llm_calls
+
+    # Print table header
+    print(f"{'Job ID':<40} {'Model':<50} {'Input':<10} {'Output':<10} {'Calls':<6}")
+    print("-" * 120)
+
+    # Print table rows
+    for row in table_data:
+        model_id = row['model_id']
+        
+        # Split long model IDs into chunks that fit the column
+        if len(model_id) <= 50:
+            # Model fits in one line
+            print(f"{row['job_id']:<40} {model_id:<50} {row['input_tokens']:<10} {row['output_tokens']:<10} {row['llm_calls']:<6}")
+        else:
+            # Model needs to be wrapped
+            model_chunks = []
+            for i in range(0, len(model_id), 50):
+                model_chunks.append(model_id[i:i+50])
+            
+            # First line with all data
+            print(f"{row['job_id']:<40} {model_chunks[0]:<50} {row['input_tokens']:<10} {row['output_tokens']:<10} {row['llm_calls']:<6}")
+            
+            # Additional lines for remaining model text
+            for chunk in model_chunks[1:]:
+                print(f"{'':>40} {chunk:<50}")
+
+    # Summary for multiple results
+    if len(query_results) > 1:
+        print("-" * 120)
+        print(f"{'TOTAL':<40} {'':>50} {total_input:<10} {total_output:<10} {total_calls:<6}")
+
+    print("=" * 120)
+
+
+def main():
+    """Main function."""
+    parser = argparse.ArgumentParser(
+        description="Query token usage from CloudWatch Log Insights",
+        formatter_class=argparse.RawDescriptionHelpFormatter,
+        epilog="""
+Examples:
+  # Query token usage for a specific job ID
+  python workflow_token_usage.py --job-id e1737ab0-ddf0-4403-ad77-f54077b89809
+  
+  # Query all token usage in the last hour (default)
+  python workflow_token_usage.py --hours 1
+  
+  # Query all token usage in the last 24 hours
+  python workflow_token_usage.py --hours 24
+  
+  # Query with custom stack name
+  python workflow_token_usage.py --job-id e1737ab0-ddf0-4403-ad77-f54077b89809 --stack-name MyCustomStack
+        """
+    )
+
+    parser.add_argument(
+        '--job-id',
+        help='Specific job ID to query'
+    )
+
+    parser.add_argument(
+        '--hours',
+        type=int,
+        default=1,
+        help='Number of hours to look back from now (default: 1)'
+    )
+
+    parser.add_argument(
+        '--stack-name',
+        default='MainBackendStack',
+        help='CloudFormation stack name (default: MainBackendStack)'
+    )
+
+    parser.add_argument(
+        '--region',
+        help='AWS region (uses default from profile/environment if not specified)'
+    )
+
+    args = parser.parse_args()
+
+    # Set up AWS session
+    session_kwargs = {}
+    if args.region:
+        session_kwargs['region_name'] = args.region
+
+    session = boto3.Session(**session_kwargs)
+    logs_client = session.client('logs')
+    cf_client = session.client('cloudformation')
+
+    # Calculate time range
+    end_time = int(datetime.now().timestamp())
+    start_time = end_time - (args.hours * 3600)
+
+    # Build query
+    query = build_query(args.job_id)
+
+    # Get log groups from CloudFormation stack outputs
+    log_groups = get_log_groups_from_stack_outputs(cf_client, args.stack_name)
+
+    if not log_groups:
+        print("Error: No log groups found in CloudFormation stack outputs.")
+        print("\nTroubleshooting:")
+        print("  • Check if the stack name is correct with --stack-name")
+        print("  • Verify the stack has been deployed with log group outputs")
+        print("  • Ensure you have permissions to describe CloudFormation stacks")
+        return 1
+
+    print(f"\nUsing {len(log_groups)} log groups for query")
+    print()
+
+    try:
+        # Run query
+        results = run_query(logs_client, query, log_groups, start_time, end_time)
+
+        # Format and display results
+        format_results(results)
+
+    except Exception as e:
+        print(f"Error: {e}")
+        return 1
+
+    return 0
+
+
+if __name__ == '__main__':
+    exit(main())
diff --git a/back-end/stack/__init__.py b/back-end/stack/__init__.py
index b7f69a9..51f3231 100644
--- a/back-end/stack/__init__.py
+++ b/back-end/stack/__init__.py
@@ -219,6 +219,28 @@ class BackendStack(Stack):
             export_name=f"{Stack.of(self).stack_name}RegionName",
         )
 
+        # Log group outputs for token usage tracking
+        CfnOutput(
+            self,
+            "PreprocessingLogGroup",
+            value=self.sfn_stack.preprocessing_step.preprocess_contract_fn.log_group.log_group_name,
+            description="CloudWatch log group for the preprocessing Lambda function"
+        )
+
+        CfnOutput(
+            self,
+            "ClassificationLogGroup", 
+            value=self.sfn_stack.classification.classify_clauses_fn.log_group.log_group_name,
+            description="CloudWatch log group for the classification Lambda function"
+        )
+
+        CfnOutput(
+            self,
+            "EvaluationLogGroup",
+            value=self.sfn_stack.evaluation_step.evaluate_clauses_fn.log_group.log_group_name,
+            description="CloudWatch log group for the evaluation Lambda function"
+        )
+
         # cdk-nag suppressions
         stack_suppressions = [
             # Insert your stack-level NagPackSuppression"s here
diff --git a/back-end/stack/sfn/__init__.py b/back-end/stack/sfn/__init__.py
index d072dc9..f53c7d1 100644
--- a/back-end/stack/sfn/__init__.py
+++ b/back-end/stack/sfn/__init__.py
@@ -166,3 +166,21 @@ class StepFunctionsStack(NestedStack):
             ],
             apply_to_children=True,
         )
+
+        # Suppress CDK-nag errors for LogRetention constructs
+        # These are automatically created by CDK for Lambda functions
+        NagSuppressions.add_stack_suppressions(
+            stack=self,
+            suppressions=[
+                NagPackSuppression(
+                    id="AwsSolutions-IAM4",
+                    reason="LogRetention construct requires AWSLambdaBasicExecutionRole managed policy for CloudWatch log operations",
+                    applies_to=["Policy::arn:<AWS::Partition>:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"],
+                ),
+                NagPackSuppression(
+                    id="AwsSolutions-IAM5",
+                    reason="LogRetention construct requires wildcard permissions for CloudWatch log group operations across different log groups",
+                    applies_to=["Resource::*"],
+                ),
+            ],
+        )
diff --git a/back-end/stack/sfn/classification/fn-classify-clauses/index.py b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
index a99104c..13b5649 100644
--- a/back-end/stack/sfn/classification/fn-classify-clauses/index.py
+++ b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
@@ -11,7 +11,6 @@
 # and limitations under the License.
 #
 
-import logging
 import boto3
 import json
 import concurrent.futures
@@ -24,8 +23,11 @@ import difflib
 from llm import invoke_llm
 from util import get_prompt_vars_dict, extract_first_item_from_tagged_list, extract_items_and_attributes_from_tagged_list
 
-logger = logging.getLogger()
-logger.setLevel(os.getenv("LOG_LEVEL", "INFO"))
+# Import Powertools
+from aws_lambda_powertools import Logger
+
+# Initialize Powertools logger
+logger = Logger(service="contract-compliance-analysis")
 
 VERBOSE_LLM = True
 BEDROCK_MAX_CONCURRENCY = int(os.environ.get('BEDROCK_MAX_CONCURRENCY', 10))
@@ -251,8 +253,13 @@ def classify_clause(clause, request_id, number_of_classification_prompts=1):
             return ddb_values, yes_answers
 
 
+@logger.inject_lambda_context(log_event=True)
 def handler(event, context):
-    logger.info(f"Received event {event}")
+    # Extract Step Functions execution name and set as correlation ID
+    job_id = event.get("JobId", "unknown")
+    logger.set_correlation_id(job_id)  # Use JobId as correlation ID (which is the execution name)
+    
+    logger.info("Received event", extra={"event": event})
 
     job_id, clause_number = parse_event(event)
     request_id = context.aws_request_id
@@ -277,6 +284,6 @@ def handler(event, context):
 
     ddb_response = clauses_table.put_item(Item=clause_record)
 
-    logger.info("DynamoDB update response: %s", ddb_response)
+    logger.info("DynamoDB update response", extra={"ddb_response": ddb_response})
 
     return "OK"
diff --git a/back-end/stack/sfn/common-layer/llm.py b/back-end/stack/sfn/common-layer/llm.py
index fb263bb..d71c212 100644
--- a/back-end/stack/sfn/common-layer/llm.py
+++ b/back-end/stack/sfn/common-layer/llm.py
@@ -22,10 +22,13 @@ from langchain_aws import ChatBedrock
 from langchain_core.messages import HumanMessage
 from langchain_core.prompts import ChatPromptTemplate
 
+# Import Powertools Logger
+from aws_lambda_powertools import Logger
+
 CLAUDE_MODEL_ID = "anthropic.claude-3-sonnet-20240229-v1:0"
 
-logger = logging.getLogger()
-logger.setLevel(os.getenv("LOG_LEVEL", "INFO"))
+# Initialize Powertools logger with shared service name
+logger = Logger(service="contract-compliance-analysis")
 
 bedrock_client = boto3.client('bedrock-runtime', config=Config(
     connect_timeout=180,
@@ -121,4 +124,14 @@ def invoke_llm(prompt, model_id, temperature=0.5, top_k=None, top_p=None, max_ne
         logger.info(f"Model usage: {usage_data}")
         logger.info(f"Model stop_reason: {stop_reason}")
 
+    # # Always log token usage for cost tracking with Powertools structured logging
+    if usage_data:
+        logger.info("LLM token usage", extra={
+            "token_usage": {
+                "model_id": model_id,
+                "input_tokens": usage_data.get('prompt_tokens', 0),
+                "output_tokens": usage_data.get('completion_tokens', 0)
+            }
+        })
+
     return content, usage_data, stop_reason
diff --git a/back-end/stack/sfn/common-layer/requirements.txt b/back-end/stack/sfn/common-layer/requirements.txt
index 4672493..df99346 100644
--- a/back-end/stack/sfn/common-layer/requirements.txt
+++ b/back-end/stack/sfn/common-layer/requirements.txt
@@ -1,2 +1,3 @@
 retrying==1.3.4
-botocore==1.38.9
\ No newline at end of file
+botocore==1.38.9
+aws-lambda-powertools==3.18.0
\ No newline at end of file
diff --git a/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py b/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py
index 17a8a05..7fe6d22 100644
--- a/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py
+++ b/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py
@@ -11,7 +11,6 @@
 # and limitations under the License.
 #
 
-import logging
 import os
 import boto3
 from boto3.dynamodb.conditions import Key
@@ -19,6 +18,12 @@ from collections import defaultdict
 from llm import invoke_llm
 from util import get_prompt_vars_dict, extract_first_item_from_tagged_list, extract_items_from_tagged_list
 
+# Import Powertools
+from aws_lambda_powertools import Logger
+
+# Initialize Powertools logger
+logger = Logger(service="contract-compliance-analysis")
+
 CLAUSE_EVALUATION_PROMPT_TEMPLATE = """
 
 Human: You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
@@ -70,9 +75,6 @@ Assistant:"""
 
 PROMPT_VARS = os.environ.get('PROMPT_VARS', "")
 
-logger = logging.getLogger()
-logger.setLevel(os.getenv("LOG_LEVEL", "INFO"))
-
 clauses_table = boto3.resource('dynamodb').Table(os.environ['CLAUSES_TABLE_NAME'])
 guidelines_table = boto3.resource('dynamodb').Table(os.environ['GUIDELINES_TABLE_NAME'])
 
@@ -196,12 +198,17 @@ def update_clause(clause):
     )
 
 
+@logger.inject_lambda_context(log_event=True)
 def handler(event, context):
     """Lambda to evaluate contract clauses against guidelines rules
     """
-    logger.info("Received event %s", event)
+    # Extract Step Functions execution name and set as correlation ID
+    job_id = event.get("JobId", "unknown")
+    logger.set_correlation_id(job_id)  # Use JobId as correlation ID (which is the execution name)
+    
+    logger.info("Received event", extra={"event": event})
     clause = get_clause(event["JobId"], event["ClauseNumber"])
-    logger.info("Clause %s", clause)
+    logger.info("Retrieved clause", extra={"clause_number": event["ClauseNumber"], "has_types": "types" in clause})
     request_id = context.aws_request_id
 
     prompt_vars_dict = get_prompt_vars_dict(PROMPT_VARS)
@@ -216,19 +223,19 @@ def handler(event, context):
         type_id = type_["type_id"]
         try:
             rule = get_guidelines_rule(type_id)
-            logger.info("Rule %s", rule)
+            logger.info("Processing rule", extra={"type_id": type_id, "rule_name": rule.get("name", "unknown")})
         except ValueError:
             continue  # rule not found, skip it.
 
         eval_result = run_evaluation(clause, clause_context, rule, prompt_vars_dict)
-        logger.info("Evaluation result %s", eval_result)
+        logger.info("Evaluation completed", extra={"type_id": type_id, "compliant": eval_result["compliant"]})
         type_["compliant"] = eval_result["compliant"]
         type_["analysis"] = eval_result["analysis"]
         type_["level"] = rule["level"]
         type_["evaluation_request_id"] = request_id
 
     update_clause(clause)
-    logger.info("Clause %s", clause)
+    logger.info("Clause evaluation completed", extra={"clause_number": event["ClauseNumber"]})
 
     return {
         "Status": "OK"
diff --git a/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py b/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py
index 0e4b12f..7a47fa1 100644
--- a/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py
+++ b/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py
@@ -11,23 +11,24 @@
 # and limitations under the License.
 #
 
-import logging
 import tempfile
 import re
 import os
 from difflib import Differ
+from tabnanny import verbose
 
 import boto3
 
 from langchain.text_splitter import TokenTextSplitter
 
 from llm import invoke_llm
-from pyarrow.compute import top_k_unstable
 from util import get_prompt_vars_dict
 
+# Import Powertools
+from aws_lambda_powertools import Logger
 
-logger = logging.getLogger()
-logger.setLevel(os.getenv("LOG_LEVEL", "INFO"))
+# Initialize Powertools logger
+logger = Logger(service="contract-compliance-analysis")
 
 clauses_table_name = os.environ["CLAUSES_TABLE_NAME"]
 
@@ -106,6 +107,7 @@ def separate_clauses(contract_excerpt):
         temperature=0.0,
         top_k=3,
         max_new_tokens=4096,
+        verbose=True
     )
     return llm_response
 
@@ -130,10 +132,15 @@ def parse_event(event):
         raise MalformedRequest(f"Invalid S3 URI: {document_s3_path}")
 
 
+@logger.inject_lambda_context(log_event=True)
 def handler(event, context):
     """Lambda to preprocess a contract document
     """
-    logger.info("Received event %s", event)
+    # Extract Step Functions execution name and set as correlation ID
+    execution_name = event.get("ExecutionName")
+    logger.set_correlation_id(execution_name)
+    
+    logger.info("Received event", extra={"event": event})
 
     bucket, key, execution_name = parse_event(event)
 
@@ -146,6 +153,8 @@ def handler(event, context):
 
         # Split text in chunks of less than 4000 tokens
         chunks = split_chunks(contract)
+        logger.info(f"Split contract into {len(chunks)} chunks")
+        
         # Separate each chunk, including separators between clauses
         separated_contract = "".join([
             separate_clauses(chunk) for chunk in chunks
@@ -162,6 +171,9 @@ def handler(event, context):
         ])
         # Get each individual clause and insert into table
         clauses = list(filter(None, [clause.strip() for clause in merged_contract.split(CLAUSE_SEPARATOR)]))
+        
+        logger.info(f"Extracted {len(clauses)} clauses from contract")
+        
         for i, clause in enumerate(clauses):
             clauses_table.put_item(Item={
                 'job_id': execution_name,
-- 
2.39.5 (Apple Git-154)


From df483f2b71e6973652328e2aeff85d3c45a203fd Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Mon, 4 Aug 2025 16:57:59 -0300
Subject: [PATCH 07/13] Add service name to Cloudwatch Log Insights query

---
 back-end/scripts/workflow_token_usage.py | 1 +
 1 file changed, 1 insertion(+)

diff --git a/back-end/scripts/workflow_token_usage.py b/back-end/scripts/workflow_token_usage.py
index 96558ce..5e84ff0 100755
--- a/back-end/scripts/workflow_token_usage.py
+++ b/back-end/scripts/workflow_token_usage.py
@@ -77,6 +77,7 @@ def build_query(correlation_id: str = None) -> str:
     base_query = """
     fields @timestamp, correlation_id, token_usage.model_id, token_usage.input_tokens, token_usage.output_tokens
     | filter ispresent(token_usage.input_tokens)
+     and service = "contract-compliance-analysis"
     """
 
     if correlation_id:
-- 
2.39.5 (Apple Git-154)


From 69450aaabca5ca487443ff10188ad29b18006470 Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Tue, 5 Aug 2025 16:22:53 -0300
Subject: [PATCH 08/13] Enable prompt caching; Facilitate token count for
 contract processing

---
 back-end/eval/eval_clause_classification.py   | 354 +++++++++++-------
 back-end/requirements.txt                     |   3 +-
 back-end/scripts/workflow_token_usage.py      |  79 ++--
 .../fn-classify-clauses/index.py              | 117 +++---
 back-end/stack/sfn/common-layer/llm.py        | 221 ++++++++---
 .../stack/sfn/common-layer/requirements.txt   |   4 +-
 .../sfn/langchain-deps-layer/requirements.txt |   6 +-
 7 files changed, 508 insertions(+), 276 deletions(-)

diff --git a/back-end/eval/eval_clause_classification.py b/back-end/eval/eval_clause_classification.py
index 2c3287e..9c94097 100644
--- a/back-end/eval/eval_clause_classification.py
+++ b/back-end/eval/eval_clause_classification.py
@@ -24,25 +24,21 @@ os.environ['BEDROCK_MAX_CONCURRENCY'] = "3"
 sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'stack', 'sfn', 'common-layer'))
 sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'stack', 'sfn', 'classification', 'fn-classify-clauses'))
 
-# Configure logging
-logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
+# Logger will be configured after importing index.py
 logger = logging.getLogger(__name__)
 
 # =============================================================================
 # CONFIGURATION - MODIFY THESE TO TEST DIFFERENT PROMPTS
 # =============================================================================
 
-# Original one
-# PROMPT_TEMPLATE = """
-#
-# You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
+# Custom system prompt template for testing (set to None to use existing lambda prompt)
+# This will monkey patch the SYSTEM_PROMPT_TEMPLATE constant in index.py
+CUSTOM_SYSTEM_PROMPT_TEMPLATE = None
+
+# Extracted from v1
+# CUSTOM_SYSTEM_PROMPT_TEMPLATE = """You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
 # You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
 #
-# This is the clause you are reading right now:
-# <current_clause>
-# {clause}
-# </current_clause>
-#
 # Rules of thought process:
 # <rules_of_thought_process>
 # - Making deductions is forbidden
@@ -65,55 +61,12 @@ logger = logging.getLogger(__name__)
 # - Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
 # - Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one and determine if any is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags.
 # - For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
-#
 # """
 
-# Clause type distillation
-PROMPT_TEMPLATE = """
-
-You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
-You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
-
-This is the clause you are reading right now:
-<current_clause>
-{clause}
-</current_clause>
-
-You task is to say whether any of the following possible types is highly applicable to the clause: 
-<possible_types>
-{possible_types}
-<possible_types>
-
-Rules of thought process:
-<rules_of_thought_process>
-- Making deductions is forbidden
-- Proposing premises is forbidden.
-- Making generalizations is forbidden. 
-- Making implications/deductions about implicit content is forbidden.
-</rules_of_thought_process>
-
-Examples:
-<examples>
-{examples}
-</examples>
-
-Follow these steps:
-- Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
-- For each possible type, look at the corresponding examples (the content between <examples> tags) and distill them into a definition for the clause type. Write all type / distillation pairs between a single <distilled_type_definition></distilled_type_definition> tag pair.  
-- Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one, together with each corresponding distilled type definition, and determine if a type is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags. 
-- For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
-
-"""
-
 # Verbal reinforcement prompt
-# PROMPT_TEMPLATE = """You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
+# CUSTOM_SYSTEM_PROMPT_TEMPLATE = """You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
 # You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
 #
-# This is the clause you are reading right now:
-# <current_clause>
-# {clause}
-# </current_clause>
-#
 # Rules of thought process:
 # <rules_of_thought_process>
 # - Making deductions is forbidden.
@@ -153,119 +106,231 @@ Follow these steps:
 # Conclude with a final reflection on the overall solution, discussing effectiveness, challenges, and solutions. Assign a final reward score.
 # """
 
+
+# Example of a custom system prompt template (uncomment to test):
+# CUSTOM_SYSTEM_PROMPT_TEMPLATE = """You are a Senior Legal Expert specializing in contract analysis for {company_name}.
+# You are analyzing a {contract_type} between {company_name} ({company_party_type}) and the {other_party_type}.
+# 
+# Your task is to determine if any of these clause types apply to the given clause:
+# <possible_types>
+# {possible_types}
+# </possible_types>
+# 
+# Analysis Guidelines:
+# <guidelines>
+# - Base your analysis only on explicit content in the clause
+# - Do not make assumptions or inferences beyond what is directly stated
+# - Consider the specific examples provided for each clause type
+# - A clause type is "highly applicable" only if there is clear, direct evidence
+# </guidelines>
+# 
+# Reference Examples:
+# <examples>
+# {examples}
+# </examples>
+# 
+# Analysis Process:
+# 1. First, reproduce the clause text between <clause_replica> tags
+# 2. For each possible type, create a definition based on the examples between <distilled_type_definition> tags
+# 3. Analyze each type systematically between <thinking> tags, following the guidelines
+# 4. Provide your final answer using <type reason="explanation">type_name</type> tags for applicable types
+# 5. If no types apply, use <no_highly_applicable_types/>
+# 
+# Respond in {language}."""
+
 # =============================================================================
 
 class ClassificationTester:
     """Test classification accuracy against ground truth"""
-    
+
     def __init__(self, test_data_file: str, app_properties: Dict[str, str]):
         # Store app_properties for later use
         self.app_properties = app_properties
-        
+
         # Environment variable is already set in main(), so we can directly import
-        from index import classify_clause, get_guidelines_clauses
+        from index import classify_clause, get_guidelines_clauses, _build_system_prompt, _build_user_prompt
+
+        # Lambda Powertools might have added its own handlers
+        self._configure_plain_text_logging()
+        
         self.classify_clause = classify_clause
         self.get_guidelines_clauses = get_guidelines_clauses
-        
+        self._build_system_prompt = _build_system_prompt
+        self._build_user_prompt = _build_user_prompt
+
+        # Apply monkey patch if custom system prompt is provided
+        if CUSTOM_SYSTEM_PROMPT_TEMPLATE is not None:
+            self._apply_system_prompt_monkey_patch()
+            logger.info("Applied custom system prompt monkey patch")
+        else:
+            logger.info("Using existing system prompt")
+
         # Load test data from YAML file
         self.test_data = self.load_test_data(test_data_file)
+
+    def _configure_plain_text_logging(self):
+        """Ensure plain text logging is configured after all imports"""
+        # Get all loggers that might have been created by Lambda Powertools
+        import logging
         
+        # Configure the root logger and any AWS Powertools loggers
+        loggers_to_fix = [
+            logging.getLogger(),  # Root logger
+            logging.getLogger('aws_lambda_powertools'),
+            logging.getLogger('contract-compliance-analysis'),
+        ]
+        
+        plain_formatter = logging.Formatter(
+            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+        )
+        
+        for logger_obj in loggers_to_fix:
+            # Remove any existing handlers
+            for handler in logger_obj.handlers[:]:
+                logger_obj.removeHandler(handler)
+            
+            # Add our plain text handler
+            if not logger_obj.handlers:  # Only add if no handlers exist
+                handler = logging.StreamHandler(sys.stdout)
+                handler.setFormatter(plain_formatter)
+                logger_obj.addHandler(handler)
+
+    def _apply_system_prompt_monkey_patch(self):
+        """Apply monkey patch to use custom system prompt template"""
+        import index
+        # Simply replace the constant - much cleaner!
+        index.SYSTEM_PROMPT_TEMPLATE = CUSTOM_SYSTEM_PROMPT_TEMPLATE
+        logger.info(f"Monkey patched SYSTEM_PROMPT_TEMPLATE constant")
+
     def load_test_data(self, file_path: str) -> Dict:
         """Load test data from YAML file"""
         logger.info(f"Loading test data from: {file_path}")
-        
+
         with open(file_path, 'r') as f:
             data = yaml.safe_load(f)
-        
+
         logger.info(f"Loaded {len(data['clauses'])} clauses")
         return data
-        
+
+    def get_current_prompt_structure(self) -> Dict[str, str]:
+        """Get the current system and user prompt templates for reporting"""
+        # Get a sample clause type group to build example prompts
+        clause_types = self.get_guidelines_clauses()
+        if not clause_types:
+            return {"error": "No clause types available"}
+
+        # Take first few clause types as example
+        sample_clause_types = clause_types[:3]
+
+        # Build example prompts using the same logic as production
+        from index import build_tagged_examples_string
+        examples_str = build_tagged_examples_string(sample_clause_types)
+        possible_types_str = "\n".join([f"- {clause_type['name']}" for clause_type in sample_clause_types])
+
+        # Build system prompt (will use monkey patched version if applied)
+        system_prompt = self._build_system_prompt(
+            possible_types_str, examples_str, self.app_properties
+        )
+
+        # Build user prompt with sample text
+        user_prompt = self._build_user_prompt("Sample clause text for demonstration")
+
+        # Indicate if using custom prompt
+        prompt_type = "custom" if CUSTOM_SYSTEM_PROMPT_TEMPLATE is not None else "production"
+
+        return {
+            "system_prompt": system_prompt,
+            "user_prompt_template": user_prompt.replace("Sample clause text for demonstration", "{clause_text}"),
+            "prompt_type": prompt_type
+        }
+
     def get_ground_truth(self) -> Dict[int, Set[str]]:
         """Get ground truth classifications"""
         ground_truth = {}
-        
+
         for clause in self.test_data['clauses']:
             clause_number = clause['clause_number']
             types = set(clause['ground_truth_types'])
             ground_truth[clause_number] = types
-            
+
         return ground_truth
-    
+
     def get_clause_text(self, clause_number: int) -> str:
         """Get the text for a specific clause"""
         for clause in self.test_data['clauses']:
             if clause['clause_number'] == clause_number:
                 return clause['text']
-        
+
         raise ValueError(f"Clause {clause_number} not found in test data")
-    
+
     def test_classification(self, clause_number: int) -> Set[str]:
         """Test classification for a single clause"""
         clause_text = self.get_clause_text(clause_number)
-        
+
         # Mock request ID for testing
         request_id = f"test-{clause_number}-{datetime.now().strftime('%Y%m%d%H%M%S')}"
-        
+
         # Call the actual classify_clause function
         try:
             ddb_values, yes_answers = self.classify_clause(clause_text, request_id)
-            
+
             # Extract type names from results
             predicted_types = set()
             for answer in yes_answers:
                 if 'type_name' in answer:
                     predicted_types.add(answer['type_name'])
-            
+
             return predicted_types
-            
+
         except Exception as e:
             logger.error(f"Error classifying clause {clause_number}: {str(e)}")
             return set()
-    
-    def calculate_accuracy_metrics(self, ground_truth: Dict[int, Set[str]], predictions: Dict[int, Set[str]]) -> Dict[str, float]:
+
+    def calculate_accuracy_metrics(self, ground_truth: Dict[int, Set[str]], predictions: Dict[int, Set[str]]) -> Dict[
+        str, float]:
         """Calculate various accuracy metrics"""
-        
+
         exact_matches = 0
         total_precision = 0
         total_recall = 0
         total_f1 = 0
         valid_clauses = 0
-        
+
         for clause_number in ground_truth:
             if clause_number not in predictions:
                 continue
-                
+
             gt_types = ground_truth[clause_number]
             pred_types = predictions[clause_number]
-            
+
             # Exact match
             if gt_types == pred_types:
                 exact_matches += 1
-            
+
             # Precision, Recall, F1 (per clause)
             if len(pred_types) > 0:
                 precision = len(gt_types.intersection(pred_types)) / len(pred_types)
             else:
                 precision = 1.0 if len(gt_types) == 0 else 0.0
-                
+
             if len(gt_types) > 0:
                 recall = len(gt_types.intersection(pred_types)) / len(gt_types)
             else:
                 recall = 1.0 if len(pred_types) == 0 else 0.0
-            
+
             if precision + recall > 0:
                 f1 = 2 * (precision * recall) / (precision + recall)
             else:
                 f1 = 0.0
-            
+
             total_precision += precision
             total_recall += recall
             total_f1 += f1
             valid_clauses += 1
-        
+
         if valid_clauses == 0:
             return {"error": "No valid clauses to evaluate"}
-        
+
         return {
             "exact_match_accuracy": exact_matches / valid_clauses,
             "average_precision": total_precision / valid_clauses,
@@ -274,25 +339,28 @@ class ClassificationTester:
             "total_clauses": valid_clauses,
             "exact_matches": exact_matches
         }
-    
+
     def run_accuracy_test(self) -> Dict[str, any]:
         """Run full accuracy test"""
         model_id = self.app_properties.get('llm_model_id', 'unknown')
         logger.info(f"Using model: {model_id}")
-        
+
+        # Get current prompt structure for reporting
+        prompt_structure = self.get_current_prompt_structure()
+
         # Load ground truth
         ground_truth = self.get_ground_truth()
-        
+
         # Test each clause
         predictions = {}
         detailed_results = []
-        
+
         for clause_number in sorted(ground_truth.keys()):
             logger.info(f"Testing clause {clause_number}...")
-            
+
             predicted_types = self.test_classification(clause_number)
             predictions[clause_number] = predicted_types
-            
+
             # Store detailed result
             gt_types = ground_truth[clause_number]
             detailed_results.append({
@@ -303,26 +371,27 @@ class ClassificationTester:
                 'missing_types': list(gt_types - predicted_types),
                 'extra_types': list(predicted_types - gt_types)
             })
-            
+
             # Print progress
             match_status = "✓" if gt_types == predicted_types else "✗"
             logger.info(f"  {match_status} GT: {gt_types}")
             logger.info(f"    Pred: {predicted_types}")
-        
+
         # Calculate metrics
         metrics = self.calculate_accuracy_metrics(ground_truth, predictions)
-        
+
         return {
             'metrics': metrics,
             'detailed_results': detailed_results,
             'model_id': model_id,
             'test_timestamp': datetime.now().isoformat(),
-            'prompt_template': PROMPT_TEMPLATE
+            'prompt_structure': prompt_structure
         }
 
+
 def main():
     """Main function"""
-    
+
     # Parse command line arguments
     parser = argparse.ArgumentParser(
         description='Test ClassifyClauseFunction accuracy against ground truth',
@@ -334,21 +403,21 @@ Examples:
   python test_classification_accuracy.py -f ground_truth_custom.yaml
         """
     )
-    
+
     parser.add_argument(
         '--yaml-file', '-f',
         type=str,
         default='ground_truth_sample_contract.yaml',
         help='Path to the YAML file containing test data (default: ground_truth_sample_contract.yaml)'
     )
-    
+
     parser.add_argument(
         '--model-id', '-m',
         type=str,
         default='us.amazon.nova-pro-v1:0',
         help='Model ID to use for classification (default: us.amazon.nova-pro-v1:0)'
     )
-    
+
     parser.add_argument(
         '--verbose', '-v',
         action='store_true',
@@ -358,11 +427,17 @@ Examples:
     parser.add_argument(
         '--quiet', '-q',
         action='store_true',
-        help='Disable verbose output (hide prompts and LLM responses)'
+        help='Reduce log output (only show essential information)'
     )
-    
+
+    parser.add_argument(
+        '--debug',
+        action='store_true',
+        help='Enable debug level logging'
+    )
+
     args = parser.parse_args()
-    
+
     # Create APP_PROPERTIES with the model from command line
     APP_PROPERTIES = {
         'company_name': 'AnyCompany',
@@ -372,27 +447,39 @@ Examples:
         'language': 'English',
         'llm_model_id': args.model_id
     }
-    
+
     print(f"Using model: {args.model_id}")
-    
+
+    # Configure logging level based on arguments
+    if args.debug:
+        logging.getLogger().setLevel(logging.DEBUG)
+        print("Debug logging enabled")
+    elif args.quiet:
+        logging.getLogger().setLevel(logging.WARNING)
+        print("Quiet mode - only warnings and errors will be shown")
+    else:
+        logging.getLogger().setLevel(logging.INFO)
+
     # SET PROMPT_VARS ENVIRONMENT VARIABLE BEFORE IMPORT
     prompt_vars = '%%'.join([f"{key}={value}" for key, value in APP_PROPERTIES.items()])
     os.environ['PROMPT_VARS'] = prompt_vars
-    
+
     # NOW import the lambda function after setting PROMPT_VARS
     import index
-    index.GROUP_CLASSIFICATION_PROMPT_TEMPLATE = PROMPT_TEMPLATE
-    
+
     # Set verbose flag based on command line argument
     if args.verbose:
         index.VERBOSE_LLM = True
-        print("Verbose mode enabled - will show prompts and LLM responses")
+        print("Verbose LLM mode enabled - will show prompts and LLM responses")
+    elif args.quiet:
+        index.VERBOSE_LLM = False
     else:
+        # Default: show some LLM info but not full verbose
         index.VERBOSE_LLM = False
-    
+
     # Test data file
     test_data_file = args.yaml_file
-    
+
     if not os.path.exists(test_data_file):
         print(f"Error: Test data file '{test_data_file}' not found!")
         print("Available YAML files in current directory:")
@@ -404,37 +491,39 @@ Examples:
             print("  No YAML files found.")
         print("\nPlease run 'python extract_ground_truth.py' first to create a test data file.")
         return 1
-    
+
     print(f"Using test data file: {test_data_file}")
     print(f"Using model: {args.model_id}")
-    
+
     # Initialize tester
     tester = ClassificationTester(test_data_file, APP_PROPERTIES)
-    
+
     # Run test
     results = tester.run_accuracy_test()
-    
+
     # Print results
-    print("\n" + "="*60)
+    print("\n" + "=" * 60)
     print("CLASSIFICATION ACCURACY TEST RESULTS")
-    print("="*60)
+    print("=" * 60)
     print(f"Test Data File: {test_data_file}")
     print(f"Model: {results['model_id']}")
+    print(f"Prompt Type: {results['prompt_structure'].get('prompt_type', 'unknown')}")
     print(f"Test Time: {results['test_timestamp']}")
     print()
-    
+
     metrics = results['metrics']
     if 'error' in metrics:
         print(f"Error: {metrics['error']}")
         return 1
-    
+
     print("ACCURACY METRICS:")
-    print(f"  Exact Match Accuracy: {metrics['exact_match_accuracy']:.3f} ({metrics['exact_matches']}/{metrics['total_clauses']})")
+    print(
+        f"  Exact Match Accuracy: {metrics['exact_match_accuracy']:.3f} ({metrics['exact_matches']}/{metrics['total_clauses']})")
     print(f"  Average Precision:    {metrics['average_precision']:.3f}")
     print(f"  Average Recall:       {metrics['average_recall']:.3f}")
     print(f"  Average F1 Score:     {metrics['average_f1']:.3f}")
     print()
-    
+
     # Show detailed mismatches
     mismatches = [r for r in results['detailed_results'] if not r['exact_match']]
     if mismatches:
@@ -449,14 +538,14 @@ Examples:
                 print(f"  Extra:        {result['extra_types']}")
     else:
         print("🎉 All clauses classified correctly!")
-    
+
     # Create results directory if it doesn't exist
     results_dir = "results"
     os.makedirs(results_dir, exist_ok=True)
-    
+
     # Save results to YAML file in results subfolder
     output_file = os.path.join(results_dir, f"accuracy_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.yaml")
-    
+
     # Manual YAML writing to properly handle multiline strings
     with open(output_file, 'w') as f:
         f.write("detailed_results:\n")
@@ -476,16 +565,23 @@ Examples:
         for key, value in results['metrics'].items():
             f.write(f"  {key}: {value}\n")
         f.write(f"model_id: {results['model_id']}\n")
-        
-        # Write prompt template using literal block style
-        f.write("prompt_template: |\n")
-        for line in results['prompt_template'].split('\n'):
-            f.write(f"  {line}\n")
-        
+
+        # Write prompt structure using literal block style
+        if 'prompt_structure' in results and 'error' not in results['prompt_structure']:
+            f.write("prompt_structure:\n")
+            f.write(f"  prompt_type: {results['prompt_structure'].get('prompt_type', 'unknown')}\n")
+            f.write("  system_prompt: |\n")
+            for line in results['prompt_structure']['system_prompt'].split('\n'):
+                f.write(f"    {line}\n")
+            f.write("  user_prompt_template: |\n")
+            for line in results['prompt_structure']['user_prompt_template'].split('\n'):
+                f.write(f"    {line}\n")
+
         f.write(f"test_timestamp: '{results['test_timestamp']}'\n")
-    
+
     print(f"\nDetailed results saved to: {output_file}")
     return 0
 
+
 if __name__ == "__main__":
     sys.exit(main())
diff --git a/back-end/requirements.txt b/back-end/requirements.txt
index 16a8344..6ac537c 100644
--- a/back-end/requirements.txt
+++ b/back-end/requirements.txt
@@ -8,4 +8,5 @@ pandas==2.2.3
 awswrangler==3.10.1
 argparse==1.4.0
 retrying==1.3.4
-PyYAML==6.0.2
\ No newline at end of file
+PyYAML==6.0.2
+tabulate==0.9.0
\ No newline at end of file
diff --git a/back-end/scripts/workflow_token_usage.py b/back-end/scripts/workflow_token_usage.py
index 5e84ff0..740174d 100755
--- a/back-end/scripts/workflow_token_usage.py
+++ b/back-end/scripts/workflow_token_usage.py
@@ -24,6 +24,12 @@ import time
 from datetime import datetime
 from typing import Dict, List, Any
 
+try:
+    from tabulate import tabulate
+    TABULATE_AVAILABLE = True
+except ImportError:
+    TABULATE_AVAILABLE = False
+
 
 def get_log_groups_from_stack_outputs(cf_client, stack_name: str) -> List[str]:
     """Get log group names from CloudFormation stack outputs."""
@@ -87,6 +93,8 @@ def build_query(correlation_id: str = None) -> str:
     | stats
         sum(token_usage.input_tokens) as total_input_tokens,
         sum(token_usage.output_tokens) as total_output_tokens,
+        sum(token_usage.cache_read_tokens) as total_cache_read_tokens,
+        sum(token_usage.cache_write_tokens) as total_cache_write_tokens,
         count() as llm_calls
         by correlation_id, token_usage.model_id
     """
@@ -126,8 +134,35 @@ def run_query(logs_client, query: str, log_groups: List[str], start_time: int, e
             raise Exception(f"Unknown query status: {status}")
 
 
+def print_table_with_tabulate(table_data: List[Dict], total_input: int, total_output: int, 
+                             total_cache_read: int, total_cache_write: int, total_calls: int) -> None:
+    """Print the table using the tabulate library in simple format."""
+    if not TABULATE_AVAILABLE:
+        print("⚠️  tabulate library not available. Install with: pip install tabulate")
+        return
+    
+    # Prepare data for tabulate
+    headers = ["Job ID", "Model", "Input", "Output", "Cache Read", "Cache Write", "Calls"]
+    
+    # Convert table data to list of lists
+    rows = []
+    for row in table_data:
+        rows.append([
+            row['job_id'],
+            row['model_id'],
+            row['input_tokens'],
+            row['output_tokens'],
+            row['cache_read_tokens'],
+            row['cache_write_tokens'],
+            row['llm_calls']
+        ])
+    
+    # Print table in simple format (no TOTAL row)
+    print(tabulate(rows, headers=headers, tablefmt="simple"))
+
+
 def format_results(results: Dict[str, Any]) -> None:
-    """Format and display the query results."""
+    """Format and display the query results using tabulate."""
     print("\n" + "=" * 120)
     print("TOKEN USAGE ANALYSIS RESULTS")
     print("=" * 120)
@@ -151,12 +186,13 @@ def format_results(results: Dict[str, Any]) -> None:
         return
 
     print(f"\nFound {len(query_results)} result(s):")
-    print("=" * 120)
 
     # Prepare table data
     table_data = []
     total_input = 0
     total_output = 0
+    total_cache_read = 0
+    total_cache_write = 0
     total_calls = 0
 
     for result in query_results:
@@ -166,6 +202,8 @@ def format_results(results: Dict[str, Any]) -> None:
         model_id = row_data.get('token_usage.model_id', 'N/A')
         input_tokens = int(row_data.get('total_input_tokens', 0))
         output_tokens = int(row_data.get('total_output_tokens', 0))
+        cache_read_tokens = int(row_data.get('total_cache_read_tokens', 0))
+        cache_write_tokens = int(row_data.get('total_cache_write_tokens', 0))
         llm_calls = int(row_data.get('llm_calls', 0))
 
         table_data.append({
@@ -173,44 +211,19 @@ def format_results(results: Dict[str, Any]) -> None:
             'model_id': model_id,
             'input_tokens': input_tokens,
             'output_tokens': output_tokens,
+            'cache_read_tokens': cache_read_tokens,
+            'cache_write_tokens': cache_write_tokens,
             'llm_calls': llm_calls
         })
 
         total_input += input_tokens
         total_output += output_tokens
+        total_cache_read += cache_read_tokens
+        total_cache_write += cache_write_tokens
         total_calls += llm_calls
 
-    # Print table header
-    print(f"{'Job ID':<40} {'Model':<50} {'Input':<10} {'Output':<10} {'Calls':<6}")
-    print("-" * 120)
-
-    # Print table rows
-    for row in table_data:
-        model_id = row['model_id']
-        
-        # Split long model IDs into chunks that fit the column
-        if len(model_id) <= 50:
-            # Model fits in one line
-            print(f"{row['job_id']:<40} {model_id:<50} {row['input_tokens']:<10} {row['output_tokens']:<10} {row['llm_calls']:<6}")
-        else:
-            # Model needs to be wrapped
-            model_chunks = []
-            for i in range(0, len(model_id), 50):
-                model_chunks.append(model_id[i:i+50])
-            
-            # First line with all data
-            print(f"{row['job_id']:<40} {model_chunks[0]:<50} {row['input_tokens']:<10} {row['output_tokens']:<10} {row['llm_calls']:<6}")
-            
-            # Additional lines for remaining model text
-            for chunk in model_chunks[1:]:
-                print(f"{'':>40} {chunk:<50}")
-
-    # Summary for multiple results
-    if len(query_results) > 1:
-        print("-" * 120)
-        print(f"{'TOTAL':<40} {'':>50} {total_input:<10} {total_output:<10} {total_calls:<6}")
-
-    print("=" * 120)
+    # Print table using tabulate
+    print_table_with_tabulate(table_data, total_input, total_output, total_cache_read, total_cache_write, total_calls)
 
 
 def main():
diff --git a/back-end/stack/sfn/classification/fn-classify-clauses/index.py b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
index 13b5649..d1ac22a 100644
--- a/back-end/stack/sfn/classification/fn-classify-clauses/index.py
+++ b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
@@ -20,7 +20,36 @@ from collections import defaultdict
 from more_itertools import divide, unique_everseen
 import difflib
 
-from llm import invoke_llm
+from llm import invoke_llm, supports_prompt_caching
+
+SYSTEM_PROMPT_TEMPLATE = """You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
+You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
+
+You task is to say whether any of the following possible types is highly applicable to the clause: 
+<possible_types>
+{possible_types}
+</possible_types>
+
+Rules of thought process:
+<rules_of_thought_process>
+- Making deductions is forbidden
+- Proposing premises is forbidden.
+- Making generalizations is forbidden. 
+- Making implications/deductions about implicit content is forbidden.
+</rules_of_thought_process>
+
+Examples:
+<examples>
+{examples}
+</examples>
+
+Follow these steps:
+- Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
+- For each possible type, look at the corresponding examples (the content between <examples> tags) and distill them into a definition for the clause type. Write all type / distillation pairs between a single <distilled_type_definition></distilled_type_definition> tag pair.  
+- Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one, together with each corresponding distilled type definition, and determine if a type is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags. 
+- For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
+"""
+
 from util import get_prompt_vars_dict, extract_first_item_from_tagged_list, extract_items_and_attributes_from_tagged_list
 
 # Import Powertools
@@ -83,46 +112,6 @@ def generate_prompt(prompt_template, inputs):
     return prompt_template.format_map(defaultdict(str, **inputs))
 
 
-# In onder to help you remember of some context, this is a segment of the contract where the clause you are reading right now is included:
-# <contract_segment>
-# {context}
-# </contract_segment>
-GROUP_CLASSIFICATION_PROMPT_TEMPLATE = """
-
-You are a Senior Specialist in Law, very skilled in understanding of contracts, and you work for company {company_name}.
-You are carefully reading a contract ({contract_type}), having as parties involved the {other_party_type} and company {company_name} ({company_party_type}).
-
-This is the clause you are reading right now:
-<current_clause>
-{clause}
-</current_clause>
-
-You task is to say whether any of the following possible types is highly applicable to the clause: 
-<possible_types>
-{possible_types}
-<possible_types>
-
-Rules of thought process:
-<rules_of_thought_process>
-- Making deductions is forbidden
-- Proposing premises is forbidden.
-- Making generalizations is forbidden. 
-- Making implications/deductions about implicit content is forbidden.
-</rules_of_thought_process>
-
-Examples:
-<examples>
-{examples}
-</examples>
-
-Follow these steps:
-- Replicate between <clause_replica> tags the original text of the clause you are reading (the content between <current_clause> tags)
-- For each possible type, look at the corresponding examples (the content between <examples> tags) and distill them into a definition for the clause type. Write all type / distillation pairs between a single <distilled_type_definition></distilled_type_definition> tag pair.  
-- Thinking step by step and following the rules of thought process (the content between <rules_of_thought_process> tags), look at all possible types (the content between <possible_types> tags) one by one, together with each corresponding distilled type definition, and determine if a type is highly applicable for the clause you are reading (the content between <current_clause> tags). Write all your thoughts, in full, between <thinking> tags. 
-- For your answer, write each highly applicable type between separate <type></type> tags, including an attribute 'reason' having the reason (write in {language}) of why you selected the type. For example: <type reason="reason for selecting the type">a type</type>. If none of the possible types is highly applicable, then write <no_highly_applicable_types/>
-
-"""
-
 ANSWER_TYPE_TAG = 'type'
 ANSWER_REASON_ATTR = 'reason'
 
@@ -145,7 +134,7 @@ def classify_clause(clause, request_id, number_of_classification_prompts=1):
 
     clause_types = get_guidelines_clauses()
 
-    prompt_template = GROUP_CLASSIFICATION_PROMPT_TEMPLATE
+    # prompt_template = GROUP_CLASSIFICATION_PROMPT_TEMPLATE
 
     clause_type_name_to_id = {clause_type['name']: clause_type['type_id'] for clause_type in clause_types}
 
@@ -170,20 +159,19 @@ def classify_clause(clause, request_id, number_of_classification_prompts=1):
 
             possible_types_str = "\n".join([f"- {clause_type['name']}" for clause_type in clause_types_group])
 
-            binary_clause_classification_prompt = generate_prompt(prompt_template, {
-                'possible_types': possible_types_str,
-                'examples': examples_str,
-                'clause': clause,
-                'language': prompt_vars_dict.get('language', 'English'),
-                'company_name': prompt_vars_dict.get('company_name', ''),
-                'contract_type': prompt_vars_dict.get('contract_type', ''),
-                'company_party_type': prompt_vars_dict.get('company_party_type', ''),
-                'other_party_type': prompt_vars_dict.get('other_party_type', '')
-            })
+            # Always build system prompt (guidelines) and user prompt (clause analysis)
+            system_prompt = _build_system_prompt(
+                possible_types_str, examples_str, prompt_vars_dict
+            )
+            user_prompt = _build_user_prompt(clause)
+            
+            # Enable caching only if model supports it
+            enable_caching = supports_prompt_caching(prompt_vars_dict.get("llm_model_id", ''))
 
             futures.append(
-                executor.submit(invoke_llm, prompt=binary_clause_classification_prompt, temperature=0.01, top_k=3,
-                                max_new_tokens=4096, model_id=prompt_vars_dict.get("llm_model_id", ''), verbose=VERBOSE_LLM)
+                executor.submit(invoke_llm, prompt=user_prompt, temperature=0.01, top_k=3,
+                                max_new_tokens=4096, model_id=prompt_vars_dict.get("llm_model_id", ''), 
+                                verbose=VERBOSE_LLM, system_prompt=system_prompt, enable_caching=enable_caching)
             )
 
         llm_output_limit_detected = False
@@ -253,6 +241,27 @@ def classify_clause(clause, request_id, number_of_classification_prompts=1):
             return ddb_values, yes_answers
 
 
+def _build_system_prompt(possible_types_str, examples_str, prompt_vars_dict):
+    """Build the system prompt with guidelines and examples (cacheable)."""
+    return generate_prompt(SYSTEM_PROMPT_TEMPLATE, {
+        'possible_types': possible_types_str,
+        'examples': examples_str,
+        'language': prompt_vars_dict.get('language', 'English'),
+        'company_name': prompt_vars_dict.get('company_name', ''),
+        'contract_type': prompt_vars_dict.get('contract_type', ''),
+        'company_party_type': prompt_vars_dict.get('company_party_type', ''),
+        'other_party_type': prompt_vars_dict.get('other_party_type', '')
+    })
+
+
+def _build_user_prompt(clause):
+    """Build the user prompt with the specific clause to analyze."""
+    return f"""This is the clause you are reading right now:
+<current_clause>
+{clause}
+</current_clause>"""
+
+
 @logger.inject_lambda_context(log_event=True)
 def handler(event, context):
     # Extract Step Functions execution name and set as correlation ID
diff --git a/back-end/stack/sfn/common-layer/llm.py b/back-end/stack/sfn/common-layer/llm.py
index d71c212..3bfe1f8 100644
--- a/back-end/stack/sfn/common-layer/llm.py
+++ b/back-end/stack/sfn/common-layer/llm.py
@@ -12,6 +12,7 @@
 #
 
 import boto3
+import json
 import logging
 import os
 
@@ -73,65 +74,177 @@ def invoke_chain_with_retry(chain):
         raise BedrockRetryableError(str(timeoutExc))
 
 
-def invoke_llm(prompt, model_id, temperature=0.5, top_k=None, top_p=None, max_new_tokens=4096, verbose=False):
+def invoke_llm(prompt, model_id, temperature=0.5, top_k=None, top_p=None, max_new_tokens=4096, verbose=False, system_prompt=None, enable_caching=False):
+    """
+    Invoke LLM using LangChain ChatBedrock with prompt caching support.
+    
+    Args:
+        prompt: The user prompt text
+        model_id: Model identifier
+        temperature: Sampling temperature
+        top_k: Top-k sampling parameter
+        top_p: Top-p sampling parameter
+        max_new_tokens: Maximum tokens to generate
+        verbose: Enable verbose logging
+        system_prompt: System prompt text (cacheable if enable_caching=True)
+        enable_caching: Whether to cache the system prompt
+    """
     model_id = (model_id or CLAUDE_MODEL_ID)
 
     if verbose:
         logger.info(f"ModelId: {model_id}")
-        logger.info(f"Prompt:\n{prompt}")
-
-    model_kwargs = {
-        # 'anthropic_version': 'bedrock-2023-05-31',
-        "max_tokens": max_new_tokens,
-    }
-    if temperature is not None:
-        model_kwargs["temperature"] = temperature
-    if top_p is not None:
-        model_kwargs["top_p"] = top_p
-    if top_k is not None:
-        model_kwargs["top_k"] = top_k
-
-    chat = ChatBedrock(
-        client=bedrock_client,
-        model_id=model_id,
-        model_kwargs=model_kwargs,
-    )
-
-    human_message = [{
-        'type': 'text',
-        'text': prompt,
-    }]
-    prompt = ChatPromptTemplate.from_messages([
-        HumanMessage(content=human_message)
-    ])
-    chain = prompt | chat
-
-    response = invoke_chain_with_retry(chain)
-    content = response.content
-
-    usage_data = None
-    stop_reason = None
-
-    if ('anthropic' in model_id):
-        usage_data = response.response_metadata['usage']
-        stop_reason = response.response_metadata['stop_reason']
-    elif ('amazon.nova' in model_id):
-        usage_data = response.usage_metadata
-        stop_reason = response.response_metadata['stopReason']
+        if system_prompt:
+            logger.info(f"System prompt (cache={enable_caching}): {system_prompt}...")
+        logger.info(f"User prompt: {prompt}...")
 
-    if verbose:
-        logger.info(f"Model response: {content}")
-        logger.info(f"Model usage: {usage_data}")
-        logger.info(f"Model stop_reason: {stop_reason}")
-
-    # # Always log token usage for cost tracking with Powertools structured logging
-    if usage_data:
-        logger.info("LLM token usage", extra={
-            "token_usage": {
+    try:
+        # Configure model parameters
+        model_kwargs = {
+            "max_tokens": max_new_tokens,
+            "temperature": temperature,
+        }
+        if top_p is not None:
+            model_kwargs["top_p"] = top_p
+        if top_k is not None:
+            model_kwargs["top_k"] = top_k
+
+        # Initialize ChatBedrock
+        chat = ChatBedrock(
+            client=bedrock_client,
+            model_id=model_id,
+            model_kwargs=model_kwargs,
+        )
+
+        # Build messages with caching support
+        messages = []
+        
+        # Add system message with optional caching
+        if system_prompt:
+            system_message = _build_cached_system_message(enable_caching, system_prompt, model_id)
+            if system_message:
+                messages.append(system_message)
+                
+                # User message must also be in raw format when mixing with cached system
+                user_message = {
+                    "role": "user", 
+                    "content": [
+                        {
+                            "type": "text",
+                            "text": prompt
+                        }
+                    ]
+                }
+                messages.append(user_message)
+            else:
+                # No caching (either not requested or not supported), use standard format
+                messages.append(("system", system_prompt))
+                messages.append(("user", prompt))
+        else:
+            # No system prompt, just user message
+            messages.append(("user", prompt))
+
+        # Invoke the model
+        response = chat.invoke(messages)
+        
+        if verbose:
+            logger.info(f"Model response: {response}")
+
+        # Extract usage data and cache metrics
+        usage_data = getattr(response, 'usage_metadata', {})
+        stop_reason = getattr(response, 'response_metadata', {}).get('stop_reason')
+
+        if usage_data:
+            input_token_details = usage_data.get('input_token_details', {})
+            cache_read = (input_token_details.get('cache_read', 0))
+            cache_write = (input_token_details.get('cache_creation', 0))
+            
+            if cache_read > 0:
+                logger.info(f"✅ Cache read: {cache_read} tokens")
+            if cache_write > 0:
+                logger.info(f"✅ Cache created: {cache_write} tokens")
+
+            token_usage_log = {
                 "model_id": model_id,
-                "input_tokens": usage_data.get('prompt_tokens', 0),
-                "output_tokens": usage_data.get('completion_tokens', 0)
+                "input_tokens": usage_data.get('input_tokens', 0),
+                "output_tokens": usage_data.get('output_tokens', 0),
+                "cache_read_tokens": cache_read,
+                "cache_write_tokens": cache_write
             }
-        })
+            
+            logger.info("LLM token usage", extra={
+                "token_usage": token_usage_log
+            })
+
+        return response.content, usage_data, stop_reason
+        
+    except Exception as e:
+        logger.error(f"Error invoking model: {str(e)}")
+        raise
+
+
+def _build_cached_system_message(enable_caching, system_prompt, model_id):
+    """Build a cached system message if caching is enabled and model supports it, otherwise return None."""
+    if not enable_caching or not supports_prompt_caching(model_id):
+        return None
+    
+    base_content = {"type": "text", "text": system_prompt}
+    
+    if _is_nova_model(model_id):
+        return {
+            "role": "system",
+            "content": [base_content, {"cachePoint": {"type": "default"}}]
+        }
+    elif _is_claude_model(model_id):
+        base_content["cache_control"] = {"type": "ephemeral"}
+        return {
+            "role": "system", 
+            "content": [base_content]
+        }
+    else:
+        # Fallback for unknown model types - no caching
+        return {
+            "role": "system",
+            "content": [base_content]
+        }
+
+
+def supports_prompt_caching(model_id):
+    """Check if the model supports prompt caching."""
+    supported_models = [
+        'anthropic.claude-opus-4-20250514-v1:0',
+        'anthropic.claude-sonnet-4-20250514-v1:0', 
+        'anthropic.claude-3-7-sonnet-20250219-v1:0',
+        'anthropic.claude-3-haiku-20240307-v1:0',
+        'anthropic.claude-3-5-haiku-20241022-v1:0',
+        'anthropic.claude-3-5-sonnet-20241022-v2:0',
+        'amazon.nova-micro-v1:0',
+        'amazon.nova-lite-v1:0',
+        'amazon.nova-pro-v1:0',
+        'amazon.nova-premier-v1:0'
+    ]
+    
+    # Remove region prefix if it exists (e.g., "us." or "eu.")
+    if model_id.startswith('us.') or model_id.startswith('eu.'):
+        model_id = model_id.split('.', 1)[1]
+    
+    return model_id in supported_models
+
+
+def _is_nova_model(model_id):
+    """Check if the model is an Amazon Nova model."""
+    # Remove region prefix if it exists (e.g., "us." or "eu.")
+    if model_id.startswith('us.') or model_id.startswith('eu.'):
+        model_id = model_id.split('.', 1)[1]
+    
+    return model_id.startswith('amazon.nova-')
+
+
+def _is_claude_model(model_id):
+    """Check if the model is an Anthropic Claude model."""
+    # Remove region prefix if it exists (e.g., "us." or "eu.")
+    if model_id.startswith('us.') or model_id.startswith('eu.'):
+        model_id = model_id.split('.', 1)[1]
+    
+    return model_id.startswith('anthropic.claude-')
+
 
-    return content, usage_data, stop_reason
diff --git a/back-end/stack/sfn/common-layer/requirements.txt b/back-end/stack/sfn/common-layer/requirements.txt
index df99346..6b0f74e 100644
--- a/back-end/stack/sfn/common-layer/requirements.txt
+++ b/back-end/stack/sfn/common-layer/requirements.txt
@@ -1,3 +1,3 @@
-retrying==1.3.4
-botocore==1.38.9
+retrying==1.4.2
+botocore==1.40.2
 aws-lambda-powertools==3.18.0
\ No newline at end of file
diff --git a/back-end/stack/sfn/langchain-deps-layer/requirements.txt b/back-end/stack/sfn/langchain-deps-layer/requirements.txt
index b53826c..d1260ae 100644
--- a/back-end/stack/sfn/langchain-deps-layer/requirements.txt
+++ b/back-end/stack/sfn/langchain-deps-layer/requirements.txt
@@ -1,3 +1,3 @@
-langchain==0.3.9
-langchain-community==0.3.9
-langchain-aws==0.2.9
\ No newline at end of file
+langchain==0.3.27
+langchain-community==0.3.27
+langchain-aws==0.2.30
\ No newline at end of file
-- 
2.39.5 (Apple Git-154)


From 9591d5a5ce0f547e167bbbab561a24b26bb065d5 Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Tue, 5 Aug 2025 16:48:08 -0300
Subject: [PATCH 09/13] Remove hardcoded DynamoDB resource names

---
 back-end/eval/eval_clause_classification.py | 76 +++++++++++++++++++--
 back-end/stack/__init__.py                  |  6 ++
 2 files changed, 77 insertions(+), 5 deletions(-)

diff --git a/back-end/eval/eval_clause_classification.py b/back-end/eval/eval_clause_classification.py
index 9c94097..21a0b5d 100644
--- a/back-end/eval/eval_clause_classification.py
+++ b/back-end/eval/eval_clause_classification.py
@@ -14,11 +14,41 @@ import argparse
 from typing import Dict, List, Set
 from datetime import datetime
 
-# Set environment variables BEFORE importing lambda modules
-# TODO: get DDB resource names dynamically (CFN
-os.environ['GUIDELINES_TABLE_NAME'] = "MainBackendStack-GuidelinesTable52F2F85C-BLPR5YN3XTT7"
-os.environ['CLAUSES_TABLE_NAME'] = "MainBackendStack-ClausesTableB80AC60F-1JDQ7Q8DBVI9A"
-os.environ['BEDROCK_MAX_CONCURRENCY'] = "3"
+def get_table_names_from_stack(cf_client, stack_name: str = "MainBackendStack") -> Dict[str, str]:
+    """Get DynamoDB table names from CloudFormation stack outputs"""
+    response = cf_client.describe_stacks(StackName=stack_name)
+    
+    if not response['Stacks']:
+        raise Exception(f"Stack {stack_name} not found")
+    
+    stack = response['Stacks'][0]
+    outputs = stack.get('Outputs', [])
+    
+    # Create a map of output key to value
+    output_map = {output['OutputKey']: output['OutputValue'] for output in outputs}
+    
+    # Look for table name outputs
+    table_names = {}
+    
+    # Common patterns for table name outputs
+    for output_key, output_value in output_map.items():
+        if 'guidelines' in output_key.lower() and 'table' in output_key.lower():
+            table_names['GUIDELINES_TABLE_NAME'] = output_value
+        elif 'clauses' in output_key.lower() and 'table' in output_key.lower():
+            table_names['CLAUSES_TABLE_NAME'] = output_value
+    
+    # Verify we found both required outputs
+    required_tables = ['GUIDELINES_TABLE_NAME', 'CLAUSES_TABLE_NAME']
+    missing_tables = [table for table in required_tables if table not in table_names]
+    
+    if missing_tables:
+        print(f"Error: Missing required table outputs in stack {stack_name}: {missing_tables}")
+        print("Available outputs:")
+        for output_key in output_map.keys():
+            print(f"  - {output_key}")
+        raise Exception(f"Required table outputs not found: {missing_tables}")
+    
+    return table_names
 
 # Add the lambda function modules to path
 sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'stack', 'sfn', 'common-layer'))
@@ -436,8 +466,44 @@ Examples:
         help='Enable debug level logging'
     )
 
+    parser.add_argument(
+        '--stack-name',
+        type=str,
+        default='MainBackendStack',
+        help='CloudFormation stack name to get table names from (default: MainBackendStack)'
+    )
+
+    parser.add_argument(
+        '--region',
+        help='AWS region (uses default from profile/environment if not specified)'
+    )
+
     args = parser.parse_args()
 
+    # Set up AWS session
+    session_kwargs = {}
+    if args.region:
+        session_kwargs['region_name'] = args.region
+
+    session = boto3.Session(**session_kwargs)
+    cf_client = session.client('cloudformation')
+
+    # Get table names dynamically from CloudFormation using the specified stack name
+    table_names = get_table_names_from_stack(cf_client, args.stack_name)
+    
+    # Set environment variables BEFORE importing lambda modules
+    os.environ['GUIDELINES_TABLE_NAME'] = table_names['GUIDELINES_TABLE_NAME']
+    os.environ['CLAUSES_TABLE_NAME'] = table_names['CLAUSES_TABLE_NAME']
+    os.environ['BEDROCK_MAX_CONCURRENCY'] = "3"
+
+    print(f"Using stack: {args.stack_name}")
+    if args.region:
+        print(f"Using region: {args.region}")
+    else:
+        print("Using default region from AWS profile/environment")
+    print(f"Using Guidelines Table: {table_names['GUIDELINES_TABLE_NAME']}")
+    print(f"Using Clauses Table: {table_names['CLAUSES_TABLE_NAME']}")
+
     # Create APP_PROPERTIES with the model from command line
     APP_PROPERTIES = {
         'company_name': 'AnyCompany',
diff --git a/back-end/stack/__init__.py b/back-end/stack/__init__.py
index 51f3231..d6d68b8 100644
--- a/back-end/stack/__init__.py
+++ b/back-end/stack/__init__.py
@@ -71,6 +71,12 @@ class BackendStack(Stack):
             sort_key=dynamodb.Attribute(name="clause_number", type=dynamodb.AttributeType.NUMBER)
         )
 
+        CfnOutput(
+            self,
+            "ClausesTableName",
+            value=self.clauses_table.table_name,
+        )
+
         # Jobs DynamoDB table
         self.jobs_table = stack_constructs.TableConstruct(
             self,
-- 
2.39.5 (Apple Git-154)


From 1b06b18ff41e03e503396aa8bcf46b2bdef7dac9 Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Tue, 5 Aug 2025 18:22:21 -0300
Subject: [PATCH 10/13] add retry for ModelErrorException

---
 back-end/stack/sfn/common-layer/llm.py | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/back-end/stack/sfn/common-layer/llm.py b/back-end/stack/sfn/common-layer/llm.py
index 3bfe1f8..7b89987 100644
--- a/back-end/stack/sfn/common-layer/llm.py
+++ b/back-end/stack/sfn/common-layer/llm.py
@@ -52,7 +52,7 @@ class BedrockRetryableError(Exception):
     retry_on_exception=lambda ex: isinstance(ex, BedrockRetryableError),
 )
 def invoke_chain_with_retry(chain):
-    """Invoke Bedrock with retry logic for throttling"""
+    """Invoke Bedrock with retry logic for throttling and model errors"""
     try:
         return chain.invoke({})
     except ClientError as exc:
@@ -64,6 +64,9 @@ def invoke_chain_with_retry(chain):
         elif exc.response["Error"]["Code"] == "ModelTimeoutException":
             logger.warning("Bedrock ModelTimeoutException. Retrying...")
             raise BedrockRetryableError(str(exc))
+        elif exc.response["Error"]["Code"] == "ModelErrorException":
+            logger.warning("Bedrock ModelErrorException. Retrying...")
+            raise BedrockRetryableError(str(exc))
         else:
             raise
     except bedrock_client.exceptions.ThrottlingException as throttlingExc:
-- 
2.39.5 (Apple Git-154)


From 1eb5c37b666c150271de7fc51ee0e596bd9d4247 Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Tue, 5 Aug 2025 18:23:46 -0300
Subject: [PATCH 11/13] no longer set top_k together with temperature

---
 back-end/stack/sfn/classification/fn-classify-clauses/index.py | 2 +-
 back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py     | 1 -
 .../stack/sfn/preprocessing/fn-preprocess-contract/index.py    | 3 +--
 3 files changed, 2 insertions(+), 4 deletions(-)

diff --git a/back-end/stack/sfn/classification/fn-classify-clauses/index.py b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
index d1ac22a..558ccbf 100644
--- a/back-end/stack/sfn/classification/fn-classify-clauses/index.py
+++ b/back-end/stack/sfn/classification/fn-classify-clauses/index.py
@@ -169,7 +169,7 @@ def classify_clause(clause, request_id, number_of_classification_prompts=1):
             enable_caching = supports_prompt_caching(prompt_vars_dict.get("llm_model_id", ''))
 
             futures.append(
-                executor.submit(invoke_llm, prompt=user_prompt, temperature=0.01, top_k=3,
+                executor.submit(invoke_llm, prompt=user_prompt, temperature=0.01,
                                 max_new_tokens=4096, model_id=prompt_vars_dict.get("llm_model_id", ''), 
                                 verbose=VERBOSE_LLM, system_prompt=system_prompt, enable_caching=enable_caching)
             )
diff --git a/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py b/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py
index 7fe6d22..e6c1d4d 100644
--- a/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py
+++ b/back-end/stack/sfn/evaluation/fn-evaluate-clauses/index.py
@@ -154,7 +154,6 @@ def run_evaluation(clause, clause_context, rule, prompt_vars_dict):
         prompt=evaluation_prompt,
         model_id=prompt_vars_dict.get("llm_model_id", ''),
         temperature=0.01,
-        top_k=3,
         max_new_tokens=2000,
         verbose=True
     )
diff --git a/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py b/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py
index 7a47fa1..6ccf0ed 100644
--- a/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py
+++ b/back-end/stack/sfn/preprocessing/fn-preprocess-contract/index.py
@@ -104,8 +104,7 @@ def separate_clauses(contract_excerpt):
     llm_response, model_usage, stop_reason = invoke_llm(
         prompt=PROMPT_TEMPLATE.format(CONTRACT_EXCERPT=contract_excerpt),
         model_id=prompt_vars_dict.get("llm_model_id", ''),
-        temperature=0.0,
-        top_k=3,
+        temperature=0.01,
         max_new_tokens=4096,
         verbose=True
     )
-- 
2.39.5 (Apple Git-154)


From e186717d121ee98f05e21f90cad6c742bbba840e Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Tue, 5 Aug 2025 18:24:40 -0300
Subject: [PATCH 12/13] replace system/user actual prompts with corresponding
 templates in the eval results

---
 back-end/eval/eval_clause_classification.py | 54 +++++++++------------
 1 file changed, 24 insertions(+), 30 deletions(-)

diff --git a/back-end/eval/eval_clause_classification.py b/back-end/eval/eval_clause_classification.py
index 21a0b5d..c80e77b 100644
--- a/back-end/eval/eval_clause_classification.py
+++ b/back-end/eval/eval_clause_classification.py
@@ -242,35 +242,29 @@ class ClassificationTester:
         logger.info(f"Loaded {len(data['clauses'])} clauses")
         return data
 
-    def get_current_prompt_structure(self) -> Dict[str, str]:
-        """Get the current system and user prompt templates for reporting"""
-        # Get a sample clause type group to build example prompts
-        clause_types = self.get_guidelines_clauses()
-        if not clause_types:
-            return {"error": "No clause types available"}
-
-        # Take first few clause types as example
-        sample_clause_types = clause_types[:3]
-
-        # Build example prompts using the same logic as production
-        from index import build_tagged_examples_string
-        examples_str = build_tagged_examples_string(sample_clause_types)
-        possible_types_str = "\n".join([f"- {clause_type['name']}" for clause_type in sample_clause_types])
-
-        # Build system prompt (will use monkey patched version if applied)
-        system_prompt = self._build_system_prompt(
-            possible_types_str, examples_str, self.app_properties
-        )
-
-        # Build user prompt with sample text
-        user_prompt = self._build_user_prompt("Sample clause text for demonstration")
+    def get_prompt_templates(self) -> Dict[str, str]:
+        """Get the current system and user prompt templates for reporting (preserving placeholders)"""
+        # Import the template from index.py to get the current version (including any monkey patches)
+        import index
+        
+        # Get the current system prompt template (will be monkey patched version if applied)
+        if CUSTOM_SYSTEM_PROMPT_TEMPLATE is not None:
+            system_prompt_template = CUSTOM_SYSTEM_PROMPT_TEMPLATE
+            prompt_type = "custom"
+        else:
+            system_prompt_template = index.SYSTEM_PROMPT_TEMPLATE
+            prompt_type = "existing"
 
-        # Indicate if using custom prompt
-        prompt_type = "custom" if CUSTOM_SYSTEM_PROMPT_TEMPLATE is not None else "production"
+        # Get the user prompt template by examining the _build_user_prompt function
+        # This preserves the template structure with placeholders
+        user_prompt_template = """This is the clause you are reading right now:
+<current_clause>
+{clause_text}
+</current_clause>"""
 
         return {
-            "system_prompt": system_prompt,
-            "user_prompt_template": user_prompt.replace("Sample clause text for demonstration", "{clause_text}"),
+            "system_prompt_template": system_prompt_template,
+            "user_prompt_template": user_prompt_template,
             "prompt_type": prompt_type
         }
 
@@ -375,8 +369,8 @@ class ClassificationTester:
         model_id = self.app_properties.get('llm_model_id', 'unknown')
         logger.info(f"Using model: {model_id}")
 
-        # Get current prompt structure for reporting
-        prompt_structure = self.get_current_prompt_structure()
+        # Get current prompt templates for reporting
+        prompt_structure = self.get_prompt_templates()
 
         # Load ground truth
         ground_truth = self.get_ground_truth()
@@ -636,8 +630,8 @@ Examples:
         if 'prompt_structure' in results and 'error' not in results['prompt_structure']:
             f.write("prompt_structure:\n")
             f.write(f"  prompt_type: {results['prompt_structure'].get('prompt_type', 'unknown')}\n")
-            f.write("  system_prompt: |\n")
-            for line in results['prompt_structure']['system_prompt'].split('\n'):
+            f.write("  system_prompt_template: |\n")
+            for line in results['prompt_structure']['system_prompt_template'].split('\n'):
                 f.write(f"    {line}\n")
             f.write("  user_prompt_template: |\n")
             for line in results['prompt_structure']['user_prompt_template'].split('\n'):
-- 
2.39.5 (Apple Git-154)


From 1fd492de7fabfd65db214de600e5f61bba664edc Mon Sep 17 00:00:00 2001
From: Givanildo Alves <gdalves@amazon.com>
Date: Tue, 5 Aug 2025 19:11:01 -0300
Subject: [PATCH 13/13] fix duplicate log entries

---
 back-end/.gitignore                         |  1 +
 back-end/eval/eval_clause_classification.py | 18 ++++++++++--------
 2 files changed, 11 insertions(+), 8 deletions(-)

diff --git a/back-end/.gitignore b/back-end/.gitignore
index ada5695..6bbc474 100644
--- a/back-end/.gitignore
+++ b/back-end/.gitignore
@@ -215,6 +215,7 @@ __pypackages__/
 
 
 ### VisualStudioCode ###
+.vscode
 .vscode/*
 !.vscode/settings.json
 !.vscode/tasks.json
diff --git a/back-end/eval/eval_clause_classification.py b/back-end/eval/eval_clause_classification.py
index c80e77b..3effc9e 100644
--- a/back-end/eval/eval_clause_classification.py
+++ b/back-end/eval/eval_clause_classification.py
@@ -215,15 +215,17 @@ class ClassificationTester:
         )
         
         for logger_obj in loggers_to_fix:
-            # Remove any existing handlers
-            for handler in logger_obj.handlers[:]:
-                logger_obj.removeHandler(handler)
+            # Clear ALL handlers completely
+            logger_obj.handlers.clear()
             
-            # Add our plain text handler
-            if not logger_obj.handlers:  # Only add if no handlers exist
-                handler = logging.StreamHandler(sys.stdout)
-                handler.setFormatter(plain_formatter)
-                logger_obj.addHandler(handler)
+            # Always add our plain text handler
+            handler = logging.StreamHandler(sys.stdout)
+            handler.setFormatter(plain_formatter)
+            logger_obj.addHandler(handler)
+            
+            # Prevent propagation to avoid duplicate messages from parent loggers
+            if logger_obj.name != '':  # Don't set propagate=False on root logger
+                logger_obj.propagate = False
 
     def _apply_system_prompt_monkey_patch(self):
         """Apply monkey patch to use custom system prompt template"""
-- 
2.39.5 (Apple Git-154)

